{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "936121ed-12d9-4be2-b118-e42eb59c65e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov10'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/THU-MIG/yolov10.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baaad2fa-23ed-4ee6-8b4f-dce92cb6ab4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd yolov10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a726b2d9-9fa5-4e51-88b9-4cf7f1fd0e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing c:\\users\\sshiv\\desktop\\sihproject\\yolov10\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics==8.1.34) (3.8.2)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics==8.1.34) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics==8.1.34) (10.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics==8.1.34) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics==8.1.34) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics==8.1.34) (1.14.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics==8.1.34) (2.4.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics==8.1.34) (0.19.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics==8.1.34) (4.66.5)\n",
      "Requirement already satisfied: psutil in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics==8.1.34) (6.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics==8.1.34) (9.0.0)\n",
      "Requirement already satisfied: thop>=0.1.1 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics==8.1.34) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics==8.1.34) (2.1.4)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics==8.1.34) (0.13.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.1.34) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.1.34) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.1.34) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.1.34) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.1.34) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.1.34) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.1.34) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.1.34) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.1.4->ultralytics==8.1.34) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.1.4->ultralytics==8.1.34) (2023.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics==8.1.34) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics==8.1.34) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics==8.1.34) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics==8.1.34) (2024.2.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.1.34) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.1.34) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.1.34) (1.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.1.34) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.1.34) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.1.34) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.1.34) (69.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>=4.64.0->ultralytics==8.1.34) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics==8.1.34) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics==8.1.34) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics==8.1.34) (1.3.0)\n",
      "Building wheels for collected packages: ultralytics\n",
      "  Building wheel for ultralytics (pyproject.toml): started\n",
      "  Building wheel for ultralytics (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for ultralytics: filename=ultralytics-8.1.34-py3-none-any.whl size=735416 sha256=3ae778142be384e3990c2ac8390f75fb622c3930f4efcdf464b8d3a4e4974833\n",
      "  Stored in directory: C:\\Users\\sshiv\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-ra15e_2t\\wheels\\b4\\60\\f5\\b2efe50de2bcf69c35ca7a25a65e866ba4a406f497e7bc59ec\n",
      "Successfully built ultralytics\n",
      "Installing collected packages: ultralytics\n",
      "  Attempting uninstall: ultralytics\n",
      "    Found existing installation: ultralytics 8.1.34\n",
      "    Uninstalling ultralytics-8.1.34:\n",
      "      Successfully uninstalled ultralytics-8.1.34\n",
      "Successfully installed ultralytics-8.1.34\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f87dcf77-1f72-4422-89a3-988abd628b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/THU-MIG/yolov10.git\n",
      "  Cloning https://github.com/THU-MIG/yolov10.git to c:\\users\\sshiv\\appdata\\local\\temp\\pip-req-build-6tpe8frx\n",
      "  Resolved https://github.com/THU-MIG/yolov10.git to commit cd2f79c70299c9041fb6d19617ef1296f47575b1\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics==8.1.34) (3.8.2)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics==8.1.34) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics==8.1.34) (10.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics==8.1.34) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics==8.1.34) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics==8.1.34) (1.14.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics==8.1.34) (2.4.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics==8.1.34) (0.19.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics==8.1.34) (4.66.5)\n",
      "Requirement already satisfied: psutil in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics==8.1.34) (6.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics==8.1.34) (9.0.0)\n",
      "Requirement already satisfied: thop>=0.1.1 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics==8.1.34) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics==8.1.34) (2.1.4)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics==8.1.34) (0.13.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.1.34) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.1.34) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.1.34) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.1.34) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.1.34) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.1.34) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.1.34) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.1.34) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.1.4->ultralytics==8.1.34) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.1.4->ultralytics==8.1.34) (2023.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics==8.1.34) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics==8.1.34) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics==8.1.34) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics==8.1.34) (2024.2.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.1.34) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.1.34) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.1.34) (1.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.1.34) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.1.34) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.1.34) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.1.34) (69.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>=4.64.0->ultralytics==8.1.34) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics==8.1.34) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics==8.1.34) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics==8.1.34) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/THU-MIG/yolov10.git 'C:\\Users\\sshiv\\AppData\\Local\\Temp\\pip-req-build-6tpe8frx'\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/THU-MIG/yolov10.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d34b79a-d451-47ae-8dfa-914ecf4490f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt\n",
      "Downloaded C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10s.pt\n",
      "Downloaded C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10m.pt\n",
      "Downloaded C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10b.pt\n",
      "Downloaded C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10x.pt\n",
      "Downloaded C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10l.pt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "# Create a directory for the weights in the current working directory\n",
    "weights_dir = os.path.join(os.getcwd(), \"weights\")\n",
    "os.makedirs(weights_dir, exist_ok=True)\n",
    "\n",
    "# URLs of the weight files\n",
    "urls = [\n",
    "    \"https://github.com/jameslahm/yolov10/releases/download/v1.0/yolov10n.pt\",\n",
    "    \"https://github.com/jameslahm/yolov10/releases/download/v1.0/yolov10s.pt\",\n",
    "    \"https://github.com/jameslahm/yolov10/releases/download/v1.0/yolov10m.pt\",\n",
    "    \"https://github.com/jameslahm/yolov10/releases/download/v1.0/yolov10b.pt\",\n",
    "    \"https://github.com/jameslahm/yolov10/releases/download/v1.0/yolov10x.pt\",\n",
    "    \"https://github.com/jameslahm/yolov10/releases/download/v1.0/yolov10l.pt\"\n",
    "]\n",
    "\n",
    "# Download each file\n",
    "for url in urls:\n",
    "    file_name = os.path.join(weights_dir, os.path.basename(url))\n",
    "    urllib.request.urlretrieve(url, file_name)\n",
    "    print(f\"Downloaded {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09c905b0-5465-439a-946e-e10c250b0b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\yolo.exe\\__main__.py\", line 4, in <module>\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\__init__.py\", line 5, in <module>\n",
      "    from ultralytics.data.explorer.explorer import Explorer\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\data\\__init__.py\", line 3, in <module>\n",
      "    from .base import BaseDataset\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\data\\base.py\", line 15, in <module>\n",
      "    from torch.utils.data import Dataset\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\__init__.py\", line 148, in <module>\n",
      "    raise err\n",
      "OSError: [WinError 126] The specified module could not be found. Error loading \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\lib\\fbgemm.dll\" or one of its dependencies.\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.25 save=True model=../weights/yolov10n.pt source=test_images/1.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f9e416e-629c-41d7-ba7c-5b50f24b3267",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\yolo.exe\\__main__.py\", line 4, in <module>\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\__init__.py\", line 5, in <module>\n",
      "    from ultralytics.data.explorer.explorer import Explorer\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\data\\__init__.py\", line 3, in <module>\n",
      "    from .base import BaseDataset\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\data\\base.py\", line 15, in <module>\n",
      "    from torch.utils.data import Dataset\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\__init__.py\", line 148, in <module>\n",
      "    raise err\n",
      "OSError: [WinError 126] The specified module could not be found. Error loading \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\lib\\fbgemm.dll\" or one of its dependencies.\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.25 save=True model=../weights/yolov10n.pt source=test_images/1.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "461c023f-9ee3-4c86-ab86-d504d1a84624",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\yolo.exe\\__main__.py\", line 4, in <module>\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\__init__.py\", line 5, in <module>\n",
      "    from ultralytics.data.explorer.explorer import Explorer\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\data\\__init__.py\", line 3, in <module>\n",
      "    from .base import BaseDataset\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\data\\base.py\", line 15, in <module>\n",
      "    from torch.utils.data import Dataset\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\__init__.py\", line 148, in <module>\n",
      "    raise err\n",
      "OSError: [WinError 126] The specified module could not be found. Error loading \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\lib\\fbgemm.dll\" or one of its dependencies.\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.25 save=True model=../weights/yolov10n.pt source=test_images/1.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87895254-a755-4a3b-ad78-a76e756747eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\yolo.exe\\__main__.py\", line 4, in <module>\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\__init__.py\", line 5, in <module>\n",
      "    from ultralytics.data.explorer.explorer import Explorer\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\data\\__init__.py\", line 3, in <module>\n",
      "    from .base import BaseDataset\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\data\\base.py\", line 15, in <module>\n",
      "    from torch.utils.data import Dataset\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\__init__.py\", line 148, in <module>\n",
      "    raise err\n",
      "OSError: [WinError 126] The specified module could not be found. Error loading \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\lib\\fbgemm.dll\" or one of its dependencies.\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.25 save=True model=../weights/yolov10n.pt source=test_images/1.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b992d0e-c09a-47b5-b27b-13d267d6701f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\yolo.exe\\__main__.py\", line 4, in <module>\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\__init__.py\", line 5, in <module>\n",
      "    from ultralytics.data.explorer.explorer import Explorer\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\data\\__init__.py\", line 3, in <module>\n",
      "    from .base import BaseDataset\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\data\\base.py\", line 15, in <module>\n",
      "    from torch.utils.data import Dataset\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\__init__.py\", line 148, in <module>\n",
      "    raise err\n",
      "OSError: [WinError 126] The specified module could not be found. Error loading \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\lib\\fbgemm.dll\" or one of its dependencies.\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.25 save=True model=../weights/yolov10n.pt source=test_images/1.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59908ba9-eae6-4ceb-9f5e-4dfcde41452e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\yolo.exe\\__main__.py\", line 4, in <module>\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\__init__.py\", line 5, in <module>\n",
      "    from ultralytics.data.explorer.explorer import Explorer\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\data\\__init__.py\", line 3, in <module>\n",
      "    from .base import BaseDataset\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\data\\base.py\", line 15, in <module>\n",
      "    from torch.utils.data import Dataset\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\__init__.py\", line 148, in <module>\n",
      "    raise err\n",
      "OSError: [WinError 126] The specified module could not be found. Error loading \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\lib\\fbgemm.dll\" or one of its dependencies.\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.25 save=True model=../weights/yolov10s.pt source=test_images/1.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e934db6-6a83-410b-a3d0-0017ea3fecf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\yolo.exe\\__main__.py\", line 4, in <module>\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\__init__.py\", line 5, in <module>\n",
      "    from ultralytics.data.explorer.explorer import Explorer\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\data\\__init__.py\", line 3, in <module>\n",
      "    from .base import BaseDataset\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\data\\base.py\", line 15, in <module>\n",
      "    from torch.utils.data import Dataset\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\__init__.py\", line 148, in <module>\n",
      "    raise err\n",
      "OSError: [WinError 126] The specified module could not be found. Error loading \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\lib\\fbgemm.dll\" or one of its dependencies.\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.25 save=True model=../weights/yolov10s.pt source=test_images/1.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c105e31e-24eb-43c4-9edb-57a5dd3dae9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\yolo.exe\\__main__.py\", line 4, in <module>\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\__init__.py\", line 5, in <module>\n",
      "    from ultralytics.data.explorer.explorer import Explorer\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\data\\explorer\\explorer.py\", line 18, in <module>\n",
      "    from ultralytics.models.yolo.model import YOLO\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\models\\__init__.py\", line 6, in <module>\n",
      "    from .yolov10 import YOLOv10\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\models\\yolov10\\__init__.py\", line 1, in <module>\n",
      "    from .model import YOLOv10\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\models\\yolov10\\model.py\", line 7, in <module>\n",
      "    from huggingface_hub import PyTorchModelHubMixin\n",
      "ModuleNotFoundError: No module named 'huggingface_hub'\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.25 save=True model=../weights/yolov10s.pt source=test_images/1.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cdbf63f-ef5f-4664-9e3f-3034c30e0b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\yolo.exe\\__main__.py\", line 4, in <module>\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\__init__.py\", line 5, in <module>\n",
      "    from ultralytics.data.explorer.explorer import Explorer\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\data\\explorer\\explorer.py\", line 18, in <module>\n",
      "    from ultralytics.models.yolo.model import YOLO\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\models\\__init__.py\", line 6, in <module>\n",
      "    from .yolov10 import YOLOv10\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\models\\yolov10\\__init__.py\", line 1, in <module>\n",
      "    from .model import YOLOv10\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\models\\yolov10\\model.py\", line 7, in <module>\n",
      "    from huggingface_hub import PyTorchModelHubMixin\n",
      "ModuleNotFoundError: No module named 'huggingface_hub'\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.25 save=True model=../weights/yolov10n.pt source=test_images/1.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e462510b-2fed-4c57-aa9d-67cc0b779a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 567, in entrypoint\n",
      "    model = YOLOv10(model)\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\models\\yolov10\\model.py\", line 14, in __init__\n",
      "    super().__init__(model=model, task=task, verbose=verbose)\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 141, in __init__\n",
      "    self._load(model, task=task)\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 230, in _load\n",
      "    self.model, self.ckpt = attempt_load_one_weight(weights)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py\", line 807, in attempt_load_one_weight\n",
      "    ckpt, weight = torch_safe_load(weight)  # load ckpt\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py\", line 733, in torch_safe_load\n",
      "    ckpt = torch.load(file, map_location=\"cpu\")\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py\", line 1065, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py\", line 468, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py\", line 449, in __init__\n",
      "    super().__init__(open(name, mode))\n",
      "                     ^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '..\\\\weights\\\\yolov10n.pt'\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.25 save=True model=../weights/yolov10n.pt source=test_images/1.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f84c5158-eb10-4efc-bc90-ec0f74256deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "YOLOv10n summary (fused): 285 layers, 2762608 parameters, 63840 gradients, 8.6 GFLOPs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 594, in entrypoint\n",
      "    getattr(model, mode)(**overrides)  # default args from model\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 441, in predict\n",
      "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\predictor.py\", line 177, in predict_cli\n",
      "    for _ in gen:  # noqa, running CLI inference without accumulating any outputs (do not modify)\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_contextlib.py\", line 36, in generator_context\n",
      "    response = gen.send(None)\n",
      "               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\predictor.py\", line 220, in stream_inference\n",
      "    self.setup_source(source if source is not None else self.args.source)\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\predictor.py\", line 192, in setup_source\n",
      "    self.dataset = load_inference_source(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\data\\build.py\", line 181, in load_inference_source\n",
      "    dataset = LoadImagesAndVideos(source, batch=batch, vid_stride=vid_stride)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\data\\loaders.py\", line 292, in __init__\n",
      "    raise FileNotFoundError(f\"{p} does not exist\")\n",
      "FileNotFoundError: test_images/1.jpg does not exist\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.25 save=True model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights/yolov10n.pt source=test_images/1.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ee58f62-0c90-4c81-a4ad-491c43811856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "YOLOv10n summary (fused): 285 layers, 2762608 parameters, 63840 gradients, 8.6 GFLOPs\n",
      "\n",
      "Downloading https://gratisography.com/wp-content/uploads/2024/01/gratisography-cyber-kitty-800x525.jpg to 'gratisography-cyber-kitty-800x525.jpg'...\n",
      "image 1/1 C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\gratisography-cyber-kitty-800x525.jpg: 448x640 1 15, 1 59, 56.4ms\n",
      "Speed: 2.1ms preprocess, 56.4ms inference, 59.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\predict3\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n",
      "\n",
      "0.00B [00:00, ?B/s]\n",
      "73.6kB [00:00, 91.6kB/s]\n",
      "73.6kB [00:00, 91.6kB/s]\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.25 save=True model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt source=https://gratisography.com/wp-content/uploads/2024/01/gratisography-cyber-kitty-800x525.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbffb090-4ce0-4917-9241-7c35d638e346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/c/Users/sshiv/Desktop/sihProject/yolov10\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f901f8ed-bb2b-42fe-a5b5-af6e7edb6bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.81 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt, data=sihProject\\custom_dataset\\dataset\\data.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, val_period=1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=C:\\Users\\sshiv\\runs\\detect\\train2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 138, in __init__\n",
      "    self.data = check_det_dataset(self.args.data)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\data\\utils.py\", line 267, in check_det_dataset\n",
      "    file = check_file(dataset)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\utils\\checks.py\", line 500, in check_file\n",
      "    raise FileNotFoundError(f\"'{file}' does not exist\")\n",
      "FileNotFoundError: 'sihProject\\custom_dataset\\dataset\\data.yaml' does not exist\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 594, in entrypoint\n",
      "    getattr(model, mode)(**overrides)  # default args from model\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 638, in train\n",
      "    self.trainer = (trainer or self._smart_load(\"trainer\"))(overrides=args, _callbacks=self.callbacks)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 142, in __init__\n",
      "    raise RuntimeError(emojis(f\"Dataset '{clean_url(self.args.data)}' error \\u274c {e}\")) from e\n",
      "RuntimeError: Dataset 'sihProject/custom_dataset/dataset/data.yaml' error  'sihProject\\custom_dataset\\dataset\\data.yaml' does not exist\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=train epochs=100 batch=16 plots=True model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt data=sihProject\\custom_dataset\\dataset\\data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3d01aa2-a4c5-4391-8a7f-211ec683bf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is 20FD-A684\n",
      "\n",
      " Directory of C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\n",
      "\n",
      "24-08-2024  20:04    <DIR>          .\n",
      "24-08-2024  21:34    <DIR>          ..\n",
      "24-08-2024  08:43             2,468 .gitignore\n",
      "24-08-2024  08:43             2,391 .pre-commit-config.yaml\n",
      "24-08-2024  08:43             5,688 app.py\n",
      "24-08-2024  08:45    <DIR>          build\n",
      "24-08-2024  08:43             5,681 CONTRIBUTING.md\n",
      "24-08-2024  08:43    <DIR>          docker\n",
      "24-08-2024  08:43    <DIR>          docs\n",
      "24-08-2024  08:43    <DIR>          examples\n",
      "24-08-2024  08:43    <DIR>          figures\n",
      "24-08-2024  08:43               219 flops.py\n",
      "24-08-2024  20:04            75,348 gratisography-cyber-kitty-800x525.jpg\n",
      "24-08-2024  08:43            35,184 LICENSE\n",
      "24-08-2024  08:43    <DIR>          logs\n",
      "24-08-2024  08:43            32,631 mkdocs.yml\n",
      "24-08-2024  08:43             7,003 pyproject.toml\n",
      "24-08-2024  08:43            12,545 README.md\n",
      "24-08-2024  08:43               281 requirements.txt\n",
      "24-08-2024  08:43    <DIR>          tests\n",
      "24-08-2024  08:43    <DIR>          ultralytics\n",
      "24-08-2024  08:45    <DIR>          ultralytics.egg-info\n",
      "24-08-2024  08:53    <DIR>          weights\n",
      "24-08-2024  20:01            54,613 zoo-8378189_640.jpg\n",
      "              12 File(s)        234,052 bytes\n",
      "              12 Dir(s)  113,081,503,744 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c2b18b3-527f-4afb-a380-2573d83c0526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\Desktop\\sihProject\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "555e9668-04b7-4c0f-bdfd-376f40709e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is 20FD-A684\n",
      "\n",
      " Directory of C:\\Users\\sshiv\\Desktop\\sihProject\n",
      "\n",
      "24-08-2024  21:34    <DIR>          .\n",
      "24-08-2024  08:42    <DIR>          ..\n",
      "24-08-2024  08:42    <DIR>          .ipynb_checkpoints\n",
      "24-08-2024  18:38    <DIR>          custom_dataset\n",
      "24-08-2024  21:20               332 data.yml\n",
      "24-08-2024  18:34    <DIR>          test_images\n",
      "24-08-2024  21:33            55,116 Untitled.ipynb\n",
      "24-08-2024  20:04    <DIR>          yolov10\n",
      "               2 File(s)         55,448 bytes\n",
      "               6 Dir(s)  113,055,526,912 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9568059e-f068-46d6-a42d-e8dfab226f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.81 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt, data=C:\\Users\\sshiv\\Desktop\\sihProject\\data.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, val_period=1, cache=False, device=None, workers=8, project=None, name=train4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=C:\\Users\\sshiv\\runs\\detect\\train4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 138, in __init__\n",
      "    self.data = check_det_dataset(self.args.data)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\data\\utils.py\", line 267, in check_det_dataset\n",
      "    file = check_file(dataset)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\utils\\checks.py\", line 500, in check_file\n",
      "    raise FileNotFoundError(f\"'{file}' does not exist\")\n",
      "FileNotFoundError: 'C:\\Users\\sshiv\\Desktop\\sihProject\\data.yaml' does not exist\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 594, in entrypoint\n",
      "    getattr(model, mode)(**overrides)  # default args from model\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 638, in train\n",
      "    self.trainer = (trainer or self._smart_load(\"trainer\"))(overrides=args, _callbacks=self.callbacks)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 142, in __init__\n",
      "    raise RuntimeError(emojis(f\"Dataset '{clean_url(self.args.data)}' error \\u274c {e}\")) from e\n",
      "RuntimeError: Dataset 'C://Users/sshiv/Desktop/sihProject/data.yaml' error  'C:\\Users\\sshiv\\Desktop\\sihProject\\data.yaml' does not exist\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=train epochs=10  plots=True model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt data=C:\\Users\\sshiv\\Desktop\\sihProject\\data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eeac8381-e12c-4f57-9169-ca5f2ca9376c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (8.1.34)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (3.8.2)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (10.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (1.14.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (2.4.0+cu118)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (0.19.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (4.66.5)\n",
      "Requirement already satisfied: psutil in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (6.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: thop>=0.1.1 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (2.1.4)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (69.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f8ae9b7-5b64-44e5-9167-e1334165ed2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt, data=C:\\Users\\sshiv\\Desktop\\sihProject\\data.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, val_period=1, cache=False, device=None, workers=8, project=None, name=train5, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=C:\\Users\\sshiv\\runs\\detect\\train5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 138, in __init__\n",
      "    self.data = check_det_dataset(self.args.data)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\data\\utils.py\", line 267, in check_det_dataset\n",
      "    file = check_file(dataset)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\utils\\checks.py\", line 500, in check_file\n",
      "    raise FileNotFoundError(f\"'{file}' does not exist\")\n",
      "FileNotFoundError: 'C:\\Users\\sshiv\\Desktop\\sihProject\\data.yaml' does not exist\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 594, in entrypoint\n",
      "    getattr(model, mode)(**overrides)  # default args from model\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 638, in train\n",
      "    self.trainer = (trainer or self._smart_load(\"trainer\"))(overrides=args, _callbacks=self.callbacks)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 142, in __init__\n",
      "    raise RuntimeError(emojis(f\"Dataset '{clean_url(self.args.data)}' error \\u274c {e}\")) from e\n",
      "RuntimeError: Dataset 'C://Users/sshiv/Desktop/sihProject/data.yaml' error  'C:\\Users\\sshiv\\Desktop\\sihProject\\data.yaml' does not exist\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=train epochs=10  plots=True model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt data=C:\\Users\\sshiv\\Desktop\\sihProject\\data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f65b1bf7-bc22-4cd2-a08f-ef9f1ab71a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt, data=C:\\\\Users\\sshiv\\Desktop\\sihProject\\data.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, val_period=1, cache=False, device=None, workers=8, project=None, name=train6, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=C:\\Users\\sshiv\\runs\\detect\\train6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 138, in __init__\n",
      "    self.data = check_det_dataset(self.args.data)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\data\\utils.py\", line 267, in check_det_dataset\n",
      "    file = check_file(dataset)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\utils\\checks.py\", line 500, in check_file\n",
      "    raise FileNotFoundError(f\"'{file}' does not exist\")\n",
      "FileNotFoundError: 'C:\\\\Users\\sshiv\\Desktop\\sihProject\\data.yaml' does not exist\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 594, in entrypoint\n",
      "    getattr(model, mode)(**overrides)  # default args from model\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 638, in train\n",
      "    self.trainer = (trainer or self._smart_load(\"trainer\"))(overrides=args, _callbacks=self.callbacks)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 142, in __init__\n",
      "    raise RuntimeError(emojis(f\"Dataset '{clean_url(self.args.data)}' error \\u274c {e}\")) from e\n",
      "RuntimeError: Dataset 'C://Users/sshiv/Desktop/sihProject/data.yaml' error  'C:\\\\Users\\sshiv\\Desktop\\sihProject\\data.yaml' does not exist\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=train epochs=10  plots=True model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt data=C:\\\\Users\\sshiv\\Desktop\\sihProject\\data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4b48840-e8b6-4637-8261-426d4802c47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.81 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt, data=C:\\\\Users\\sshiv\\Desktop\\sihProject\\data.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, val_period=1, cache=False, device=None, workers=8, project=None, name=train7, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=C:\\Users\\sshiv\\runs\\detect\\train7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 138, in __init__\n",
      "    self.data = check_det_dataset(self.args.data)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\data\\utils.py\", line 267, in check_det_dataset\n",
      "    file = check_file(dataset)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\utils\\checks.py\", line 500, in check_file\n",
      "    raise FileNotFoundError(f\"'{file}' does not exist\")\n",
      "FileNotFoundError: 'C:\\\\Users\\sshiv\\Desktop\\sihProject\\data.yaml' does not exist\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 594, in entrypoint\n",
      "    getattr(model, mode)(**overrides)  # default args from model\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 638, in train\n",
      "    self.trainer = (trainer or self._smart_load(\"trainer\"))(overrides=args, _callbacks=self.callbacks)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 142, in __init__\n",
      "    raise RuntimeError(emojis(f\"Dataset '{clean_url(self.args.data)}' error \\u274c {e}\")) from e\n",
      "RuntimeError: Dataset 'C://Users/sshiv/Desktop/sihProject/data.yaml' error  'C:\\\\Users\\sshiv\\Desktop\\sihProject\\data.yaml' does not exist\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=train epochs=10  plots=True model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt data=C:\\\\Users\\sshiv\\Desktop\\sihProject\\data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a44da417-5c51-4d93-ae47-05b9018e5859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.81 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt, data=C:\\Users\\sshiv\\Desktop\\sihProject\\data.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, val_period=1, cache=False, device=None, workers=8, project=None, name=train8, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=C:\\Users\\sshiv\\runs\\detect\\train8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 138, in __init__\n",
      "    self.data = check_det_dataset(self.args.data)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\data\\utils.py\", line 267, in check_det_dataset\n",
      "    file = check_file(dataset)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\utils\\checks.py\", line 500, in check_file\n",
      "    raise FileNotFoundError(f\"'{file}' does not exist\")\n",
      "FileNotFoundError: 'C:\\Users\\sshiv\\Desktop\\sihProject\\data.yaml' does not exist\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 594, in entrypoint\n",
      "    getattr(model, mode)(**overrides)  # default args from model\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 638, in train\n",
      "    self.trainer = (trainer or self._smart_load(\"trainer\"))(overrides=args, _callbacks=self.callbacks)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 142, in __init__\n",
      "    raise RuntimeError(emojis(f\"Dataset '{clean_url(self.args.data)}' error \\u274c {e}\")) from e\n",
      "RuntimeError: Dataset 'C://Users/sshiv/Desktop/sihProject/data.yaml' error  'C:\\Users\\sshiv\\Desktop\\sihProject\\data.yaml' does not exist\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=train epochs=10  plots=True model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt data=C:\\Users\\sshiv\\Desktop\\sihProject\\data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d82a1cb7-c46c-450e-95ad-c808728268ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.81 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt, data=C:\\Users\\sshiv\\Desktop\\sihProject\\data.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, val_period=1, cache=False, device=None, workers=8, project=None, name=train9, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=C:\\Users\\sshiv\\runs\\detect\\train9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 138, in __init__\n",
      "    self.data = check_det_dataset(self.args.data)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\data\\utils.py\", line 267, in check_det_dataset\n",
      "    file = check_file(dataset)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\utils\\checks.py\", line 500, in check_file\n",
      "    raise FileNotFoundError(f\"'{file}' does not exist\")\n",
      "FileNotFoundError: 'C:\\Users\\sshiv\\Desktop\\sihProject\\data.yaml' does not exist\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 594, in entrypoint\n",
      "    getattr(model, mode)(**overrides)  # default args from model\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 638, in train\n",
      "    self.trainer = (trainer or self._smart_load(\"trainer\"))(overrides=args, _callbacks=self.callbacks)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 142, in __init__\n",
      "    raise RuntimeError(emojis(f\"Dataset '{clean_url(self.args.data)}' error \\u274c {e}\")) from e\n",
      "RuntimeError: Dataset 'C://Users/sshiv/Desktop/sihProject/data.yaml' error  'C:\\Users\\sshiv\\Desktop\\sihProject\\data.yaml' does not exist\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=train epochs=10  plots=True model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt data=C:\\Users\\sshiv\\Desktop\\sihProject\\data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8dd97371-9f25-4f0d-93ef-27ba5ee7f83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.81 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt, data=C:\\Users\\sshiv\\Desktop\\sihProject\\data.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, val_period=1, cache=False, device=None, workers=8, project=None, name=train10, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=C:\\Users\\sshiv\\runs\\detect\\train10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 138, in __init__\n",
      "    self.data = check_det_dataset(self.args.data)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\data\\utils.py\", line 267, in check_det_dataset\n",
      "    file = check_file(dataset)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\utils\\checks.py\", line 500, in check_file\n",
      "    raise FileNotFoundError(f\"'{file}' does not exist\")\n",
      "FileNotFoundError: 'C:\\Users\\sshiv\\Desktop\\sihProject\\data.yaml' does not exist\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 594, in entrypoint\n",
      "    getattr(model, mode)(**overrides)  # default args from model\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 638, in train\n",
      "    self.trainer = (trainer or self._smart_load(\"trainer\"))(overrides=args, _callbacks=self.callbacks)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 142, in __init__\n",
      "    raise RuntimeError(emojis(f\"Dataset '{clean_url(self.args.data)}' error \\u274c {e}\")) from e\n",
      "RuntimeError: Dataset 'C://Users/sshiv/Desktop/sihProject/data.yaml' error  'C:\\Users\\sshiv\\Desktop\\sihProject\\data.yaml' does not exist\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=train epochs=10  plots=True model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt data=C:\\Users\\sshiv\\Desktop\\sihProject\\data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a38d2ad5-a0a9-4e6b-b237-26104b01b057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.81 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt, data=C:/Users/sshiv/Desktop/sihProject/data.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, val_period=1, cache=False, device=None, workers=8, project=None, name=train11, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=C:\\Users\\sshiv\\runs\\detect\\train11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 138, in __init__\n",
      "    self.data = check_det_dataset(self.args.data)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\data\\utils.py\", line 267, in check_det_dataset\n",
      "    file = check_file(dataset)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\utils\\checks.py\", line 500, in check_file\n",
      "    raise FileNotFoundError(f\"'{file}' does not exist\")\n",
      "FileNotFoundError: 'C:/Users/sshiv/Desktop/sihProject/data.yaml' does not exist\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 594, in entrypoint\n",
      "    getattr(model, mode)(**overrides)  # default args from model\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 638, in train\n",
      "    self.trainer = (trainer or self._smart_load(\"trainer\"))(overrides=args, _callbacks=self.callbacks)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 142, in __init__\n",
      "    raise RuntimeError(emojis(f\"Dataset '{clean_url(self.args.data)}' error \\u274c {e}\")) from e\n",
      "RuntimeError: Dataset 'C://Users/sshiv/Desktop/sihProject/data.yaml' error  'C:/Users/sshiv/Desktop/sihProject/data.yaml' does not exist\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=train epochs=10  plots=True model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt data=C:/Users/sshiv/Desktop/sihProject/data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7000ba48-af8e-40e1-b6b0-30facacdf9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.81 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt, data=C:/Users/sshiv/Desktop/sihProject/data.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, val_period=1, cache=False, device=None, workers=8, project=None, name=train12, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=C:\\Users\\sshiv\\runs\\detect\\train12\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to 'C:\\Users\\sshiv\\AppData\\Roaming\\yolov10\\Arial.ttf'...\n",
      "Overriding model.yaml nc=80 with nc=9\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1      9856  ultralytics.nn.modules.block.SCDown          [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.PSA             [256, 256]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 20                  -1  1     18048  ultralytics.nn.modules.block.SCDown          [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    282624  ultralytics.nn.modules.block.C2fCIB          [384, 256, 1, True, True]     \n",
      " 23        [16, 19, 22]  1    864838  ultralytics.nn.modules.head.v10Detect        [9, [64, 128, 256]]           \n",
      "YOLOv10n summary: 385 layers, 2710550 parameters, 2710534 gradients, 8.4 GFLOPs\n",
      "\n",
      "Transferred 493/595 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n",
      "\n",
      "  0%|          | 0.00/755k [00:00<?, ?B/s]\n",
      " 17%|#6        | 128k/755k [00:00<00:02, 225kB/s]\n",
      " 34%|###3      | 256k/755k [00:01<00:02, 192kB/s]\n",
      " 51%|#####     | 384k/755k [00:02<00:02, 178kB/s]\n",
      " 68%|######7   | 512k/755k [00:03<00:01, 163kB/s]\n",
      " 85%|########4 | 640k/755k [00:03<00:00, 156kB/s]\n",
      "100%|##########| 755k/755k [00:04<00:00, 173kB/s]\n",
      "100%|##########| 755k/755k [00:04<00:00, 173kB/s]\n",
      "\n",
      "  0%|          | 0.00/6.23M [00:00<?, ?B/s]\n",
      "  2%|2         | 128k/6.23M [00:00<00:37, 172kB/s]\n",
      "  4%|4         | 256k/6.23M [00:01<00:27, 224kB/s]\n",
      "  6%|6         | 384k/6.23M [00:01<00:29, 212kB/s]\n",
      "  8%|8         | 512k/6.23M [00:02<00:30, 198kB/s]\n",
      " 10%|#         | 640k/6.23M [00:03<00:35, 167kB/s]\n",
      " 12%|#2        | 768k/6.23M [00:04<00:32, 175kB/s]\n",
      " 14%|#4        | 896k/6.23M [00:04<00:28, 195kB/s]\n",
      " 16%|#6        | 1.00M/6.23M [00:06<00:35, 154kB/s]\n",
      " 18%|#8        | 1.12M/6.23M [00:07<00:38, 140kB/s]\n",
      " 20%|##        | 1.25M/6.23M [00:07<00:34, 152kB/s]\n",
      " 22%|##2       | 1.38M/6.23M [00:08<00:31, 163kB/s]\n",
      " 24%|##4       | 1.50M/6.23M [00:09<00:27, 180kB/s]\n",
      " 26%|##6       | 1.62M/6.23M [00:09<00:28, 170kB/s]\n",
      " 28%|##8       | 1.75M/6.23M [00:10<00:26, 176kB/s]\n",
      " 30%|###       | 1.88M/6.23M [00:11<00:24, 184kB/s]\n",
      " 32%|###2      | 2.00M/6.23M [00:11<00:23, 186kB/s]\n",
      " 34%|###4      | 2.12M/6.23M [00:12<00:23, 184kB/s]\n",
      " 36%|###6      | 2.25M/6.23M [00:13<00:26, 155kB/s]\n",
      " 38%|###8      | 2.38M/6.23M [00:14<00:25, 160kB/s]\n",
      " 40%|####      | 2.50M/6.23M [00:15<00:22, 175kB/s]\n",
      " 42%|####2     | 2.62M/6.23M [00:15<00:21, 176kB/s]\n",
      " 44%|####4     | 2.75M/6.23M [00:16<00:21, 170kB/s]\n",
      " 46%|####6     | 2.88M/6.23M [00:17<00:20, 171kB/s]\n",
      " 48%|####8     | 3.00M/6.23M [00:18<00:18, 180kB/s]\n",
      " 50%|#####     | 3.12M/6.23M [00:18<00:16, 198kB/s]\n",
      " 52%|#####2    | 3.25M/6.23M [00:19<00:18, 171kB/s]\n",
      " 54%|#####4    | 3.38M/6.23M [00:20<00:17, 172kB/s]\n",
      " 56%|#####6    | 3.50M/6.23M [00:21<00:16, 176kB/s]\n",
      " 58%|#####8    | 3.62M/6.23M [00:21<00:15, 177kB/s]\n",
      " 60%|######    | 3.75M/6.23M [00:23<00:17, 150kB/s]\n",
      " 62%|######2   | 3.88M/6.23M [00:23<00:15, 156kB/s]\n",
      " 64%|######4   | 4.00M/6.23M [00:24<00:14, 164kB/s]\n",
      " 66%|######6   | 4.12M/6.23M [00:25<00:14, 148kB/s]\n",
      " 68%|######8   | 4.25M/6.23M [00:26<00:13, 153kB/s]\n",
      " 70%|#######   | 4.38M/6.23M [00:27<00:12, 157kB/s]\n",
      " 72%|#######2  | 4.50M/6.23M [00:27<00:10, 167kB/s]\n",
      " 74%|#######4  | 4.62M/6.23M [00:28<00:09, 172kB/s]\n",
      " 76%|#######6  | 4.75M/6.23M [00:29<00:08, 192kB/s]\n",
      " 78%|#######8  | 4.88M/6.23M [00:29<00:06, 203kB/s]\n",
      " 80%|########  | 5.00M/6.23M [00:30<00:07, 165kB/s]\n",
      " 82%|########2 | 5.12M/6.23M [00:31<00:07, 146kB/s]\n",
      " 84%|########4 | 5.25M/6.23M [00:32<00:06, 158kB/s]\n",
      " 86%|########6 | 5.38M/6.23M [00:33<00:05, 167kB/s]\n",
      " 88%|########8 | 5.50M/6.23M [00:34<00:05, 151kB/s]\n",
      " 90%|######### | 5.62M/6.23M [00:35<00:03, 160kB/s]\n",
      " 92%|#########2| 5.75M/6.23M [00:35<00:03, 159kB/s]\n",
      " 94%|#########4| 5.88M/6.23M [00:36<00:02, 153kB/s]\n",
      " 96%|#########6| 6.00M/6.23M [00:37<00:01, 160kB/s]\n",
      " 98%|#########8| 6.12M/6.23M [00:38<00:00, 171kB/s]\n",
      "100%|##########| 6.23M/6.23M [00:38<00:00, 187kB/s]\n",
      "100%|##########| 6.23M/6.23M [00:38<00:00, 169kB/s]\n",
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 594, in entrypoint\n",
      "    getattr(model, mode)(**overrides)  # default args from model\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 657, in train\n",
      "    self.trainer.train()\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 213, in train\n",
      "    self._do_train(world_size)\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 327, in _do_train\n",
      "    self._setup_train(world_size)\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 271, in _setup_train\n",
      "    self.amp = torch.tensor(check_amp(self.model), device=self.device)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\utils\\checks.py\", line 653, in check_amp\n",
      "    assert amp_allclose(YOLO(\"yolov8n.pt\"), im)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\utils\\checks.py\", line 640, in amp_allclose\n",
      "    a = m(im, device=device, verbose=False)[0].boxes.data  # FP32 inference\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 166, in __call__\n",
      "    return self.predict(source, stream, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 441, in predict\n",
      "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
      "                                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\predictor.py\", line 168, in __call__\n",
      "    return list(self.stream_inference(source, model, *args, **kwargs))  # merge list of Result into one\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_contextlib.py\", line 36, in generator_context\n",
      "    response = gen.send(None)\n",
      "               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\predictor.py\", line 255, in stream_inference\n",
      "    self.results = self.postprocess(preds, im, im0s)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\models\\yolo\\detect\\predict.py\", line 25, in postprocess\n",
      "    preds = ops.non_max_suppression(\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\utils\\ops.py\", line 282, in non_max_suppression\n",
      "    i = torchvision.ops.nms(boxes, scores, iou_thres)  # NMS\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\ops\\boxes.py\", line 41, in nms\n",
      "    return torch.ops.torchvision.nms(boxes, scores, iou_threshold)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_ops.py\", line 1061, in __call__\n",
      "    return self_._op(*args, **(kwargs or {}))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "NotImplementedError: Could not run 'torchvision::nms' with arguments from the 'CUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'torchvision::nms' is only available for these backends: [CPU, Meta, QuantizedCPU, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMeta, Tracer, AutocastCPU, AutocastXPU, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n",
      "\n",
      "CPU: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\cpu\\nms_kernel.cpp:112 [kernel]\n",
      "Meta: registered at /dev/null:154 [kernel]\n",
      "QuantizedCPU: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\quantized\\cpu\\qnms_kernel.cpp:124 [kernel]\n",
      "BackendSelect: fallthrough registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\BackendSelectFallbackKernel.cpp:3 [backend fallback]\n",
      "Python: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:153 [backend fallback]\n",
      "FuncTorchDynamicLayerBackMode: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\functorch\\DynamicLayer.cpp:497 [backend fallback]\n",
      "Functionalize: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\FunctionalizeFallbackKernel.cpp:349 [backend fallback]\n",
      "Named: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\NamedRegistrations.cpp:7 [backend fallback]\n",
      "Conjugate: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\ConjugateFallback.cpp:17 [backend fallback]\n",
      "Negative: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\NegateFallback.cpp:18 [backend fallback]\n",
      "ZeroTensor: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\ZeroTensorFallback.cpp:86 [backend fallback]\n",
      "ADInplaceOrView: fallthrough registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:86 [backend fallback]\n",
      "AutogradOther: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:53 [backend fallback]\n",
      "AutogradCPU: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:57 [backend fallback]\n",
      "AutogradCUDA: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:65 [backend fallback]\n",
      "AutogradXLA: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:69 [backend fallback]\n",
      "AutogradMPS: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:77 [backend fallback]\n",
      "AutogradXPU: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:61 [backend fallback]\n",
      "AutogradHPU: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:90 [backend fallback]\n",
      "AutogradLazy: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:73 [backend fallback]\n",
      "AutogradMeta: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:81 [backend fallback]\n",
      "Tracer: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\autograd\\TraceTypeManual.cpp:297 [backend fallback]\n",
      "AutocastCPU: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\autocast\\nms_kernel.cpp:34 [kernel]\n",
      "AutocastXPU: fallthrough registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\autocast_mode.cpp:351 [backend fallback]\n",
      "AutocastCUDA: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\autocast\\nms_kernel.cpp:27 [kernel]\n",
      "FuncTorchBatched: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\functorch\\LegacyBatchingRegistrations.cpp:731 [backend fallback]\n",
      "BatchedNestedTensor: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\functorch\\LegacyBatchingRegistrations.cpp:758 [backend fallback]\n",
      "FuncTorchVmapMode: fallthrough registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\functorch\\VmapModeRegistrations.cpp:27 [backend fallback]\n",
      "Batched: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\LegacyBatchingRegistrations.cpp:1075 [backend fallback]\n",
      "VmapMode: fallthrough registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\VmapModeRegistrations.cpp:33 [backend fallback]\n",
      "FuncTorchGradWrapper: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\functorch\\TensorWrapper.cpp:207 [backend fallback]\n",
      "PythonTLSSnapshot: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:161 [backend fallback]\n",
      "FuncTorchDynamicLayerFrontMode: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\functorch\\DynamicLayer.cpp:493 [backend fallback]\n",
      "PreDispatch: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:165 [backend fallback]\n",
      "PythonDispatcher: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:157 [backend fallback]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=train epochs=10  plots=True model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt data=C:/Users/sshiv/Desktop/sihProject/data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3f2a29d1-904d-4b47-9a62-7c07be32222b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.81 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt, data=C:/Users/sshiv/Desktop/sihProject/data.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, val_period=1, cache=False, device=None, workers=8, project=None, name=train13, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=C:\\Users\\sshiv\\runs\\detect\\train13\n",
      "Overriding model.yaml nc=80 with nc=9\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1      9856  ultralytics.nn.modules.block.SCDown          [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.PSA             [256, 256]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 20                  -1  1     18048  ultralytics.nn.modules.block.SCDown          [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    282624  ultralytics.nn.modules.block.C2fCIB          [384, 256, 1, True, True]     \n",
      " 23        [16, 19, 22]  1    864838  ultralytics.nn.modules.head.v10Detect        [9, [64, 128, 256]]           \n",
      "YOLOv10n summary: 385 layers, 2710550 parameters, 2710534 gradients, 8.4 GFLOPs\n",
      "\n",
      "Transferred 493/595 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸� C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\train\\images\\IMG_20240413_011606.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸� C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\train\\images\\IMG_20240414_005657.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸� C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\train\\images\\IMG_20240414_005942.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\train\\labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸� C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\valid\\images\\IMG_20240413_011606.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸� C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\valid\\images\\IMG_20240414_005657.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸� C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\valid\\images\\IMG_20240414_005942.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\valid\\labels.cache\n",
      "Plotting labels to C:\\Users\\sshiv\\runs\\detect\\train13\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000769, momentum=0.9) with parameter groups 95 weight(decay=0.0), 108 weight(decay=0.0005), 107 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\train13\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00425     0.0648     0.0119    0.00488\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00509     0.0648     0.0104    0.00438\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00603     0.0648    0.00736    0.00323\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00571     0.0556     0.0081    0.00421\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00417     0.0278    0.00712    0.00428\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00337     0.0185    0.00661    0.00449\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00383     0.0185    0.00683    0.00497\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00427     0.0185      0.007    0.00565\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00529     0.0185    0.00742    0.00608\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00347    0.00926    0.00631    0.00568\n",
      "\n",
      "10 epochs completed in 0.031 hours.\n",
      "Optimizer stripped from C:\\Users\\sshiv\\runs\\detect\\train13\\weights\\last.pt, 5.8MB\n",
      "Optimizer stripped from C:\\Users\\sshiv\\runs\\detect\\train13\\weights\\best.pt, 5.8MB\n",
      "\n",
      "Validating C:\\Users\\sshiv\\runs\\detect\\train13\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "                   all         12         25    0.00542     0.0185     0.0075    0.00613\n",
      "             Shivanshu         12         12     0.0488      0.167     0.0675     0.0552\n",
      "                 Sumit         12          3          0          0          0          0\n",
      "              Yashwant         12          4          0          0          0          0\n",
      "                  Aman         12          1          0          0          0          0\n",
      "                Krishn         12          1          0          0          0          0\n",
      "                Aviral         12          1          0          0          0          0\n",
      "              Gurpreet         12          1          0          0          0          0\n",
      "               Shreyas         12          1          0          0          0          0\n",
      "                 Shubh         12          1          0          0          0          0\n",
      "Speed: 4.3ms preprocess, 156.5ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\train13\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n",
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:276: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\train\\labels...:   0%|          | 0/12 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\train\\labels... 7 images, 0 backgrounds, 0 corrupt:  58%|#####8    | 7/12 [00:00<00:00, 46.99it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\train\\labels... 12 images, 0 backgrounds, 0 corrupt: 100%|##########| 12/12 [00:00<00:00, 80.55it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\valid\\labels...:   0%|          | 0/12 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\valid\\labels... 7 images, 0 backgrounds, 0 corrupt:  58%|#####8    | 7/12 [00:00<00:00, 66.37it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\valid\\labels... 12 images, 0 backgrounds, 0 corrupt: 100%|##########| 12/12 [00:00<00:00, 113.78it/s]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "       1/10         0G      1.922      4.697      1.941       1.69      8.683      1.721         25        640:   0%|          | 0/1 [00:08<?, ?it/s]\n",
      "       1/10         0G      1.922      4.697      1.941       1.69      8.683      1.721         25        640: 100%|##########| 1/1 [00:08<00:00,  8.38s/it]\n",
      "       1/10         0G      1.922      4.697      1.941       1.69      8.683      1.721         25        640: 100%|##########| 1/1 [00:08<00:00,  8.38s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.65s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.65s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "       2/10         0G      1.914      4.743      1.948      1.665      8.732      1.633         25        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "       2/10         0G      1.914      4.743      1.948      1.665      8.732      1.633         25        640: 100%|##########| 1/1 [00:06<00:00,  6.68s/it]\n",
      "       2/10         0G      1.914      4.743      1.948      1.665      8.732      1.633         25        640: 100%|##########| 1/1 [00:06<00:00,  6.69s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.45s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.46s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "       3/10         0G      1.816      4.588      1.845      1.623      8.519      1.637         25        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "       3/10         0G      1.816      4.588      1.845      1.623      8.519      1.637         25        640: 100%|##########| 1/1 [00:06<00:00,  6.69s/it]\n",
      "       3/10         0G      1.816      4.588      1.845      1.623      8.519      1.637         25        640: 100%|##########| 1/1 [00:06<00:00,  6.69s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.61s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.61s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "       4/10         0G      1.829      4.678      1.943      1.729      8.818      1.715         25        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "       4/10         0G      1.829      4.678      1.943      1.729      8.818      1.715         25        640: 100%|##########| 1/1 [00:07<00:00,  7.05s/it]\n",
      "       4/10         0G      1.829      4.678      1.943      1.729      8.818      1.715         25        640: 100%|##########| 1/1 [00:07<00:00,  7.05s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.51s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.51s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "       5/10         0G      1.797      4.476      1.718      1.551      8.429      1.511         25        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "       5/10         0G      1.797      4.476      1.718      1.551      8.429      1.511         25        640: 100%|##########| 1/1 [00:06<00:00,  6.73s/it]\n",
      "       5/10         0G      1.797      4.476      1.718      1.551      8.429      1.511         25        640: 100%|##########| 1/1 [00:06<00:00,  6.73s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.51s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.51s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "       6/10         0G      1.782       4.65       1.87      1.476      8.509      1.534         25        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "       6/10         0G      1.782       4.65       1.87      1.476      8.509      1.534         25        640: 100%|##########| 1/1 [00:07<00:00,  7.03s/it]\n",
      "       6/10         0G      1.782       4.65       1.87      1.476      8.509      1.534         25        640: 100%|##########| 1/1 [00:07<00:00,  7.03s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.66s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.66s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "       7/10         0G      1.645      4.447      1.804      1.352      8.304      1.519         25        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "       7/10         0G      1.645      4.447      1.804      1.352      8.304      1.519         25        640: 100%|##########| 1/1 [00:06<00:00,  6.66s/it]\n",
      "       7/10         0G      1.645      4.447      1.804      1.352      8.304      1.519         25        640: 100%|##########| 1/1 [00:06<00:00,  6.66s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.55s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.55s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "       8/10         0G      1.734      4.568      1.647      1.413      8.516      1.395         25        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "       8/10         0G      1.734      4.568      1.647      1.413      8.516      1.395         25        640: 100%|##########| 1/1 [00:06<00:00,  6.82s/it]\n",
      "       8/10         0G      1.734      4.568      1.647      1.413      8.516      1.395         25        640: 100%|##########| 1/1 [00:06<00:00,  6.82s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.57s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.57s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "       9/10         0G      1.515      4.313       1.57      1.103      8.252      1.363         24        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "       9/10         0G      1.515      4.313       1.57      1.103      8.252      1.363         24        640: 100%|##########| 1/1 [00:06<00:00,  6.99s/it]\n",
      "       9/10         0G      1.515      4.313       1.57      1.103      8.252      1.363         24        640: 100%|##########| 1/1 [00:06<00:00,  6.99s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.68s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.68s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "      10/10         0G      1.532       4.32      1.534      1.225       8.22      1.353         25        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      10/10         0G      1.532       4.32      1.534      1.225       8.22      1.353         25        640: 100%|##########| 1/1 [00:07<00:00,  7.02s/it]\n",
      "      10/10         0G      1.532       4.32      1.534      1.225       8.22      1.353         25        640: 100%|##########| 1/1 [00:07<00:00,  7.02s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.73s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.73s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:02<00:00,  2.93s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:02<00:00,  2.93s/it]\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=train epochs=10  plots=True model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt data=C:/Users/sshiv/Desktop/sihProject/data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8f00c64a-d348-46b5-ad26-0045f061cc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "image 1/1 C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\3.jpg: 640x384 (no detections), 90.4ms\n",
      "Speed: 4.1ms preprocess, 90.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\predict5\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.25 save=True model=C:\\Users\\sshiv\\runs\\detect\\train13\\weights\\best.pt source=test_images/3.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f06c310d-1af6-4ac7-9e68-da445820f151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "New https://pypi.org/project/ultralytics/8.2.81 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt, data=C:/Users/sshiv/Desktop/sihProject/data.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, val_period=1, cache=False, device=None, workers=8, project=None, name=train14, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=C:\\Users\\sshiv\\runs\\detect\\train14\n",
      "Overriding model.yaml nc=80 with nc=9\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1      9856  ultralytics.nn.modules.block.SCDown          [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.PSA             [256, 256]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 20                  -1  1     18048  ultralytics.nn.modules.block.SCDown          [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    282624  ultralytics.nn.modules.block.C2fCIB          [384, 256, 1, True, True]     \n",
      " 23        [16, 19, 22]  1    864838  ultralytics.nn.modules.head.v10Detect        [9, [64, 128, 256]]           \n",
      "YOLOv10n summary: 385 layers, 2710550 parameters, 2710534 gradients, 8.4 GFLOPs\n",
      "\n",
      "Transferred 493/595 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸� C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\train\\images\\IMG_20240413_011606.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸� C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\train\\images\\IMG_20240414_005657.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸� C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\train\\images\\IMG_20240414_005942.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸� C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\valid\\images\\IMG_20240413_011606.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸� C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\valid\\images\\IMG_20240414_005657.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸� C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\valid\\images\\IMG_20240414_005942.jpg: corrupt JPEG restored and saved\n",
      "Plotting labels to C:\\Users\\sshiv\\runs\\detect\\train14\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000769, momentum=0.9) with parameter groups 95 weight(decay=0.0), 108 weight(decay=0.0005), 107 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\train14\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00403     0.0648     0.0118    0.00485\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25     0.0049     0.0648     0.0121    0.00493\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00572     0.0648     0.0106    0.00489\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00458      0.037    0.00629    0.00307\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00388     0.0278    0.00685    0.00365\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00274     0.0185    0.00617    0.00354\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00304     0.0185     0.0047    0.00299\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00182    0.00926    0.00241    0.00166\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00364     0.0185    0.00439    0.00239\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25     0.0167     0.0648     0.0295    0.00835\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25     0.0181     0.0648     0.0258     0.0107\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25      0.017     0.0741     0.0264     0.0135\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25     0.0078      0.037     0.0196     0.0168\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00775      0.148     0.0175     0.0132\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25      0.041      0.111     0.0471     0.0282\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25     0.0232     0.0833     0.0372     0.0262\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25     0.0302      0.231     0.0415     0.0316\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25     0.0302      0.231     0.0415     0.0316\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25     0.0217      0.231       0.04     0.0306\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25     0.0217      0.231       0.04     0.0306\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25      0.015      0.241     0.0403     0.0318\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25      0.015      0.241     0.0403     0.0318\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25      0.013      0.241     0.0487     0.0405\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25      0.013      0.241     0.0487     0.0405\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00995      0.241     0.0636     0.0553\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00995      0.241     0.0636     0.0553\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00826      0.352     0.0747     0.0654\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00826      0.352     0.0747     0.0654\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00805      0.361     0.0758     0.0666\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00805      0.361     0.0758     0.0666\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00772      0.361     0.0768     0.0641\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00772      0.361     0.0768     0.0641\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00701      0.361     0.0747     0.0617\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00701      0.361     0.0747     0.0617\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00702       0.37      0.081     0.0661\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00702       0.37      0.081     0.0661\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00842      0.407     0.0947     0.0754\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00842      0.407     0.0947     0.0754\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00809      0.407      0.109     0.0876\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00809      0.407      0.109     0.0876\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00744      0.407      0.112     0.0911\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00744      0.407      0.112     0.0911\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00714      0.407      0.113     0.0921\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00714      0.407      0.113     0.0921\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00746      0.435      0.115     0.0958\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00746      0.435      0.115     0.0958\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00711      0.435      0.116     0.0976\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00711      0.435      0.116     0.0976\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00673      0.435      0.118        0.1\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         12         25    0.00673      0.435      0.118        0.1\n",
      "\n",
      "50 epochs completed in 0.161 hours.\n",
      "Optimizer stripped from C:\\Users\\sshiv\\runs\\detect\\train14\\weights\\last.pt, 5.8MB\n",
      "Optimizer stripped from C:\\Users\\sshiv\\runs\\detect\\train14\\weights\\best.pt, 5.8MB\n",
      "\n",
      "Validating C:\\Users\\sshiv\\runs\\detect\\train14\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "                   all         12         25    0.00675      0.435      0.118        0.1\n",
      "             Shivanshu         12         12     0.0254      0.833      0.532      0.464\n",
      "                 Sumit         12          3     0.0167      0.333     0.0171     0.0137\n",
      "              Yashwant         12          4     0.0169       0.75      0.502      0.414\n",
      "                  Aman         12          1          0          0          0          0\n",
      "                Krishn         12          1   0.000888          1    0.00513     0.0031\n",
      "                Aviral         12          1          0          0          0          0\n",
      "              Gurpreet         12          1          0          0          0          0\n",
      "               Shreyas         12          1          0          0          0          0\n",
      "                 Shubh         12          1   0.000935          1    0.00816    0.00571\n",
      "Speed: 4.6ms preprocess, 162.2ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\train14\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n",
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:276: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\train\\labels.cache... 12 images, 0 backgrounds, 0 corrupt: 100%|##########| 12/12 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\train\\labels.cache... 12 images, 0 backgrounds, 0 corrupt: 100%|##########| 12/12 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\valid\\labels.cache... 12 images, 0 backgrounds, 0 corrupt: 100%|##########| 12/12 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\valid\\labels.cache... 12 images, 0 backgrounds, 0 corrupt: 100%|##########| 12/12 [00:00<?, ?it/s]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "       1/50         0G      1.823      4.417       1.77       1.48      6.832      1.535         39        640:   0%|          | 0/1 [00:10<?, ?it/s]\n",
      "       1/50         0G      1.823      4.417       1.77       1.48      6.832      1.535         39        640: 100%|##########| 1/1 [00:10<00:00, 10.16s/it]\n",
      "       1/50         0G      1.823      4.417       1.77       1.48      6.832      1.535         39        640: 100%|##########| 1/1 [00:10<00:00, 10.16s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.45s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.45s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "       2/50         0G      1.872        4.5      1.783      1.553      6.731      1.525         44        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "       2/50         0G      1.872        4.5      1.783      1.553      6.731      1.525         44        640: 100%|##########| 1/1 [00:06<00:00,  6.68s/it]\n",
      "       2/50         0G      1.872        4.5      1.783      1.553      6.731      1.525         44        640: 100%|##########| 1/1 [00:06<00:00,  6.68s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.31s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "       3/50         0G      1.743      4.164      1.696      1.549      5.875      1.485         59        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "       3/50         0G      1.743      4.164      1.696      1.549      5.875      1.485         59        640: 100%|##########| 1/1 [00:06<00:00,  6.60s/it]\n",
      "       3/50         0G      1.743      4.164      1.696      1.549      5.875      1.485         59        640: 100%|##########| 1/1 [00:06<00:00,  6.60s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.41s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.41s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "       4/50         0G      1.658      4.456      1.749      1.446      7.055      1.568         36        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "       4/50         0G      1.658      4.456      1.749      1.446      7.055      1.568         36        640: 100%|##########| 1/1 [00:06<00:00,  6.79s/it]\n",
      "       4/50         0G      1.658      4.456      1.749      1.446      7.055      1.568         36        640: 100%|##########| 1/1 [00:06<00:00,  6.79s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.54s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.54s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "       5/50         0G      1.683      4.409      1.535      1.533      6.579      1.338         47        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "       5/50         0G      1.683      4.409      1.535      1.533      6.579      1.338         47        640: 100%|##########| 1/1 [00:06<00:00,  6.88s/it]\n",
      "       5/50         0G      1.683      4.409      1.535      1.533      6.579      1.338         47        640: 100%|##########| 1/1 [00:06<00:00,  6.88s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.38s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.38s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "       6/50         0G      1.766      4.247      1.717      1.586      6.225      1.476         50        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "       6/50         0G      1.766      4.247      1.717      1.586      6.225      1.476         50        640: 100%|##########| 1/1 [00:06<00:00,  6.71s/it]\n",
      "       6/50         0G      1.766      4.247      1.717      1.586      6.225      1.476         50        640: 100%|##########| 1/1 [00:06<00:00,  6.71s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.67s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.67s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "       7/50         0G      1.504      4.244      1.513      1.366      6.408      1.349         43        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "       7/50         0G      1.504      4.244      1.513      1.366      6.408      1.349         43        640: 100%|##########| 1/1 [00:07<00:00,  7.92s/it]\n",
      "       7/50         0G      1.504      4.244      1.513      1.366      6.408      1.349         43        640: 100%|##########| 1/1 [00:07<00:00,  7.92s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.94s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.94s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "       8/50         0G      1.572      4.139      1.631      1.282      7.019      1.482         34        640:   0%|          | 0/1 [00:11<?, ?it/s]\n",
      "       8/50         0G      1.572      4.139      1.631      1.282      7.019      1.482         34        640: 100%|##########| 1/1 [00:11<00:00, 11.07s/it]\n",
      "       8/50         0G      1.572      4.139      1.631      1.282      7.019      1.482         34        640: 100%|##########| 1/1 [00:11<00:00, 11.07s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.72s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.72s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "       9/50         0G      1.691      4.288      1.626       1.46      6.167       1.35         50        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "       9/50         0G      1.691      4.288      1.626       1.46      6.167       1.35         50        640: 100%|##########| 1/1 [00:07<00:00,  7.75s/it]\n",
      "       9/50         0G      1.691      4.288      1.626       1.46      6.167       1.35         50        640: 100%|##########| 1/1 [00:07<00:00,  7.75s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.73s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.73s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "      10/50         0G      1.397      4.122      1.398      1.294      5.872      1.335         55        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      10/50         0G      1.397      4.122      1.398      1.294      5.872      1.335         55        640: 100%|##########| 1/1 [00:07<00:00,  7.39s/it]\n",
      "      10/50         0G      1.397      4.122      1.398      1.294      5.872      1.335         55        640: 100%|##########| 1/1 [00:07<00:00,  7.39s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.67s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.67s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "      11/50         0G      1.374      4.065      1.341      1.286       5.76      1.216         55        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      11/50         0G      1.374      4.065      1.341      1.286       5.76      1.216         55        640: 100%|##########| 1/1 [00:07<00:00,  7.44s/it]\n",
      "      11/50         0G      1.374      4.065      1.341      1.286       5.76      1.216         55        640: 100%|##########| 1/1 [00:07<00:00,  7.44s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.66s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.66s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "      12/50         0G       1.39      3.936      1.422      1.158      6.153      1.372         42        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      12/50         0G       1.39      3.936      1.422      1.158      6.153      1.372         42        640: 100%|##########| 1/1 [00:07<00:00,  7.92s/it]\n",
      "      12/50         0G       1.39      3.936      1.422      1.158      6.153      1.372         42        640: 100%|##########| 1/1 [00:07<00:00,  7.92s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.59s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.59s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "      13/50         0G      1.151      3.914      1.196      1.099      6.247      1.157         39        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      13/50         0G      1.151      3.914      1.196      1.099      6.247      1.157         39        640: 100%|##########| 1/1 [00:07<00:00,  7.61s/it]\n",
      "      13/50         0G      1.151      3.914      1.196      1.099      6.247      1.157         39        640: 100%|##########| 1/1 [00:07<00:00,  7.61s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.62s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.62s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "      14/50         0G      1.373      4.079      1.259      1.199      5.937      1.166         52        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "      14/50         0G      1.373      4.079      1.259      1.199      5.937      1.166         52        640: 100%|##########| 1/1 [00:06<00:00,  7.00s/it]\n",
      "      14/50         0G      1.373      4.079      1.259      1.199      5.937      1.166         52        640: 100%|##########| 1/1 [00:06<00:00,  7.00s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.82s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.82s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "      15/50         0G      1.236      3.788      1.267      1.099      5.664      1.193         49        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      15/50         0G      1.236      3.788      1.267      1.099      5.664      1.193         49        640: 100%|##########| 1/1 [00:07<00:00,  7.36s/it]\n",
      "      15/50         0G      1.236      3.788      1.267      1.099      5.664      1.193         49        640: 100%|##########| 1/1 [00:07<00:00,  7.36s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.70s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.70s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "      16/50         0G      1.115      3.761      1.223      1.032      5.548       1.18         48        640:   0%|          | 0/1 [00:09<?, ?it/s]\n",
      "      16/50         0G      1.115      3.761      1.223      1.032      5.548       1.18         48        640: 100%|##########| 1/1 [00:09<00:00,  9.84s/it]\n",
      "      16/50         0G      1.115      3.761      1.223      1.032      5.548       1.18         48        640: 100%|##########| 1/1 [00:09<00:00,  9.84s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.68s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.68s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "      17/50         0G      1.286      3.908      1.282      1.171      6.742      1.232         32        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      17/50         0G      1.286      3.908      1.282      1.171      6.742      1.232         32        640: 100%|##########| 1/1 [00:07<00:00,  7.72s/it]\n",
      "      17/50         0G      1.286      3.908      1.282      1.171      6.742      1.232         32        640: 100%|##########| 1/1 [00:07<00:00,  7.72s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.63s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.63s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "      18/50         0G      1.308      3.863       1.22      1.184      5.722      1.141         48        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      18/50         0G      1.308      3.863       1.22      1.184      5.722      1.141         48        640: 100%|##########| 1/1 [00:07<00:00,  7.13s/it]\n",
      "      18/50         0G      1.308      3.863       1.22      1.184      5.722      1.141         48        640: 100%|##########| 1/1 [00:07<00:00,  7.13s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.51s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.51s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "      19/50         0G       1.13      3.673      1.133      1.041       5.19      1.088         56        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      19/50         0G       1.13      3.673      1.133      1.041       5.19      1.088         56        640: 100%|##########| 1/1 [00:07<00:00,  7.32s/it]\n",
      "      19/50         0G       1.13      3.673      1.133      1.041       5.19      1.088         56        640: 100%|##########| 1/1 [00:07<00:00,  7.32s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.66s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.66s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "      20/50         0G      1.147      3.601      1.185      1.089      4.842      1.134         63        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      20/50         0G      1.147      3.601      1.185      1.089      4.842      1.134         63        640: 100%|##########| 1/1 [00:07<00:00,  7.30s/it]\n",
      "      20/50         0G      1.147      3.601      1.185      1.089      4.842      1.134         63        640: 100%|##########| 1/1 [00:07<00:00,  7.30s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.80s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.80s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "      21/50         0G      1.225      3.734      1.284       1.05      5.563      1.133         47        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      21/50         0G      1.225      3.734      1.284       1.05      5.563      1.133         47        640: 100%|##########| 1/1 [00:07<00:00,  7.25s/it]\n",
      "      21/50         0G      1.225      3.734      1.284       1.05      5.563      1.133         47        640: 100%|##########| 1/1 [00:07<00:00,  7.25s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.82s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.82s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "      22/50         0G      1.074      3.573      1.087     0.9861        4.8      1.053         62        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      22/50         0G      1.074      3.573      1.087     0.9861        4.8      1.053         62        640: 100%|##########| 1/1 [00:07<00:00,  7.04s/it]\n",
      "      22/50         0G      1.074      3.573      1.087     0.9861        4.8      1.053         62        640: 100%|##########| 1/1 [00:07<00:00,  7.04s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.72s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.72s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "      23/50         0G      1.132      3.555      1.136      1.079      5.158      1.114         50        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      23/50         0G      1.132      3.555      1.136      1.079      5.158      1.114         50        640: 100%|##########| 1/1 [00:07<00:00,  7.29s/it]\n",
      "      23/50         0G      1.132      3.555      1.136      1.079      5.158      1.114         50        640: 100%|##########| 1/1 [00:07<00:00,  7.29s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.64s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.64s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "      24/50         0G      1.382      3.613      1.229      1.292      5.237      1.146         56        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      24/50         0G      1.382      3.613      1.229      1.292      5.237      1.146         56        640: 100%|##########| 1/1 [00:07<00:00,  7.48s/it]\n",
      "      24/50         0G      1.382      3.613      1.229      1.292      5.237      1.146         56        640: 100%|##########| 1/1 [00:07<00:00,  7.48s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.74s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.74s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "      25/50         0G      1.274      3.365      1.283      1.065      5.615      1.136         39        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      25/50         0G      1.274      3.365      1.283      1.065      5.615      1.136         39        640: 100%|##########| 1/1 [00:07<00:00,  7.46s/it]\n",
      "      25/50         0G      1.274      3.365      1.283      1.065      5.615      1.136         39        640: 100%|##########| 1/1 [00:07<00:00,  7.46s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.67s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.67s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "      26/50         0G      1.059      3.512      1.132     0.9621      5.311      1.091         44        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      26/50         0G      1.059      3.512      1.132     0.9621      5.311      1.091         44        640: 100%|##########| 1/1 [00:07<00:00,  7.15s/it]\n",
      "      26/50         0G      1.059      3.512      1.132     0.9621      5.311      1.091         44        640: 100%|##########| 1/1 [00:07<00:00,  7.15s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.66s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.66s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "      27/50         0G      1.223      3.224       1.36      1.106      5.985      1.263         33        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      27/50         0G      1.223      3.224       1.36      1.106      5.985      1.263         33        640: 100%|##########| 1/1 [00:07<00:00,  7.49s/it]\n",
      "      27/50         0G      1.223      3.224       1.36      1.106      5.985      1.263         33        640: 100%|##########| 1/1 [00:07<00:00,  7.49s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.83s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.83s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "      28/50         0G      1.286      3.212      1.279      1.057       5.43      1.169         41        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      28/50         0G      1.286      3.212      1.279      1.057       5.43      1.169         41        640: 100%|##########| 1/1 [00:07<00:00,  7.24s/it]\n",
      "      28/50         0G      1.286      3.212      1.279      1.057       5.43      1.169         41        640: 100%|##########| 1/1 [00:07<00:00,  7.24s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.96s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.96s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "      29/50         0G      1.111      3.421      1.156       1.04      4.692      1.131         62        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      29/50         0G      1.111      3.421      1.156       1.04      4.692      1.131         62        640: 100%|##########| 1/1 [00:07<00:00,  7.31s/it]\n",
      "      29/50         0G      1.111      3.421      1.156       1.04      4.692      1.131         62        640: 100%|##########| 1/1 [00:07<00:00,  7.31s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.73s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.73s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "      30/50         0G      1.191      3.462      1.193      1.135      6.216      1.162         33        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      30/50         0G      1.191      3.462      1.193      1.135      6.216      1.162         33        640: 100%|##########| 1/1 [00:07<00:00,  7.30s/it]\n",
      "      30/50         0G      1.191      3.462      1.193      1.135      6.216      1.162         33        640: 100%|##########| 1/1 [00:07<00:00,  7.30s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.51s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.51s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "      31/50         0G       1.18      3.488      1.158      1.148      5.272      1.119         47        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      31/50         0G       1.18      3.488      1.158      1.148      5.272      1.119         47        640: 100%|##########| 1/1 [00:07<00:00,  7.66s/it]\n",
      "      31/50         0G       1.18      3.488      1.158      1.148      5.272      1.119         47        640: 100%|##########| 1/1 [00:07<00:00,  7.66s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.89s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.89s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "      32/50         0G      1.066      3.149      1.198     0.9621      4.805      1.172         50        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      32/50         0G      1.066      3.149      1.198     0.9621      4.805      1.172         50        640: 100%|##########| 1/1 [00:07<00:00,  7.47s/it]\n",
      "      32/50         0G      1.066      3.149      1.198     0.9621      4.805      1.172         50        640: 100%|##########| 1/1 [00:07<00:00,  7.47s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.80s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.80s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "      33/50         0G      1.071      3.087      1.168      1.026      5.545       1.09         34        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      33/50         0G      1.071      3.087      1.168      1.026      5.545       1.09         34        640: 100%|##########| 1/1 [00:07<00:00,  7.28s/it]\n",
      "      33/50         0G      1.071      3.087      1.168      1.026      5.545       1.09         34        640: 100%|##########| 1/1 [00:07<00:00,  7.28s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.82s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.82s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "      34/50         0G     0.9324      2.766      1.126     0.8714      5.316      1.102         35        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      34/50         0G     0.9324      2.766      1.126     0.8714      5.316      1.102         35        640: 100%|##########| 1/1 [00:07<00:00,  7.01s/it]\n",
      "      34/50         0G     0.9324      2.766      1.126     0.8714      5.316      1.102         35        640: 100%|##########| 1/1 [00:07<00:00,  7.01s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.85s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.85s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "      35/50         0G      1.162      3.285       1.11     0.9568      4.745      1.024         57        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      35/50         0G      1.162      3.285       1.11     0.9568      4.745      1.024         57        640: 100%|##########| 1/1 [00:07<00:00,  7.41s/it]\n",
      "      35/50         0G      1.162      3.285       1.11     0.9568      4.745      1.024         57        640: 100%|##########| 1/1 [00:07<00:00,  7.41s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.92s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.92s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "      36/50         0G      1.004      3.262      1.019     0.9645      4.883     0.9553         50        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      36/50         0G      1.004      3.262      1.019     0.9645      4.883     0.9553         50        640: 100%|##########| 1/1 [00:07<00:00,  7.41s/it]\n",
      "      36/50         0G      1.004      3.262      1.019     0.9645      4.883     0.9553         50        640: 100%|##########| 1/1 [00:07<00:00,  7.41s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.69s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.69s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "      37/50         0G      1.049      2.939      1.141      1.017      5.251      1.081         40        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      37/50         0G      1.049      2.939      1.141      1.017      5.251      1.081         40        640: 100%|##########| 1/1 [00:07<00:00,  7.33s/it]\n",
      "      37/50         0G      1.049      2.939      1.141      1.017      5.251      1.081         40        640: 100%|##########| 1/1 [00:07<00:00,  7.33s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.77s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.77s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "      38/50         0G      1.093      3.214      1.079       1.08      4.648      1.034         58        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      38/50         0G      1.093      3.214      1.079       1.08      4.648      1.034         58        640: 100%|##########| 1/1 [00:07<00:00,  7.26s/it]\n",
      "      38/50         0G      1.093      3.214      1.079       1.08      4.648      1.034         58        640: 100%|##########| 1/1 [00:07<00:00,  7.26s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.66s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.66s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "      39/50         0G      1.152      3.045       1.15      1.009      5.588      1.098         38        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      39/50         0G      1.152      3.045       1.15      1.009      5.588      1.098         38        640: 100%|##########| 1/1 [00:07<00:00,  7.20s/it]\n",
      "      39/50         0G      1.152      3.045       1.15      1.009      5.588      1.098         38        640: 100%|##########| 1/1 [00:07<00:00,  7.20s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.82s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.82s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "      40/50         0G       1.14      2.987      1.157      1.107      5.068      1.134         43        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      40/50         0G       1.14      2.987      1.157      1.107      5.068      1.134         43        640: 100%|##########| 1/1 [00:07<00:00,  7.06s/it]\n",
      "      40/50         0G       1.14      2.987      1.157      1.107      5.068      1.134         43        640: 100%|##########| 1/1 [00:07<00:00,  7.06s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.83s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.83s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "      41/50         0G      1.143      3.103      1.142      1.015      7.179      1.068         25        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      41/50         0G      1.143      3.103      1.142      1.015      7.179      1.068         25        640: 100%|##########| 1/1 [00:07<00:00,  7.15s/it]\n",
      "      41/50         0G      1.143      3.103      1.142      1.015      7.179      1.068         25        640: 100%|##########| 1/1 [00:07<00:00,  7.15s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.86s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.86s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "      42/50         0G     0.9978       3.01      1.072     0.9053      6.832      1.063         25        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      42/50         0G     0.9978       3.01      1.072     0.9053      6.832      1.063         25        640: 100%|##########| 1/1 [00:07<00:00,  7.00s/it]\n",
      "      42/50         0G     0.9978       3.01      1.072     0.9053      6.832      1.063         25        640: 100%|##########| 1/1 [00:07<00:00,  7.00s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.90s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.90s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "      43/50         0G      1.047       2.79      1.053     0.9787      6.696      1.022         25        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      43/50         0G      1.047       2.79      1.053     0.9787      6.696      1.022         25        640: 100%|##########| 1/1 [00:07<00:00,  7.02s/it]\n",
      "      43/50         0G      1.047       2.79      1.053     0.9787      6.696      1.022         25        640: 100%|##########| 1/1 [00:07<00:00,  7.02s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.88s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.88s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "      44/50         0G       0.88      2.883      1.003     0.8369      6.839     0.9478         25        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      44/50         0G       0.88      2.883      1.003     0.8369      6.839     0.9478         25        640: 100%|##########| 1/1 [00:07<00:00,  7.24s/it]\n",
      "      44/50         0G       0.88      2.883      1.003     0.8369      6.839     0.9478         25        640: 100%|##########| 1/1 [00:07<00:00,  7.24s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.67s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.67s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "      45/50         0G     0.9571      2.943      1.111     0.9072      6.728      1.029         25        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      45/50         0G     0.9571      2.943      1.111     0.9072      6.728      1.029         25        640: 100%|##########| 1/1 [00:07<00:00,  7.38s/it]\n",
      "      45/50         0G     0.9571      2.943      1.111     0.9072      6.728      1.029         25        640: 100%|##########| 1/1 [00:07<00:00,  7.38s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.66s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.66s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "      46/50         0G      1.014      2.974       1.07      1.064      7.108     0.9985         25        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      46/50         0G      1.014      2.974       1.07      1.064      7.108     0.9985         25        640: 100%|##########| 1/1 [00:07<00:00,  7.04s/it]\n",
      "      46/50         0G      1.014      2.974       1.07      1.064      7.108     0.9985         25        640: 100%|##########| 1/1 [00:07<00:00,  7.04s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.81s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.81s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "      47/50         0G       0.97      2.956      1.091     0.9514      6.768      1.069         25        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      47/50         0G       0.97      2.956      1.091     0.9514      6.768      1.069         25        640: 100%|##########| 1/1 [00:07<00:00,  7.10s/it]\n",
      "      47/50         0G       0.97      2.956      1.091     0.9514      6.768      1.069         25        640: 100%|##########| 1/1 [00:07<00:00,  7.10s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.90s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.90s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "      48/50         0G     0.8768      3.008     0.9789     0.7039      6.783     0.8601         25        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      48/50         0G     0.8768      3.008     0.9789     0.7039      6.783     0.8601         25        640: 100%|##########| 1/1 [00:07<00:00,  7.33s/it]\n",
      "      48/50         0G     0.8768      3.008     0.9789     0.7039      6.783     0.8601         25        640: 100%|##########| 1/1 [00:07<00:00,  7.33s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.85s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.85s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "      49/50         0G     0.9621      2.972      1.021      1.052      6.712      1.036         25        640:   0%|          | 0/1 [00:07<?, ?it/s]\n",
      "      49/50         0G     0.9621      2.972      1.021      1.052      6.712      1.036         25        640: 100%|##########| 1/1 [00:07<00:00,  7.07s/it]\n",
      "      49/50         0G     0.9621      2.972      1.021      1.052      6.712      1.036         25        640: 100%|##########| 1/1 [00:07<00:00,  7.07s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.79s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.79s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "      50/50         0G     0.8977      2.844       1.03     0.8631      6.312     0.9012         25        640:   0%|          | 0/1 [00:06<?, ?it/s]\n",
      "      50/50         0G     0.8977      2.844       1.03     0.8631      6.312     0.9012         25        640: 100%|##########| 1/1 [00:06<00:00,  6.88s/it]\n",
      "      50/50         0G     0.8977      2.844       1.03     0.8631      6.312     0.9012         25        640: 100%|##########| 1/1 [00:06<00:00,  6.88s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.71s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.71s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.06s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 1/1 [00:03<00:00,  3.06s/it]\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=train epochs=50 batch=16  plots=True model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt data=C:/Users/sshiv/Desktop/sihProject/data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "13df5cbb-71a9-4920-9276-6ca4b9bd0129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=train epochs=50 batch=16  plots=True model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt data=C:/Users/sshiv/Desktop/sihProject/data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5f2f6e56-aac2-4f01-bb98-7d1397485bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=train epochs=50 batch=16  plots=True model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt data=C:/Users/sshiv/Desktop/sihProject/data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f4685948-ebe6-4832-a36f-1bfa7f42a851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 567, in entrypoint\n",
      "    model = YOLOv10(model)\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\models\\yolov10\\model.py\", line 14, in __init__\n",
      "    super().__init__(model=model, task=task, verbose=verbose)\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 141, in __init__\n",
      "    self._load(model, task=task)\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 230, in _load\n",
      "    self.model, self.ckpt = attempt_load_one_weight(weights)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py\", line 807, in attempt_load_one_weight\n",
      "    ckpt, weight = torch_safe_load(weight)  # load ckpt\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py\", line 733, in torch_safe_load\n",
      "    ckpt = torch.load(file, map_location=\"cpu\")\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py\", line 1065, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py\", line 468, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py\", line 449, in __init__\n",
      "    super().__init__(open(name, mode))\n",
      "                     ^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\sshiv\\\\runs\\\\detect\\\\train15\\\\weightsbest.pt'\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.25 save=True model=C:\\Users\\sshiv\\runs\\detect\\train15\\weightsbest.pt source=test_images/3.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240e3d4d-dcee-429c-8fea-129a6a8bfebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo task=detect mode=train epochs=25 batch=16  plots=True model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt data=C:/Users/sshiv/Desktop/sihProject/data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b9ff180-6b7c-47be-92cb-a9b2c0d6e1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "image 1/1 C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\3.jpg: 640x384 (no detections), 78.0ms\n",
      "Speed: 4.1ms preprocess, 78.0ms inference, 10.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\predict6\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.25 save=True model=C:\\Users\\sshiv\\runs\\detect\\train17\\weights\\best.pt source=test_images/3.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a39261a8-0e8f-4fcd-8f28-44a4807fe086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "image 1/1 C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\4.jpg: 384x640 (no detections), 79.7ms\n",
      "Speed: 3.0ms preprocess, 79.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\predict7\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.25 save=True model=C:\\Users\\sshiv\\runs\\detect\\train17\\weights\\best.pt source=test_images/4.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd9fc678-feff-4cf4-a4a0-26d3fdbe3a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "image 1/1 C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\5.jpg: 640x480 (no detections), 100.4ms\n",
      "Speed: 3.1ms preprocess, 100.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\predict2\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.25 save=True model=C:\\Users\\sshiv\\runs\\detect\\train17\\weights\\best.pt source=test_images/5.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9180bd4-043f-4df4-b444-1f6833be0d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "image 1/1 C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\5.jpg: 640x480 (no detections), 102.0ms\n",
      "Speed: 2.1ms preprocess, 102.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\predict3\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.05 save=True model=C:\\Users\\sshiv\\runs\\detect\\train17\\weights\\best.pt source=test_images/5.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2f0bc66-bf90-42f9-9c04-bfc6cb7e7a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=train epochs=50 batch=16  plots=True model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt data=C:/Users/sshiv/Desktop/sihProject/data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd968a46-8215-4def-8d69-aad89ad1e41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.81 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt, data=C:/Users/sshiv/Desktop/sihProject/data.yaml, epochs=10, time=None, patience=100, batch=10, imgsz=640, save=True, save_period=-1, val_period=1, cache=False, device=None, workers=8, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=C:\\Users\\sshiv\\runs\\detect\\train3\n",
      "Overriding model.yaml nc=80 with nc=9\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1      9856  ultralytics.nn.modules.block.SCDown          [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.PSA             [256, 256]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 20                  -1  1     18048  ultralytics.nn.modules.block.SCDown          [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    282624  ultralytics.nn.modules.block.C2fCIB          [384, 256, 1, True, True]     \n",
      " 23        [16, 19, 22]  1    864838  ultralytics.nn.modules.head.v10Detect        [9, [64, 128, 256]]           \n",
      "YOLOv10n summary: 385 layers, 2710550 parameters, 2710534 gradients, 8.4 GFLOPs\n",
      "\n",
      "Transferred 493/595 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸� C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\train\\images\\IMG_20240413_011606.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸� C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\train\\images\\IMG_20240414_005657.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸� C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\train\\images\\IMG_20240414_005942.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸� C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\valid\\images\\IMG_20240413_011606.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸� C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\valid\\images\\IMG_20240414_005657.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸� C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\valid\\images\\IMG_20240414_005942.jpg: corrupt JPEG restored and saved\n",
      "Plotting labels to C:\\Users\\sshiv\\runs\\detect\\train3\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000769, momentum=0.9) with parameter groups 95 weight(decay=0.0), 108 weight(decay=0.00046875), 107 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\train3\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         96        150     0.0124      0.131     0.0141    0.00565\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         96        150     0.0164      0.456     0.0414     0.0218\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         96        150    0.00911      0.645     0.0479     0.0284\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         96        150    0.00695      0.806     0.0622     0.0317\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         96        150    0.00594      0.936     0.0768     0.0427\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         96        150    0.00561      0.872     0.0723     0.0395\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         96        150    0.00512      0.847     0.0988     0.0517\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         96        150      0.581      0.165     0.0931     0.0466\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         96        150      0.858     0.0533      0.112     0.0524\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         96        150      0.964      0.026      0.116      0.069\n",
      "\n",
      "10 epochs completed in 0.379 hours.\n",
      "Optimizer stripped from C:\\Users\\sshiv\\runs\\detect\\train3\\weights\\last.pt, 5.7MB\n",
      "Optimizer stripped from C:\\Users\\sshiv\\runs\\detect\\train3\\weights\\best.pt, 5.7MB\n",
      "\n",
      "Validating C:\\Users\\sshiv\\runs\\detect\\train3\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "                   all         96        150      0.964     0.0259      0.116     0.0689\n",
      "             Shivanshu         96         79      0.672      0.233      0.519      0.323\n",
      "                 Sumit         96         33          1          0      0.166      0.103\n",
      "              Yashwant         96         12          1          0     0.0311     0.0161\n",
      "                  Aman         96          4          1          0     0.0365     0.0215\n",
      "                Krishn         96          4          1          0    0.00457    0.00242\n",
      "                Aviral         96          4          1          0     0.0129    0.00769\n",
      "              Gurpreet         96          5          1          0     0.0518     0.0276\n",
      "               Shreyas         96          8          1          0      0.219      0.119\n",
      "                 Shubh         96          1          1          0          0          0\n",
      "Speed: 4.9ms preprocess, 207.6ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\train3\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n",
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:276: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\train\\labels.cache... 95 images, 1 backgrounds, 0 corrupt: 100%|##########| 96/96 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\train\\labels.cache... 95 images, 1 backgrounds, 0 corrupt: 100%|##########| 96/96 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\valid\\labels.cache... 95 images, 1 backgrounds, 0 corrupt: 100%|##########| 96/96 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\valid\\labels.cache... 95 images, 1 backgrounds, 0 corrupt: 100%|##########| 96/96 [00:00<?, ?it/s]\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "       1/10         0G      2.005      4.939      2.023      1.573      9.622      1.693         17        640:   0%|          | 0/10 [00:10<?, ?it/s]\n",
      "       1/10         0G      2.005      4.939      2.023      1.573      9.622      1.693         17        640:  10%|#         | 1/10 [00:10<01:31, 10.12s/it]\n",
      "       1/10         0G       1.95      5.373      1.946      1.632      11.44      1.706         11        640:  10%|#         | 1/10 [00:20<01:31, 10.12s/it]\n",
      "       1/10         0G       1.95      5.373      1.946      1.632      11.44      1.706         11        640:  20%|##        | 2/10 [00:20<01:21, 10.20s/it]\n",
      "       1/10         0G      1.933       5.22      1.967      1.623      10.97      1.727         16        640:  20%|##        | 2/10 [00:30<01:21, 10.20s/it]\n",
      "       1/10         0G      1.933       5.22      1.967      1.623      10.97      1.727         16        640:  30%|###       | 3/10 [00:30<01:10, 10.03s/it]\n",
      "       1/10         0G      1.962      5.119      1.971      1.658      10.29      1.723         24        640:  30%|###       | 3/10 [00:40<01:10, 10.03s/it]\n",
      "       1/10         0G      1.962      5.119      1.971      1.658      10.29      1.723         24        640:  40%|####      | 4/10 [00:40<01:01, 10.24s/it]\n",
      "       1/10         0G      2.016      5.123      1.966       1.68      10.47       1.71         14        640:  40%|####      | 4/10 [00:51<01:01, 10.24s/it]\n",
      "       1/10         0G      2.016      5.123      1.966       1.68      10.47       1.71         14        640:  50%|#####     | 5/10 [00:51<00:51, 10.32s/it]\n",
      "       1/10         0G      1.967      5.062       1.95      1.623      10.41      1.672         15        640:  50%|#####     | 5/10 [01:02<00:51, 10.32s/it]\n",
      "       1/10         0G      1.967      5.062       1.95      1.623      10.41      1.672         15        640:  60%|######    | 6/10 [01:02<00:42, 10.55s/it]\n",
      "       1/10         0G      1.992      5.068       1.96      1.621      10.44      1.665         15        640:  60%|######    | 6/10 [01:13<00:42, 10.55s/it]\n",
      "       1/10         0G      1.992      5.068       1.96      1.621      10.44      1.665         15        640:  70%|#######   | 7/10 [01:13<00:31, 10.63s/it]\n",
      "       1/10         0G       1.98      5.036      1.966      1.629      10.49      1.646         14        640:  70%|#######   | 7/10 [01:23<00:31, 10.63s/it]\n",
      "       1/10         0G       1.98      5.036      1.966      1.629      10.49      1.646         14        640:  80%|########  | 8/10 [01:23<00:21, 10.56s/it]\n",
      "       1/10         0G      1.931      4.989      1.919      1.586      10.41      1.614         15        640:  80%|########  | 8/10 [01:33<00:21, 10.56s/it]\n",
      "       1/10         0G      1.931      4.989      1.919      1.586      10.41      1.614         15        640:  90%|######### | 9/10 [01:33<00:10, 10.48s/it]\n",
      "       1/10         0G      1.885      4.966      1.867      1.553      10.36      1.581          9        640:  90%|######### | 9/10 [01:39<00:10, 10.48s/it]\n",
      "       1/10         0G      1.885      4.966      1.867      1.553      10.36      1.581          9        640: 100%|##########| 10/10 [01:39<00:00,  9.13s/it]\n",
      "       1/10         0G      1.885      4.966      1.867      1.553      10.36      1.581          9        640: 100%|##########| 10/10 [01:39<00:00,  9.98s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  20%|##        | 1/5 [00:09<00:37,  9.48s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  40%|####      | 2/5 [00:19<00:29,  9.97s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  60%|######    | 3/5 [00:28<00:18,  9.30s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  80%|########  | 4/5 [00:36<00:08,  8.71s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 5/5 [00:40<00:00,  7.13s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 5/5 [00:40<00:00,  8.09s/it]\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "       2/10         0G      1.756      4.562      1.769      1.487      10.05      1.561         15        640:   0%|          | 0/10 [00:08<?, ?it/s]\n",
      "       2/10         0G      1.756      4.562      1.769      1.487      10.05      1.561         15        640:  10%|#         | 1/10 [00:08<01:19,  8.85s/it]\n",
      "       2/10         0G      1.661      4.507      1.672       1.39       9.46      1.463         18        640:  10%|#         | 1/10 [00:17<01:19,  8.85s/it]\n",
      "       2/10         0G      1.661      4.507      1.672       1.39       9.46      1.463         18        640:  20%|##        | 2/10 [00:17<01:10,  8.83s/it]\n",
      "       2/10         0G      1.563      4.403      1.604      1.277      9.115      1.384         18        640:  20%|##        | 2/10 [00:26<01:10,  8.83s/it]\n",
      "       2/10         0G      1.563      4.403      1.604      1.277      9.115      1.384         18        640:  30%|###       | 3/10 [00:26<01:02,  8.97s/it]\n",
      "       2/10         0G      1.545      4.405      1.577      1.286      9.198      1.363         16        640:  30%|###       | 3/10 [00:36<01:02,  8.97s/it]\n",
      "       2/10         0G      1.545      4.405      1.577      1.286      9.198      1.363         16        640:  40%|####      | 4/10 [00:36<00:56,  9.35s/it]\n",
      "       2/10         0G      1.545      4.403      1.579      1.276      9.193      1.363         17        640:  40%|####      | 4/10 [00:46<00:56,  9.35s/it]\n",
      "       2/10         0G      1.545      4.403      1.579      1.276      9.193      1.363         17        640:  50%|#####     | 5/10 [00:46<00:46,  9.39s/it]\n",
      "       2/10         0G      1.574      4.412      1.582      1.301      9.262      1.377         16        640:  50%|#####     | 5/10 [00:55<00:46,  9.39s/it]\n",
      "       2/10         0G      1.574      4.412      1.582      1.301      9.262      1.377         16        640:  60%|######    | 6/10 [00:55<00:38,  9.53s/it]\n",
      "       2/10         0G      1.571      4.359      1.571      1.305       9.22      1.385         17        640:  60%|######    | 6/10 [01:05<00:38,  9.53s/it]\n",
      "       2/10         0G      1.571      4.359      1.571      1.305       9.22      1.385         17        640:  70%|#######   | 7/10 [01:05<00:28,  9.48s/it]\n",
      "       2/10         0G      1.566      4.365       1.55      1.311      9.294      1.354         15        640:  70%|#######   | 7/10 [01:15<00:28,  9.48s/it]\n",
      "       2/10         0G      1.566      4.365       1.55      1.311      9.294      1.354         15        640:  80%|########  | 8/10 [01:15<00:19,  9.72s/it]\n",
      "       2/10         0G      1.541      4.385      1.544      1.283      9.757      1.354          9        640:  80%|########  | 8/10 [01:24<00:19,  9.72s/it]\n",
      "       2/10         0G      1.541      4.385      1.544      1.283      9.757      1.354          9        640:  90%|######### | 9/10 [01:24<00:09,  9.57s/it]\n",
      "       2/10         0G      1.517      4.355      1.509       1.27       9.71      1.332          9        640:  90%|######### | 9/10 [01:29<00:09,  9.57s/it]\n",
      "       2/10         0G      1.517      4.355      1.509       1.27       9.71      1.332          9        640: 100%|##########| 10/10 [01:29<00:00,  8.05s/it]\n",
      "       2/10         0G      1.517      4.355      1.509       1.27       9.71      1.332          9        640: 100%|##########| 10/10 [01:29<00:00,  8.95s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  20%|##        | 1/5 [00:09<00:36,  9.11s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  40%|####      | 2/5 [00:18<00:28,  9.56s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  60%|######    | 3/5 [00:26<00:17,  8.72s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  80%|########  | 4/5 [00:34<00:08,  8.22s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 5/5 [00:38<00:00,  6.68s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 5/5 [00:38<00:00,  7.62s/it]\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "       3/10         0G      1.371      3.689      1.409      1.279      7.552      1.285         21        640:   0%|          | 0/10 [00:08<?, ?it/s]\n",
      "       3/10         0G      1.371      3.689      1.409      1.279      7.552      1.285         21        640:  10%|#         | 1/10 [00:08<01:17,  8.61s/it]\n",
      "       3/10         0G      1.458      3.918      1.423      1.353      8.008      1.307         19        640:  10%|#         | 1/10 [00:17<01:17,  8.61s/it]\n",
      "       3/10         0G      1.458      3.918      1.423      1.353      8.008      1.307         19        640:  20%|##        | 2/10 [00:17<01:11,  8.88s/it]\n",
      "       3/10         0G      1.376      3.936      1.453      1.183      9.245      1.265         10        640:  20%|##        | 2/10 [00:25<01:11,  8.88s/it]\n",
      "       3/10         0G      1.376      3.936      1.453      1.183      9.245      1.265         10        640:  30%|###       | 3/10 [00:25<00:58,  8.32s/it]\n",
      "       3/10         0G      1.343      3.887      1.425      1.154      9.014      1.254         17        640:  30%|###       | 3/10 [00:34<00:58,  8.32s/it]\n",
      "       3/10         0G      1.343      3.887      1.425      1.154      9.014      1.254         17        640:  40%|####      | 4/10 [00:34<00:51,  8.65s/it]\n",
      "       3/10         0G      1.355      3.826      1.409      1.169      8.862      1.239         17        640:  40%|####      | 4/10 [00:44<00:51,  8.65s/it]\n",
      "       3/10         0G      1.355      3.826      1.409      1.169      8.862      1.239         17        640:  50%|#####     | 5/10 [00:44<00:45,  9.07s/it]\n",
      "       3/10         0G      1.312      3.788      1.376      1.156      9.042      1.234         12        640:  50%|#####     | 5/10 [00:53<00:45,  9.07s/it]\n",
      "       3/10         0G      1.312      3.788      1.376      1.156      9.042      1.234         12        640:  60%|######    | 6/10 [00:53<00:36,  9.09s/it]\n",
      "       3/10         0G      1.373      3.844      1.388      1.208       9.11      1.248         15        640:  60%|######    | 6/10 [01:03<00:36,  9.09s/it]\n",
      "       3/10         0G      1.373      3.844      1.388      1.208       9.11      1.248         15        640:  70%|#######   | 7/10 [01:03<00:27,  9.32s/it]\n",
      "       3/10         0G      1.377      3.818      1.398      1.198      9.034      1.247         16        640:  70%|#######   | 7/10 [01:14<00:27,  9.32s/it]\n",
      "       3/10         0G      1.377      3.818      1.398      1.198      9.034      1.247         16        640:  80%|########  | 8/10 [01:14<00:19,  9.97s/it]\n",
      "       3/10         0G       1.41      3.783      1.439      1.244      9.035      1.303         15        640:  80%|########  | 8/10 [01:28<00:19,  9.97s/it]\n",
      "       3/10         0G       1.41      3.783      1.439      1.244      9.035      1.303         15        640:  90%|######### | 9/10 [01:28<00:11, 11.22s/it]\n",
      "       3/10         0G      1.441      3.784      1.469      1.265      9.113      1.332          8        640:  90%|######### | 9/10 [01:35<00:11, 11.22s/it]\n",
      "       3/10         0G      1.441      3.784      1.469      1.265      9.113      1.332          8        640: 100%|##########| 10/10 [01:35<00:00,  9.83s/it]\n",
      "       3/10         0G      1.441      3.784      1.469      1.265      9.113      1.332          8        640: 100%|##########| 10/10 [01:35<00:00,  9.53s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  20%|##        | 1/5 [00:09<00:36,  9.23s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  40%|####      | 2/5 [00:19<00:29,  9.88s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  60%|######    | 3/5 [00:28<00:18,  9.43s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  80%|########  | 4/5 [00:36<00:09,  9.01s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 5/5 [00:41<00:00,  7.29s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 5/5 [00:41<00:00,  8.21s/it]\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "       4/10         0G      1.422      3.421      1.556      1.351        8.7      1.384         15        640:   0%|          | 0/10 [00:10<?, ?it/s]\n",
      "       4/10         0G      1.422      3.421      1.556      1.351        8.7      1.384         15        640:  10%|#         | 1/10 [00:10<01:34, 10.46s/it]\n",
      "       4/10         0G      1.311      3.276      1.413      1.195      8.172      1.265         17        640:  10%|#         | 1/10 [00:22<01:34, 10.46s/it]\n",
      "       4/10         0G      1.311      3.276      1.413      1.195      8.172      1.265         17        640:  20%|##        | 2/10 [00:22<01:29, 11.14s/it]\n",
      "       4/10         0G      1.304      3.294       1.38      1.135      7.815      1.231         20        640:  20%|##        | 2/10 [00:32<01:29, 11.14s/it]\n",
      "       4/10         0G      1.304      3.294       1.38      1.135      7.815      1.231         20        640:  30%|###       | 3/10 [00:32<01:15, 10.80s/it]\n",
      "       4/10         0G      1.377      3.318      1.453      1.163      8.159      1.269         14        640:  30%|###       | 3/10 [00:43<01:15, 10.80s/it]\n",
      "       4/10         0G      1.377      3.318      1.453      1.163      8.159      1.269         14        640:  40%|####      | 4/10 [00:43<01:05, 10.95s/it]\n",
      "       4/10         0G      1.416      3.388       1.46      1.208      8.527      1.293         13        640:  40%|####      | 4/10 [00:52<01:05, 10.95s/it]\n",
      "       4/10         0G      1.416      3.388       1.46      1.208      8.527      1.293         13        640:  50%|#####     | 5/10 [00:52<00:51, 10.35s/it]\n",
      "       4/10         0G      1.424      3.428      1.478      1.222      8.994      1.304         10        640:  50%|#####     | 5/10 [01:02<00:51, 10.35s/it]\n",
      "       4/10         0G      1.424      3.428      1.478      1.222      8.994      1.304         10        640:  60%|######    | 6/10 [01:02<00:39,  9.99s/it]\n",
      "       4/10         0G      1.466      3.454      1.511      1.272      9.104      1.367         14        640:  60%|######    | 6/10 [01:11<00:39,  9.99s/it]\n",
      "       4/10         0G      1.466      3.454      1.511      1.272      9.104      1.367         14        640:  70%|#######   | 7/10 [01:11<00:29,  9.88s/it]\n",
      "       4/10         0G      1.507      3.472      1.507      1.297      8.847      1.358         22        640:  70%|#######   | 7/10 [01:20<00:29,  9.88s/it]\n",
      "       4/10         0G      1.507      3.472      1.507      1.297      8.847      1.358         22        640:  80%|########  | 8/10 [01:20<00:19,  9.55s/it]\n",
      "       4/10         0G      1.519      3.466      1.526      1.322      8.894      1.376         14        640:  80%|########  | 8/10 [01:29<00:19,  9.55s/it]\n",
      "       4/10         0G      1.519      3.466      1.526      1.322      8.894      1.376         14        640:  90%|######### | 9/10 [01:29<00:09,  9.45s/it]\n",
      "       4/10         0G      1.577      3.466      1.572      1.388      8.851      1.438         11        640:  90%|######### | 9/10 [01:35<00:09,  9.45s/it]\n",
      "       4/10         0G      1.577      3.466      1.572      1.388      8.851      1.438         11        640: 100%|##########| 10/10 [01:35<00:00,  8.31s/it]\n",
      "       4/10         0G      1.577      3.466      1.572      1.388      8.851      1.438         11        640: 100%|##########| 10/10 [01:35<00:00,  9.57s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  20%|##        | 1/5 [00:08<00:32,  8.20s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  40%|####      | 2/5 [00:17<00:27,  9.09s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  60%|######    | 3/5 [00:25<00:17,  8.53s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  80%|########  | 4/5 [00:33<00:08,  8.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 5/5 [00:37<00:00,  6.70s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 5/5 [00:37<00:00,  7.49s/it]\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "       5/10         0G      1.604      3.002      1.727      1.361       9.52      1.492         13        640:   0%|          | 0/10 [00:08<?, ?it/s]\n",
      "       5/10         0G      1.604      3.002      1.727      1.361       9.52      1.492         13        640:  10%|#         | 1/10 [00:08<01:19,  8.89s/it]\n",
      "       5/10         0G      1.519       3.17      1.577      1.319      9.095       1.38         15        640:  10%|#         | 1/10 [00:17<01:19,  8.89s/it]\n",
      "       5/10         0G      1.519       3.17      1.577      1.319      9.095       1.38         15        640:  20%|##        | 2/10 [00:17<01:11,  8.95s/it]\n",
      "       5/10         0G      1.581      3.156      1.655        1.4      9.027      1.489         15        640:  20%|##        | 2/10 [00:27<01:11,  8.95s/it]\n",
      "       5/10         0G      1.581      3.156      1.655        1.4      9.027      1.489         15        640:  30%|###       | 3/10 [00:27<01:04,  9.26s/it]\n",
      "       5/10         0G      1.557      3.228        1.6      1.357      9.064      1.433         14        640:  30%|###       | 3/10 [00:36<01:04,  9.26s/it]\n",
      "       5/10         0G      1.557      3.228        1.6      1.357      9.064      1.433         14        640:  40%|####      | 4/10 [00:36<00:54,  9.12s/it]\n",
      "       5/10         0G      1.609      3.224      1.585      1.423      8.817      1.399         19        640:  40%|####      | 4/10 [00:46<00:54,  9.12s/it]\n",
      "       5/10         0G      1.609      3.224      1.585      1.423      8.817      1.399         19        640:  50%|#####     | 5/10 [00:46<00:46,  9.32s/it]\n",
      "       5/10         0G      1.638       3.24      1.578      1.453       8.93      1.422         14        640:  50%|#####     | 5/10 [00:55<00:46,  9.32s/it]\n",
      "       5/10         0G      1.638       3.24      1.578      1.453       8.93      1.422         14        640:  60%|######    | 6/10 [00:55<00:37,  9.30s/it]\n",
      "       5/10         0G      1.614      3.217      1.576      1.434      8.956      1.401         14        640:  60%|######    | 6/10 [01:06<00:37,  9.30s/it]\n",
      "       5/10         0G      1.614      3.217      1.576      1.434      8.956      1.401         14        640:  70%|#######   | 7/10 [01:06<00:29,  9.77s/it]\n",
      "       5/10         0G      1.612      3.206       1.55       1.45       8.86      1.378         16        640:  70%|#######   | 7/10 [01:15<00:29,  9.77s/it]\n",
      "       5/10         0G      1.612      3.206       1.55       1.45       8.86      1.378         16        640:  80%|########  | 8/10 [01:15<00:19,  9.79s/it]\n",
      "       5/10         0G      1.604      3.195      1.535      1.468      8.734       1.38         18        640:  80%|########  | 8/10 [01:26<00:19,  9.79s/it]\n",
      "       5/10         0G      1.604      3.195      1.535      1.468      8.734       1.38         18        640:  90%|######### | 9/10 [01:26<00:09,  9.97s/it]\n",
      "       5/10         0G      1.596      3.207       1.51       1.44      8.574      1.345         12        640:  90%|######### | 9/10 [01:31<00:09,  9.97s/it]\n",
      "       5/10         0G      1.596      3.207       1.51       1.44      8.574      1.345         12        640: 100%|##########| 10/10 [01:31<00:00,  8.59s/it]\n",
      "       5/10         0G      1.596      3.207       1.51       1.44      8.574      1.345         12        640: 100%|##########| 10/10 [01:31<00:00,  9.18s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  20%|##        | 1/5 [00:10<00:41, 10.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  40%|####      | 2/5 [00:21<00:32, 10.84s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  60%|######    | 3/5 [00:30<00:19,  9.87s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  80%|########  | 4/5 [00:38<00:09,  9.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 5/5 [00:43<00:00,  7.58s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 5/5 [00:43<00:00,  8.64s/it]\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "       6/10         0G      1.592      2.913      1.504      1.635      8.296      1.594         15        640:   0%|          | 0/10 [00:09<?, ?it/s]\n",
      "       6/10         0G      1.592      2.913      1.504      1.635      8.296      1.594         15        640:  10%|#         | 1/10 [00:09<01:22,  9.17s/it]\n",
      "       6/10         0G      1.553      2.987      1.562      1.451      9.375       1.56         11        640:  10%|#         | 1/10 [00:17<01:22,  9.17s/it]\n",
      "       6/10         0G      1.553      2.987      1.562      1.451      9.375       1.56         11        640:  20%|##        | 2/10 [00:17<01:09,  8.65s/it]\n",
      "       6/10         0G      1.476      3.012      1.458      1.378      8.584      1.417         20        640:  20%|##        | 2/10 [00:26<01:09,  8.65s/it]\n",
      "       6/10         0G      1.476      3.012      1.458      1.378      8.584      1.417         20        640:  30%|###       | 3/10 [00:26<01:01,  8.82s/it]\n",
      "       6/10         0G      1.531      3.023      1.517        1.4      8.797      1.384         13        640:  30%|###       | 3/10 [00:35<01:01,  8.82s/it]\n",
      "       6/10         0G      1.531      3.023      1.517        1.4      8.797      1.384         13        640:  40%|####      | 4/10 [00:35<00:54,  9.08s/it]\n",
      "       6/10         0G      1.489      3.023      1.471      1.381      8.675      1.349         15        640:  40%|####      | 4/10 [00:44<00:54,  9.08s/it]\n",
      "       6/10         0G      1.489      3.023      1.471      1.381      8.675      1.349         15        640:  50%|#####     | 5/10 [00:44<00:43,  8.80s/it]\n",
      "       6/10         0G      1.524      2.969      1.507       1.38       8.64      1.376         14        640:  50%|#####     | 5/10 [00:53<00:43,  8.80s/it]\n",
      "       6/10         0G      1.524      2.969      1.507       1.38       8.64      1.376         14        640:  60%|######    | 6/10 [00:53<00:35,  8.96s/it]\n",
      "       6/10         0G      1.497      2.977      1.506       1.34      8.438      1.353         18        640:  60%|######    | 6/10 [01:03<00:35,  8.96s/it]\n",
      "       6/10         0G      1.497      2.977      1.506       1.34      8.438      1.353         18        640:  70%|#######   | 7/10 [01:03<00:27,  9.17s/it]\n",
      "       6/10         0G      1.498      3.032       1.49      1.325      8.549      1.316         14        640:  70%|#######   | 7/10 [01:12<00:27,  9.17s/it]\n",
      "       6/10         0G      1.498      3.032       1.49      1.325      8.549      1.316         14        640:  80%|########  | 8/10 [01:12<00:18,  9.29s/it]\n",
      "       6/10         0G      1.493      3.076      1.508      1.313      8.512      1.311         16        640:  80%|########  | 8/10 [01:21<00:18,  9.29s/it]\n",
      "       6/10         0G      1.493      3.076      1.508      1.313      8.512      1.311         16        640:  90%|######### | 9/10 [01:21<00:09,  9.21s/it]\n",
      "       6/10         0G      1.525      3.077      1.524       1.36      8.374      1.328         13        640:  90%|######### | 9/10 [01:27<00:09,  9.21s/it]\n",
      "       6/10         0G      1.525      3.077      1.524       1.36      8.374      1.328         13        640: 100%|##########| 10/10 [01:27<00:00,  8.09s/it]\n",
      "       6/10         0G      1.525      3.077      1.524       1.36      8.374      1.328         13        640: 100%|##########| 10/10 [01:27<00:00,  8.73s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  20%|##        | 1/5 [00:10<00:40, 10.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  40%|####      | 2/5 [00:21<00:32, 10.95s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  60%|######    | 3/5 [00:30<00:19,  9.97s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  80%|########  | 4/5 [00:39<00:09,  9.61s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 5/5 [00:43<00:00,  7.76s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 5/5 [00:43<00:00,  8.80s/it]\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "       7/10         0G      1.283      3.004      1.324      1.091      7.496      1.068         17        640:   0%|          | 0/10 [00:09<?, ?it/s]\n",
      "       7/10         0G      1.283      3.004      1.324      1.091      7.496      1.068         17        640:  10%|#         | 1/10 [00:09<01:28,  9.88s/it]\n",
      "       7/10         0G      1.526      2.934      1.506      1.323      7.921      1.254         16        640:  10%|#         | 1/10 [00:19<01:28,  9.88s/it]\n",
      "       7/10         0G      1.526      2.934      1.506      1.323      7.921      1.254         16        640:  20%|##        | 2/10 [00:19<01:18,  9.86s/it]\n",
      "       7/10         0G      1.612      3.046      1.522      1.441      7.955      1.299         17        640:  20%|##        | 2/10 [00:29<01:18,  9.86s/it]\n",
      "       7/10         0G      1.612      3.046      1.522      1.441      7.955      1.299         17        640:  30%|###       | 3/10 [00:29<01:10, 10.02s/it]\n",
      "       7/10         0G      1.642      3.043      1.533      1.413       7.89        1.3         18        640:  30%|###       | 3/10 [00:40<01:10, 10.02s/it]\n",
      "       7/10         0G      1.642      3.043      1.533      1.413       7.89        1.3         18        640:  40%|####      | 4/10 [00:40<01:00, 10.11s/it]\n",
      "       7/10         0G      1.582      3.001      1.472      1.387      7.686      1.264         19        640:  40%|####      | 4/10 [00:50<01:00, 10.11s/it]\n",
      "       7/10         0G      1.582      3.001      1.472      1.387      7.686      1.264         19        640:  50%|#####     | 5/10 [00:50<00:50, 10.15s/it]\n",
      "       7/10         0G      1.529      2.931      1.441      1.356      7.768      1.252         14        640:  50%|#####     | 5/10 [01:00<00:50, 10.15s/it]\n",
      "       7/10         0G      1.529      2.931      1.441      1.356      7.768      1.252         14        640:  60%|######    | 6/10 [01:00<00:40, 10.23s/it]\n",
      "       7/10         0G      1.542      2.971      1.451      1.394      7.978      1.256         15        640:  60%|######    | 6/10 [01:12<00:40, 10.23s/it]\n",
      "       7/10         0G      1.542      2.971      1.451      1.394      7.978      1.256         15        640:  70%|#######   | 7/10 [01:12<00:31, 10.66s/it]\n",
      "       7/10         0G       1.56      3.035      1.471      1.389      8.259      1.275         12        640:  70%|#######   | 7/10 [01:24<00:31, 10.66s/it]\n",
      "       7/10         0G       1.56      3.035      1.471      1.389      8.259      1.275         12        640:  80%|########  | 8/10 [01:24<00:21, 10.99s/it]\n",
      "       7/10         0G      1.545      3.016       1.46      1.379      8.319      1.283         13        640:  80%|########  | 8/10 [01:35<00:21, 10.99s/it]\n",
      "       7/10         0G      1.545      3.016       1.46      1.379      8.319      1.283         13        640:  90%|######### | 9/10 [01:35<00:11, 11.22s/it]\n",
      "       7/10         0G      1.505      3.001      1.438      1.349      8.252      1.271          9        640:  90%|######### | 9/10 [01:41<00:11, 11.22s/it]\n",
      "       7/10         0G      1.505      3.001      1.438      1.349      8.252      1.271          9        640: 100%|##########| 10/10 [01:41<00:00,  9.64s/it]\n",
      "       7/10         0G      1.505      3.001      1.438      1.349      8.252      1.271          9        640: 100%|##########| 10/10 [01:41<00:00, 10.19s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  20%|##        | 1/5 [00:10<00:42, 10.62s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  40%|####      | 2/5 [00:22<00:34, 11.40s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  60%|######    | 3/5 [00:32<00:21, 10.71s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  80%|########  | 4/5 [00:41<00:10, 10.05s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 5/5 [00:46<00:00,  8.06s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 5/5 [00:46<00:00,  9.20s/it]\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "       8/10         0G      1.464      3.152      1.481      1.287      7.727      1.344         16        640:   0%|          | 0/10 [00:09<?, ?it/s]\n",
      "       8/10         0G      1.464      3.152      1.481      1.287      7.727      1.344         16        640:  10%|#         | 1/10 [00:09<01:25,  9.52s/it]\n",
      "       8/10         0G      1.335      3.177      1.403      1.255      7.887      1.285         17        640:  10%|#         | 1/10 [00:19<01:25,  9.52s/it]\n",
      "       8/10         0G      1.335      3.177      1.403      1.255      7.887      1.285         17        640:  20%|##        | 2/10 [00:19<01:20, 10.06s/it]\n",
      "       8/10         0G      1.455      3.111       1.49      1.356      8.878      1.323         11        640:  20%|##        | 2/10 [00:30<01:20, 10.06s/it]\n",
      "       8/10         0G      1.455      3.111       1.49      1.356      8.878      1.323         11        640:  30%|###       | 3/10 [00:30<01:11, 10.16s/it]\n",
      "       8/10         0G      1.461      3.076      1.443       1.37      8.546      1.317         17        640:  30%|###       | 3/10 [00:41<01:11, 10.16s/it]\n",
      "       8/10         0G      1.461      3.076      1.443       1.37      8.546      1.317         17        640:  40%|####      | 4/10 [00:41<01:03, 10.61s/it]\n",
      "       8/10         0G      1.481      3.004      1.447      1.342      8.306      1.295         17        640:  40%|####      | 4/10 [00:53<01:03, 10.61s/it]\n",
      "       8/10         0G      1.481      3.004      1.447      1.342      8.306      1.295         17        640:  50%|#####     | 5/10 [00:53<00:55, 11.13s/it]\n",
      "       8/10         0G       1.48      2.997       1.51      1.329      8.508      1.292         12        640:  50%|#####     | 5/10 [01:04<00:55, 11.13s/it]\n",
      "       8/10         0G       1.48      2.997       1.51      1.329      8.508      1.292         12        640:  60%|######    | 6/10 [01:04<00:44, 11.06s/it]\n",
      "       8/10         0G      1.488      2.993      1.531      1.355      8.634      1.324         13        640:  60%|######    | 6/10 [01:16<00:44, 11.06s/it]\n",
      "       8/10         0G      1.488      2.993      1.531      1.355      8.634      1.324         13        640:  70%|#######   | 7/10 [01:16<00:33, 11.31s/it]\n",
      "       8/10         0G      1.507      2.939      1.527      1.353      8.415      1.324         19        640:  70%|#######   | 7/10 [01:27<00:33, 11.31s/it]\n",
      "       8/10         0G      1.507      2.939      1.527      1.353      8.415      1.324         19        640:  80%|########  | 8/10 [01:27<00:22, 11.41s/it]\n",
      "       8/10         0G      1.488      2.906       1.51      1.325      8.366      1.311         14        640:  80%|########  | 8/10 [01:38<00:22, 11.41s/it]\n",
      "       8/10         0G      1.488      2.906       1.51      1.325      8.366      1.311         14        640:  90%|######### | 9/10 [01:38<00:11, 11.28s/it]\n",
      "       8/10         0G       1.47      2.903      1.474      1.292      8.136      1.282         14        640:  90%|######### | 9/10 [01:45<00:11, 11.28s/it]\n",
      "       8/10         0G       1.47      2.903      1.474      1.292      8.136      1.282         14        640: 100%|##########| 10/10 [01:45<00:00,  9.96s/it]\n",
      "       8/10         0G       1.47      2.903      1.474      1.292      8.136      1.282         14        640: 100%|##########| 10/10 [01:45<00:00, 10.60s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  20%|##        | 1/5 [00:11<00:45, 11.42s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  40%|####      | 2/5 [00:23<00:36, 12.04s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  60%|######    | 3/5 [00:32<00:20, 10.38s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  80%|########  | 4/5 [00:40<00:09,  9.47s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 5/5 [00:44<00:00,  7.61s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 5/5 [00:44<00:00,  8.94s/it]\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "       9/10         0G      1.368      2.624      1.365      1.246      9.289      1.226         12        640:   0%|          | 0/10 [00:09<?, ?it/s]\n",
      "       9/10         0G      1.368      2.624      1.365      1.246      9.289      1.226         12        640:  10%|#         | 1/10 [00:09<01:21,  9.02s/it]\n",
      "       9/10         0G      1.396      2.667      1.426      1.268      9.129      1.317         13        640:  10%|#         | 1/10 [00:18<01:21,  9.02s/it]\n",
      "       9/10         0G      1.396      2.667      1.426      1.268      9.129      1.317         13        640:  20%|##        | 2/10 [00:18<01:16,  9.53s/it]\n",
      "       9/10         0G      1.449      2.683       1.44      1.366      8.824       1.35         15        640:  20%|##        | 2/10 [00:28<01:16,  9.53s/it]\n",
      "       9/10         0G      1.449      2.683       1.44      1.366      8.824       1.35         15        640:  30%|###       | 3/10 [00:28<01:06,  9.46s/it]\n",
      "       9/10         0G      1.531      2.767      1.487      1.436      8.622      1.334         17        640:  30%|###       | 3/10 [00:38<01:06,  9.46s/it]\n",
      "       9/10         0G      1.531      2.767      1.487      1.436      8.622      1.334         17        640:  40%|####      | 4/10 [00:38<00:58,  9.67s/it]\n",
      "       9/10         0G      1.548      2.876      1.463      1.501      8.672      1.325         15        640:  40%|####      | 4/10 [00:48<00:58,  9.67s/it]\n",
      "       9/10         0G      1.548      2.876      1.463      1.501      8.672      1.325         15        640:  50%|#####     | 5/10 [00:48<00:49,  9.85s/it]\n",
      "       9/10         0G       1.55       2.85      1.477      1.491      8.484      1.349         17        640:  50%|#####     | 5/10 [00:56<00:49,  9.85s/it]\n",
      "       9/10         0G       1.55       2.85      1.477      1.491      8.484      1.349         17        640:  60%|######    | 6/10 [00:56<00:37,  9.39s/it]\n",
      "       9/10         0G      1.541      2.897      1.449      1.473       8.28      1.319         20        640:  60%|######    | 6/10 [01:06<00:37,  9.39s/it]\n",
      "       9/10         0G      1.541      2.897      1.449      1.473       8.28      1.319         20        640:  70%|#######   | 7/10 [01:06<00:28,  9.37s/it]\n",
      "       9/10         0G       1.54      2.912      1.445      1.454      8.238      1.317         16        640:  70%|#######   | 7/10 [01:16<00:28,  9.37s/it]\n",
      "       9/10         0G       1.54      2.912      1.445      1.454      8.238      1.317         16        640:  80%|########  | 8/10 [01:16<00:19,  9.78s/it]\n",
      "       9/10         0G       1.54      2.937      1.445      1.434      8.172       1.32         17        640:  80%|########  | 8/10 [01:27<00:19,  9.78s/it]\n",
      "       9/10         0G       1.54      2.937      1.445      1.434      8.172       1.32         17        640:  90%|######### | 9/10 [01:27<00:09,  9.88s/it]\n",
      "       9/10         0G      1.567      2.947      1.459      1.417      8.281      1.324          8        640:  90%|######### | 9/10 [01:33<00:09,  9.88s/it]\n",
      "       9/10         0G      1.567      2.947      1.459      1.417      8.281      1.324          8        640: 100%|##########| 10/10 [01:33<00:00,  8.78s/it]\n",
      "       9/10         0G      1.567      2.947      1.459      1.417      8.281      1.324          8        640: 100%|##########| 10/10 [01:33<00:00,  9.33s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  20%|##        | 1/5 [00:09<00:38,  9.64s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  40%|####      | 2/5 [00:19<00:29,  9.96s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  60%|######    | 3/5 [00:27<00:17,  8.99s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  80%|########  | 4/5 [00:34<00:08,  8.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 5/5 [00:38<00:00,  6.64s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 5/5 [00:38<00:00,  7.67s/it]\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "      10/10         0G      1.463      2.965      1.261      1.263      7.567      1.168         17        640:   0%|          | 0/10 [00:08<?, ?it/s]\n",
      "      10/10         0G      1.463      2.965      1.261      1.263      7.567      1.168         17        640:  10%|#         | 1/10 [00:08<01:20,  8.91s/it]\n",
      "      10/10         0G      1.595       3.16      1.376      1.441      7.494      1.194         20        640:  10%|#         | 1/10 [00:17<01:20,  8.91s/it]\n",
      "      10/10         0G      1.595       3.16      1.376      1.441      7.494      1.194         20        640:  20%|##        | 2/10 [00:17<01:11,  8.99s/it]\n",
      "      10/10         0G      1.619      3.002      1.426      1.428       7.43      1.235         18        640:  20%|##        | 2/10 [00:26<01:11,  8.99s/it]\n",
      "      10/10         0G      1.619      3.002      1.426      1.428       7.43      1.235         18        640:  30%|###       | 3/10 [00:26<01:02,  8.94s/it]\n",
      "      10/10         0G      1.559       2.86       1.47      1.374      7.612      1.248         14        640:  30%|###       | 3/10 [00:35<01:02,  8.94s/it]\n",
      "      10/10         0G      1.559       2.86       1.47      1.374      7.612      1.248         14        640:  40%|####      | 4/10 [00:35<00:53,  8.97s/it]\n",
      "      10/10         0G       1.51      2.885      1.422       1.33      7.471      1.233         20        640:  40%|####      | 4/10 [00:44<00:53,  8.97s/it]\n",
      "      10/10         0G       1.51      2.885      1.422       1.33      7.471      1.233         20        640:  50%|#####     | 5/10 [00:44<00:44,  8.97s/it]\n",
      "      10/10         0G      1.538      2.923       1.43      1.373      7.669      1.268         14        640:  50%|#####     | 5/10 [00:54<00:44,  8.97s/it]\n",
      "      10/10         0G      1.538      2.923       1.43      1.373      7.669      1.268         14        640:  60%|######    | 6/10 [00:54<00:36,  9.04s/it]\n",
      "      10/10         0G      1.514      2.921      1.415      1.367      7.745       1.26         15        640:  60%|######    | 6/10 [01:02<00:36,  9.04s/it]\n",
      "      10/10         0G      1.514      2.921      1.415      1.367      7.745       1.26         15        640:  70%|#######   | 7/10 [01:02<00:26,  8.96s/it]\n",
      "      10/10         0G      1.496      2.894      1.404      1.331      7.933      1.247         12        640:  70%|#######   | 7/10 [01:12<00:26,  8.96s/it]\n",
      "      10/10         0G      1.496      2.894      1.404      1.331      7.933      1.247         12        640:  80%|########  | 8/10 [01:12<00:18,  9.05s/it]\n",
      "      10/10         0G      1.484      2.896      1.414      1.328        8.1      1.243         12        640:  80%|########  | 8/10 [01:21<00:18,  9.05s/it]\n",
      "      10/10         0G      1.484      2.896      1.414      1.328        8.1      1.243         12        640:  90%|######### | 9/10 [01:21<00:09,  9.32s/it]\n",
      "      10/10         0G      1.466      2.851      1.424      1.315      8.123      1.248          8        640:  90%|######### | 9/10 [01:27<00:09,  9.32s/it]\n",
      "      10/10         0G      1.466      2.851      1.424      1.315      8.123      1.248          8        640: 100%|##########| 10/10 [01:27<00:00,  8.21s/it]\n",
      "      10/10         0G      1.466      2.851      1.424      1.315      8.123      1.248          8        640: 100%|##########| 10/10 [01:27<00:00,  8.77s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  20%|##        | 1/5 [00:09<00:36,  9.11s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  40%|####      | 2/5 [00:19<00:29,  9.68s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  60%|######    | 3/5 [00:27<00:17,  8.88s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  80%|########  | 4/5 [00:34<00:08,  8.26s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 5/5 [00:37<00:00,  6.39s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 5/5 [00:37<00:00,  7.50s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  20%|##        | 1/5 [00:07<00:30,  7.75s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  40%|####      | 2/5 [00:16<00:25,  8.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  60%|######    | 3/5 [00:23<00:15,  7.69s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  80%|########  | 4/5 [00:29<00:07,  7.20s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 5/5 [00:33<00:00,  5.86s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 5/5 [00:33<00:00,  6.67s/it]\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=train epochs=10 batch=10  plots=True model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt data=C:/Users/sshiv/Desktop/sihProject/data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2596df0-2c2b-4d20-ba2f-141f54c2418d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "image 1/1 C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\3.jpg: 640x384 (no detections), 139.2ms\n",
      "Speed: 8.4ms preprocess, 139.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\predict5\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.25 save=True model=C:\\Users\\sshiv\\runs\\detect\\train3\\weights\\best.pt source=test_images/3.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f620fe9-92ff-49e0-b040-a3b4d42e0e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.81 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt, data=C:/Users/sshiv/Desktop/sihProject/data.yaml, epochs=15, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, val_period=1, cache=False, device=None, workers=8, project=None, name=train4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=C:\\Users\\sshiv\\runs\\detect\\train4\n",
      "Overriding model.yaml nc=80 with nc=8\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1      9856  ultralytics.nn.modules.block.SCDown          [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.PSA             [256, 256]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 20                  -1  1     18048  ultralytics.nn.modules.block.SCDown          [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    282624  ultralytics.nn.modules.block.C2fCIB          [384, 256, 1, True, True]     \n",
      " 23        [16, 19, 22]  1    864448  ultralytics.nn.modules.head.v10Detect        [8, [64, 128, 256]]           \n",
      "YOLOv10n summary: 385 layers, 2710160 parameters, 2710144 gradients, 8.4 GFLOPs\n",
      "\n",
      "Transferred 493/595 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸� C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\train\\images\\IMG_20240413_011606.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸� C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\train\\images\\IMG_20240414_005657.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸� C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\train\\images\\IMG_20240414_005942.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸� C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\valid\\images\\IMG_20240413_011606.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸� C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\valid\\images\\IMG_20240414_005657.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸� C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\valid\\images\\IMG_20240414_005942.jpg: corrupt JPEG restored and saved\n",
      "Plotting labels to C:\\Users\\sshiv\\runs\\detect\\train4\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000833, momentum=0.9) with parameter groups 95 weight(decay=0.0), 108 weight(decay=0.0005), 107 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\train4\u001b[0m\n",
      "Starting training for 15 epochs...\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n",
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:276: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\train\\labels.cache... 95 images, 1 backgrounds, 0 corrupt: 100%|##########| 96/96 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\train\\labels.cache... 95 images, 1 backgrounds, 0 corrupt: 100%|##########| 96/96 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\valid\\labels.cache... 95 images, 1 backgrounds, 0 corrupt: 100%|##########| 96/96 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\valid\\labels.cache... 95 images, 1 backgrounds, 0 corrupt: 100%|##########| 96/96 [00:00<?, ?it/s]\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "       1/15         0G      1.973       4.36      1.841      1.607      6.869      1.635         53        640:   0%|          | 0/6 [00:18<?, ?it/s]\n",
      "       1/15         0G      1.973       4.36      1.841      1.607      6.869      1.635         53        640:  17%|#6        | 1/6 [00:18<01:33, 18.63s/it]\n",
      "       1/15         0G      1.968      4.438      1.869      1.633      7.239      1.619         44        640:  17%|#6        | 1/6 [00:36<01:33, 18.63s/it]\n",
      "       1/15         0G      1.968      4.438      1.869      1.633      7.239      1.619         44        640:  33%|###3      | 2/6 [00:36<01:12, 18.06s/it]\n",
      "       1/15         0G      1.971      4.443      1.904      1.647      7.391       1.64         41        640:  33%|###3      | 2/6 [00:53<01:12, 18.06s/it]\n",
      "       1/15         0G      1.971      4.443      1.904      1.647      7.391       1.64         41        640:  50%|#####     | 3/6 [00:53<00:52, 17.55s/it]\n",
      "       1/15         0G      1.928      4.423      1.896      1.619      7.337      1.647         47        640:  50%|#####     | 3/6 [01:10<00:52, 17.55s/it]\n",
      "       1/15         0G      1.928      4.423      1.896      1.619      7.337      1.647         47        640:  67%|######6   | 4/6 [01:10<00:35, 17.51s/it]\n",
      "       1/15         0G      1.868      4.418      1.852      1.576      7.396       1.61         40        640:  67%|######6   | 4/6 [01:27<00:35, 17.51s/it]\n",
      "       1/15         0G      1.868      4.418      1.852      1.576      7.396       1.61         40        640:  83%|########3 | 5/6 [01:27<00:17, 17.28s/it]\n",
      "       1/15         0G      1.868      4.456      1.827       1.61      7.493      1.599         41        640:  83%|########3 | 5/6 [01:45<00:17, 17.28s/it]\n",
      "       1/15         0G      1.868      4.456      1.827       1.61      7.493      1.599         41        640: 100%|##########| 6/6 [01:45<00:00, 17.44s/it]\n",
      "       1/15         0G      1.868      4.456      1.827       1.61      7.493      1.599         41        640: 100%|##########| 6/6 [01:45<00:00, 17.55s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:16<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 594, in entrypoint\n",
      "    getattr(model, mode)(**overrides)  # default args from model\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 657, in train\n",
      "    self.trainer.train()\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 213, in train\n",
      "    self._do_train(world_size)\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 430, in _do_train\n",
      "    self.metrics, self.fitness = self.validate()\n",
      "                                 ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 552, in validate\n",
      "    metrics = self.validator(self)\n",
      "              ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\validator.py\", line 183, in __call__\n",
      "    self.loss += model.loss(batch, preds)[1]\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py\", line 275, in loss\n",
      "    return self.criterion(preds, batch)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\utils\\loss.py\", line 724, in __call__\n",
      "    loss_one2many = self.one2many(one2many, batch)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\utils\\loss.py\", line 221, in __call__\n",
      "    _, target_bboxes, target_scores, fg_mask, _ = self.assigner(\n",
      "                                                  ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\utils\\tal.py\", line 72, in forward\n",
      "    mask_pos, align_metric, overlaps = self.get_pos_mask(\n",
      "                                       ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\utils\\tal.py\", line 94, in get_pos_mask\n",
      "    align_metric, overlaps = self.get_box_metrics(pd_scores, pd_bboxes, gt_labels, gt_bboxes, mask_in_gts * mask_gt)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\utils\\tal.py\", line 113, in get_box_metrics\n",
      "    bbox_scores[mask_gt] = pd_scores[ind[0], :, ind[1]][mask_gt]  # b, max_num_obj, h*w\n",
      "                           ~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "IndexError: index 8 is out of bounds for dimension 1 with size 8\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=train epochs=15 batch=16  plots=True model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt data=C:/Users/sshiv/Desktop/sihProject/data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6941325e-52d3-4394-9dc7-46a4c4f282a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.81 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt, data=C:/Users/sshiv/Desktop/sihProject/data.yaml, epochs=15, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, val_period=1, cache=False, device=None, workers=8, project=None, name=train5, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=C:\\Users\\sshiv\\runs\\detect\\train5\n",
      "Overriding model.yaml nc=80 with nc=8\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1      9856  ultralytics.nn.modules.block.SCDown          [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.PSA             [256, 256]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 20                  -1  1     18048  ultralytics.nn.modules.block.SCDown          [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    282624  ultralytics.nn.modules.block.C2fCIB          [384, 256, 1, True, True]     \n",
      " 23        [16, 19, 22]  1    864448  ultralytics.nn.modules.head.v10Detect        [8, [64, 128, 256]]           \n",
      "YOLOv10n summary: 385 layers, 2710160 parameters, 2710144 gradients, 8.4 GFLOPs\n",
      "\n",
      "Transferred 493/595 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸� C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\train\\images\\IMG_20240413_011606.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸� C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\train\\images\\IMG_20240414_005657.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸� C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\train\\images\\IMG_20240414_005942.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸� C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\valid\\images\\IMG_20240413_011606.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸� C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\valid\\images\\IMG_20240414_005657.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸� C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\valid\\images\\IMG_20240414_005942.jpg: corrupt JPEG restored and saved\n",
      "Plotting labels to C:\\Users\\sshiv\\runs\\detect\\train5\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000833, momentum=0.9) with parameter groups 95 weight(decay=0.0), 108 weight(decay=0.0005), 107 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\train5\u001b[0m\n",
      "Starting training for 15 epochs...\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n",
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:276: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\train\\labels.cache... 95 images, 1 backgrounds, 0 corrupt: 100%|##########| 96/96 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\train\\labels.cache... 95 images, 1 backgrounds, 0 corrupt: 100%|##########| 96/96 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\valid\\labels.cache... 95 images, 1 backgrounds, 0 corrupt: 100%|##########| 96/96 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\valid\\labels.cache... 95 images, 1 backgrounds, 0 corrupt: 100%|##########| 96/96 [00:00<?, ?it/s]\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "       1/15         0G      1.973       4.36      1.841      1.607      6.869      1.635         53        640:   0%|          | 0/6 [00:17<?, ?it/s]\n",
      "       1/15         0G      1.973       4.36      1.841      1.607      6.869      1.635         53        640:  17%|#6        | 1/6 [00:17<01:25, 17.05s/it]\n",
      "       1/15         0G      1.968      4.438      1.869      1.633      7.239      1.619         44        640:  17%|#6        | 1/6 [00:34<01:25, 17.05s/it]\n",
      "       1/15         0G      1.968      4.438      1.869      1.633      7.239      1.619         44        640:  33%|###3      | 2/6 [00:34<01:09, 17.34s/it]\n",
      "       1/15         0G      1.971      4.443      1.904      1.647      7.391       1.64         41        640:  33%|###3      | 2/6 [00:52<01:09, 17.34s/it]\n",
      "       1/15         0G      1.971      4.443      1.904      1.647      7.391       1.64         41        640:  50%|#####     | 3/6 [00:52<00:52, 17.41s/it]\n",
      "       1/15         0G      1.928      4.423      1.896      1.619      7.337      1.647         47        640:  50%|#####     | 3/6 [01:09<00:52, 17.41s/it]\n",
      "       1/15         0G      1.928      4.423      1.896      1.619      7.337      1.647         47        640:  67%|######6   | 4/6 [01:09<00:34, 17.50s/it]\n",
      "       1/15         0G      1.868      4.418      1.852      1.576      7.396       1.61         40        640:  67%|######6   | 4/6 [01:26<00:34, 17.50s/it]\n",
      "       1/15         0G      1.868      4.418      1.852      1.576      7.396       1.61         40        640:  83%|########3 | 5/6 [01:26<00:17, 17.38s/it]\n",
      "       1/15         0G      1.868      4.456      1.827       1.61      7.493      1.599         41        640:  83%|########3 | 5/6 [01:44<00:17, 17.38s/it]\n",
      "       1/15         0G      1.868      4.456      1.827       1.61      7.493      1.599         41        640: 100%|##########| 6/6 [01:44<00:00, 17.47s/it]\n",
      "       1/15         0G      1.868      4.456      1.827       1.61      7.493      1.599         41        640: 100%|##########| 6/6 [01:44<00:00, 17.42s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:15<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 594, in entrypoint\n",
      "    getattr(model, mode)(**overrides)  # default args from model\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 657, in train\n",
      "    self.trainer.train()\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 213, in train\n",
      "    self._do_train(world_size)\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 430, in _do_train\n",
      "    self.metrics, self.fitness = self.validate()\n",
      "                                 ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 552, in validate\n",
      "    metrics = self.validator(self)\n",
      "              ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\validator.py\", line 183, in __call__\n",
      "    self.loss += model.loss(batch, preds)[1]\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py\", line 275, in loss\n",
      "    return self.criterion(preds, batch)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\utils\\loss.py\", line 724, in __call__\n",
      "    loss_one2many = self.one2many(one2many, batch)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\utils\\loss.py\", line 221, in __call__\n",
      "    _, target_bboxes, target_scores, fg_mask, _ = self.assigner(\n",
      "                                                  ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\utils\\tal.py\", line 72, in forward\n",
      "    mask_pos, align_metric, overlaps = self.get_pos_mask(\n",
      "                                       ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\utils\\tal.py\", line 94, in get_pos_mask\n",
      "    align_metric, overlaps = self.get_box_metrics(pd_scores, pd_bboxes, gt_labels, gt_bboxes, mask_in_gts * mask_gt)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\utils\\tal.py\", line 113, in get_box_metrics\n",
      "    bbox_scores[mask_gt] = pd_scores[ind[0], :, ind[1]][mask_gt]  # b, max_num_obj, h*w\n",
      "                           ~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "IndexError: index 8 is out of bounds for dimension 1 with size 8\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=train epochs=15 batch=16  plots=True model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt data=C:/Users/sshiv/Desktop/sihProject/data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eee77762-b8ef-41fa-a97e-a29a31af44bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.81 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt, data=C:/Users/sshiv/Desktop/sihProject/data.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, val_period=1, cache=False, device=None, workers=8, project=None, name=train6, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=C:\\Users\\sshiv\\runs\\detect\\train6\n",
      "Overriding model.yaml nc=80 with nc=8\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1      9856  ultralytics.nn.modules.block.SCDown          [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.PSA             [256, 256]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 20                  -1  1     18048  ultralytics.nn.modules.block.SCDown          [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    282624  ultralytics.nn.modules.block.C2fCIB          [384, 256, 1, True, True]     \n",
      " 23        [16, 19, 22]  1    864448  ultralytics.nn.modules.head.v10Detect        [8, [64, 128, 256]]           \n",
      "YOLOv10n summary: 385 layers, 2710160 parameters, 2710144 gradients, 8.4 GFLOPs\n",
      "\n",
      "Transferred 493/595 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\train\\labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\valid\\labels.cache\n",
      "Plotting labels to C:\\Users\\sshiv\\runs\\detect\\train6\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000833, momentum=0.9) with parameter groups 95 weight(decay=0.0), 108 weight(decay=0.0005), 107 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\train6\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n",
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:276: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\train\\labels...:   0%|          | 0/96 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\train\\labels... 50 images, 1 backgrounds, 0 corrupt:  53%|#####3    | 51/96 [00:00<00:00, 473.63it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\train\\labels... 95 images, 1 backgrounds, 0 corrupt: 100%|##########| 96/96 [00:00<00:00, 527.40it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\valid\\labels...:   0%|          | 0/96 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\valid\\labels... 95 images, 1 backgrounds, 0 corrupt: 100%|##########| 96/96 [00:00<00:00, 1021.13it/s]\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "       1/10         0G      1.993      5.088      2.021      1.649      10.89      1.754         23        640:   0%|          | 0/6 [00:16<?, ?it/s]\n",
      "       1/10         0G      1.993      5.088      2.021      1.649      10.89      1.754         23        640:  17%|#6        | 1/6 [00:16<01:22, 16.40s/it]\n",
      "       1/10         0G      1.966      5.027      2.018      1.729      10.64      1.766         25        640:  17%|#6        | 1/6 [00:33<01:22, 16.40s/it]\n",
      "       1/10         0G      1.966      5.027      2.018      1.729      10.64      1.766         25        640:  33%|###3      | 2/6 [00:33<01:08, 17.09s/it]\n",
      "       1/10         0G      1.966      5.027      2.018      1.729      10.64      1.766         25        640:  33%|###3      | 2/6 [00:43<01:26, 21.61s/it]\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 594, in entrypoint\n",
      "    getattr(model, mode)(**overrides)  # default args from model\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 657, in train\n",
      "    self.trainer.train()\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 213, in train\n",
      "    self._do_train(world_size)\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 381, in _do_train\n",
      "    self.loss, self.loss_items = self.model(batch)\n",
      "                                 ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py\", line 93, in forward\n",
      "    return self.loss(x, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py\", line 275, in loss\n",
      "    return self.criterion(preds, batch)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\utils\\loss.py\", line 724, in __call__\n",
      "    loss_one2many = self.one2many(one2many, batch)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\utils\\loss.py\", line 221, in __call__\n",
      "    _, target_bboxes, target_scores, fg_mask, _ = self.assigner(\n",
      "                                                  ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\utils\\tal.py\", line 72, in forward\n",
      "    mask_pos, align_metric, overlaps = self.get_pos_mask(\n",
      "                                       ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\utils\\tal.py\", line 94, in get_pos_mask\n",
      "    align_metric, overlaps = self.get_box_metrics(pd_scores, pd_bboxes, gt_labels, gt_bboxes, mask_in_gts * mask_gt)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\utils\\tal.py\", line 113, in get_box_metrics\n",
      "    bbox_scores[mask_gt] = pd_scores[ind[0], :, ind[1]][mask_gt]  # b, max_num_obj, h*w\n",
      "                           ~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "IndexError: index 8 is out of bounds for dimension 1 with size 8\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=train epochs=10 batch=16  plots=True model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt data=C:/Users/sshiv/Desktop/sihProject/data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a3b9419-3220-4659-b738-3ea19b0fdb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.81 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt, data=C:/Users/sshiv/Desktop/sihProject/data.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, val_period=1, cache=False, device=None, workers=8, project=None, name=train7, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=C:\\Users\\sshiv\\runs\\detect\\train7\n",
      "Overriding model.yaml nc=80 with nc=8\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1      9856  ultralytics.nn.modules.block.SCDown          [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.PSA             [256, 256]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 20                  -1  1     18048  ultralytics.nn.modules.block.SCDown          [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    282624  ultralytics.nn.modules.block.C2fCIB          [384, 256, 1, True, True]     \n",
      " 23        [16, 19, 22]  1    864448  ultralytics.nn.modules.head.v10Detect        [8, [64, 128, 256]]           \n",
      "YOLOv10n summary: 385 layers, 2710160 parameters, 2710144 gradients, 8.4 GFLOPs\n",
      "\n",
      "Transferred 493/595 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "Plotting labels to C:\\Users\\sshiv\\runs\\detect\\train7\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000833, momentum=0.9) with parameter groups 95 weight(decay=0.0), 108 weight(decay=0.0005), 107 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\train7\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n",
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:276: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\train\\labels.cache... 95 images, 1 backgrounds, 0 corrupt: 100%|##########| 96/96 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\train\\labels.cache... 95 images, 1 backgrounds, 0 corrupt: 100%|##########| 96/96 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\valid\\labels.cache... 95 images, 1 backgrounds, 0 corrupt: 100%|##########| 96/96 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\valid\\labels.cache... 95 images, 1 backgrounds, 0 corrupt: 100%|##########| 96/96 [00:00<?, ?it/s]\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "       1/10         0G      1.993      5.088      2.021      1.649      10.89      1.754         23        640:   0%|          | 0/6 [00:17<?, ?it/s]\n",
      "       1/10         0G      1.993      5.088      2.021      1.649      10.89      1.754         23        640:  17%|#6        | 1/6 [00:17<01:26, 17.36s/it]\n",
      "       1/10         0G      1.966      5.027      2.018      1.729      10.64      1.766         25        640:  17%|#6        | 1/6 [00:34<01:26, 17.36s/it]\n",
      "       1/10         0G      1.966      5.027      2.018      1.729      10.64      1.766         25        640:  33%|###3      | 2/6 [00:34<01:07, 16.97s/it]\n",
      "       1/10         0G      1.966      5.027      2.018      1.729      10.64      1.766         25        640:  33%|###3      | 2/6 [00:43<01:26, 21.63s/it]\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 594, in entrypoint\n",
      "    getattr(model, mode)(**overrides)  # default args from model\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 657, in train\n",
      "    self.trainer.train()\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 213, in train\n",
      "    self._do_train(world_size)\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 381, in _do_train\n",
      "    self.loss, self.loss_items = self.model(batch)\n",
      "                                 ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py\", line 93, in forward\n",
      "    return self.loss(x, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py\", line 275, in loss\n",
      "    return self.criterion(preds, batch)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\utils\\loss.py\", line 724, in __call__\n",
      "    loss_one2many = self.one2many(one2many, batch)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\utils\\loss.py\", line 221, in __call__\n",
      "    _, target_bboxes, target_scores, fg_mask, _ = self.assigner(\n",
      "                                                  ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\utils\\tal.py\", line 72, in forward\n",
      "    mask_pos, align_metric, overlaps = self.get_pos_mask(\n",
      "                                       ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\utils\\tal.py\", line 94, in get_pos_mask\n",
      "    align_metric, overlaps = self.get_box_metrics(pd_scores, pd_bboxes, gt_labels, gt_bboxes, mask_in_gts * mask_gt)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\utils\\tal.py\", line 113, in get_box_metrics\n",
      "    bbox_scores[mask_gt] = pd_scores[ind[0], :, ind[1]][mask_gt]  # b, max_num_obj, h*w\n",
      "                           ~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "IndexError: index 8 is out of bounds for dimension 1 with size 8\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=train epochs=10 batch=16  plots=True model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt data=C:/Users/sshiv/Desktop/sihProject/data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6cdd767-6b50-4bbe-966f-6d872806a8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.81 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt, data=C:/Users/sshiv/Desktop/sihProject/data.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, val_period=1, cache=False, device=None, workers=8, project=None, name=train8, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=C:\\Users\\sshiv\\runs\\detect\\train8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 138, in __init__\n",
      "    self.data = check_det_dataset(self.args.data)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\data\\utils.py\", line 291, in check_det_dataset\n",
      "    raise SyntaxError(emojis(f\"{dataset} 'names' length {len(data['names'])} and 'nc: {data['nc']}' must match.\"))\n",
      "SyntaxError: C:/Users/sshiv/Desktop/sihProject/data.yaml 'names' length 8 and 'nc: 7' must match.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 594, in entrypoint\n",
      "    getattr(model, mode)(**overrides)  # default args from model\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 638, in train\n",
      "    self.trainer = (trainer or self._smart_load(\"trainer\"))(overrides=args, _callbacks=self.callbacks)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 142, in __init__\n",
      "    raise RuntimeError(emojis(f\"Dataset '{clean_url(self.args.data)}' error \\u274c {e}\")) from e\n",
      "RuntimeError: Dataset 'C://Users/sshiv/Desktop/sihProject/data.yaml' error  C:/Users/sshiv/Desktop/sihProject/data.yaml 'names' length 8 and 'nc: 7' must match.\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=train epochs=10 batch=16  plots=True model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt data=C:/Users/sshiv/Desktop/sihProject/data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f319eed5-9caa-4549-9948-df65c79a774b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.81 available ðŸ˜ƒ Update with 'pip install -U ultralytics'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n",
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:276: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\train\\labels.cache... 95 images, 1 backgrounds, 0 corrupt: 100%|##########| 96/96 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\train\\labels.cache... 95 images, 1 backgrounds, 0 corrupt: 100%|##########| 96/96 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\valid\\labels.cache... 95 images, 1 backgrounds, 0 corrupt: 100%|##########| 96/96 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\valid\\labels.cache... 95 images, 1 backgrounds, 0 corrupt: 100%|##########| 96/96 [00:00<?, ?it/s]\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "       1/10         0G      1.976      5.135      2.008      1.607      10.72      1.736         23        640:   0%|          | 0/6 [00:16<?, ?it/s]\n",
      "       1/10         0G      1.976      5.135      2.008      1.607      10.72      1.736         23        640:  17%|#6        | 1/6 [00:16<01:23, 16.67s/it]\n",
      "       1/10         0G      1.956      5.053      2.011      1.686      10.55      1.778         25        640:  17%|#6        | 1/6 [00:33<01:23, 16.67s/it]\n",
      "       1/10         0G      1.956      5.053      2.011      1.686      10.55      1.778         25        640:  33%|###3      | 2/6 [00:33<01:08, 17.05s/it]\n",
      "       1/10         0G      2.055      5.044      2.003      1.751      10.22      1.728         30        640:  33%|###3      | 2/6 [00:51<01:08, 17.05s/it]\n",
      "       1/10         0G      2.055      5.044      2.003      1.751      10.22      1.728         30        640:  50%|#####     | 3/6 [00:51<00:51, 17.11s/it]\n",
      "       1/10         0G      2.021      5.049      1.985      1.714      10.12      1.693         27        640:  50%|#####     | 3/6 [01:08<00:51, 17.11s/it]\n",
      "       1/10         0G      2.021      5.049      1.985      1.714      10.12      1.693         27        640:  67%|######6   | 4/6 [01:08<00:34, 17.07s/it]\n",
      "       1/10         0G       2.01      5.027      2.012      1.746      10.43      1.721         21        640:  67%|######6   | 4/6 [01:25<00:34, 17.07s/it]\n",
      "       1/10         0G       2.01      5.027      2.012      1.746      10.43      1.721         21        640:  83%|########3 | 5/6 [01:25<00:17, 17.24s/it]\n",
      "       1/10         0G      1.942          5      1.952      1.692      10.39      1.676         24        640:  83%|########3 | 5/6 [01:43<00:17, 17.24s/it]\n",
      "       1/10         0G      1.942          5      1.952      1.692      10.39      1.676         24        640: 100%|##########| 6/6 [01:43<00:00, 17.40s/it]\n",
      "       1/10         0G      1.942          5      1.952      1.692      10.39      1.676         24        640: 100%|##########| 6/6 [01:43<00:00, 17.24s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|###3      | 1/3 [00:17<00:35, 17.57s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|######6   | 2/3 [00:32<00:15, 15.73s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:41<00:00, 12.82s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:41<00:00, 13.79s/it]\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "       2/10         0G      1.785      4.731      1.817       1.39      9.775      1.602         25        640:   0%|          | 0/6 [00:14<?, ?it/s]\n",
      "       2/10         0G      1.785      4.731      1.817       1.39      9.775      1.602         25        640:  17%|#6        | 1/6 [00:14<01:14, 14.91s/it]\n",
      "       2/10         0G       1.68      4.603      1.719       1.38      9.418      1.498         28        640:  17%|#6        | 1/6 [00:30<01:14, 14.91s/it]\n",
      "       2/10         0G       1.68      4.603      1.719       1.38      9.418      1.498         28        640:  33%|###3      | 2/6 [00:30<01:00, 15.06s/it]\n",
      "       2/10         0G      1.692      4.618      1.704      1.369      9.357      1.461         28        640:  33%|###3      | 2/6 [00:45<01:00, 15.06s/it]\n",
      "       2/10         0G      1.692      4.618      1.704      1.369      9.357      1.461         28        640:  50%|#####     | 3/6 [00:45<00:45, 15.23s/it]\n",
      "       2/10         0G      1.689      4.617      1.695      1.373      9.528      1.461         24        640:  50%|#####     | 3/6 [01:00<00:45, 15.23s/it]\n",
      "       2/10         0G      1.689      4.617      1.695      1.373      9.528      1.461         24        640:  67%|######6   | 4/6 [01:00<00:30, 15.21s/it]\n",
      "       2/10         0G      1.659      4.581      1.652      1.383      9.466      1.421         27        640:  67%|######6   | 4/6 [01:15<00:30, 15.21s/it]\n",
      "       2/10         0G      1.659      4.581      1.652      1.383      9.466      1.421         27        640:  83%|########3 | 5/6 [01:15<00:15, 15.16s/it]\n",
      "       2/10         0G      1.604      4.589      1.609      1.341      9.824      1.405         18        640:  83%|########3 | 5/6 [01:31<00:15, 15.16s/it]\n",
      "       2/10         0G      1.604      4.589      1.609      1.341      9.824      1.405         18        640: 100%|##########| 6/6 [01:31<00:00, 15.36s/it]\n",
      "       2/10         0G      1.604      4.589      1.609      1.341      9.824      1.405         18        640: 100%|##########| 6/6 [01:31<00:00, 15.25s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|###3      | 1/3 [00:17<00:35, 17.72s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|######6   | 2/3 [00:31<00:15, 15.60s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:41<00:00, 12.85s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:41<00:00, 13.80s/it]\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "       3/10         0G      1.328       3.97      1.397      1.164      7.848      1.303         33        640:   0%|          | 0/6 [00:14<?, ?it/s]\n",
      "       3/10         0G      1.328       3.97      1.397      1.164      7.848      1.303         33        640:  17%|#6        | 1/6 [00:14<01:11, 14.36s/it]\n",
      "       3/10         0G      1.353      4.171      1.424      1.231      9.249      1.309         21        640:  17%|#6        | 1/6 [00:29<01:11, 14.36s/it]\n",
      "       3/10         0G      1.353      4.171      1.424      1.231      9.249      1.309         21        640:  33%|###3      | 2/6 [00:29<00:59, 14.97s/it]\n",
      "       3/10         0G      1.375      4.131      1.417      1.227        9.1       1.29         27        640:  33%|###3      | 2/6 [00:45<00:59, 14.97s/it]\n",
      "       3/10         0G      1.375      4.131      1.417      1.227        9.1       1.29         27        640:  50%|#####     | 3/6 [00:45<00:45, 15.18s/it]\n",
      "       3/10         0G      1.364       4.09      1.394      1.223      9.318      1.275         21        640:  50%|#####     | 3/6 [01:00<00:45, 15.18s/it]\n",
      "       3/10         0G      1.364       4.09      1.394      1.223      9.318      1.275         21        640:  67%|######6   | 4/6 [01:00<00:30, 15.19s/it]\n",
      "       3/10         0G      1.364      4.106      1.373      1.213      9.305      1.244         25        640:  67%|######6   | 4/6 [01:15<00:30, 15.19s/it]\n",
      "       3/10         0G      1.364      4.106      1.373      1.213      9.305      1.244         25        640:  83%|########3 | 5/6 [01:15<00:15, 15.27s/it]\n",
      "       3/10         0G      1.422        4.1      1.416      1.254      9.387      1.264         23        640:  83%|########3 | 5/6 [01:31<00:15, 15.27s/it]\n",
      "       3/10         0G      1.422        4.1      1.416      1.254      9.387      1.264         23        640: 100%|##########| 6/6 [01:31<00:00, 15.25s/it]\n",
      "       3/10         0G      1.422        4.1      1.416      1.254      9.387      1.264         23        640: 100%|##########| 6/6 [01:31<00:00, 15.17s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|###3      | 1/3 [00:17<00:34, 17.22s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|######6   | 2/3 [00:31<00:15, 15.48s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:40<00:00, 12.75s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:40<00:00, 13.66s/it]\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "       4/10         0G      1.248      3.717      1.275      1.173      8.348      1.199         27        640:   0%|          | 0/6 [00:14<?, ?it/s]\n",
      "       4/10         0G      1.248      3.717      1.275      1.173      8.348      1.199         27        640:  17%|#6        | 1/6 [00:14<01:14, 14.83s/it]\n",
      "       4/10         0G      1.253      3.717      1.295      1.078      8.114      1.164         29        640:  17%|#6        | 1/6 [00:30<01:14, 14.83s/it]\n",
      "       4/10         0G      1.253      3.717      1.295      1.078      8.114      1.164         29        640:  33%|###3      | 2/6 [00:30<01:00, 15.18s/it]\n",
      "       4/10         0G      1.279      3.779      1.347      1.135      8.978      1.214         19        640:  33%|###3      | 2/6 [00:45<01:00, 15.18s/it]\n",
      "       4/10         0G      1.279      3.779      1.347      1.135      8.978      1.214         19        640:  50%|#####     | 3/6 [00:45<00:45, 15.25s/it]\n",
      "       4/10         0G      1.356      3.841      1.398      1.167      9.513       1.26         18        640:  50%|#####     | 3/6 [01:00<00:45, 15.25s/it]\n",
      "       4/10         0G      1.356      3.841      1.398      1.167      9.513       1.26         18        640:  67%|######6   | 4/6 [01:00<00:30, 15.22s/it]\n",
      "       4/10         0G      1.411      3.833      1.404      1.213      9.169      1.273         32        640:  67%|######6   | 4/6 [01:15<00:30, 15.22s/it]\n",
      "       4/10         0G      1.411      3.833      1.404      1.213      9.169      1.273         32        640:  83%|########3 | 5/6 [01:15<00:15, 15.00s/it]\n",
      "       4/10         0G       1.47      3.819      1.445      1.267      9.143      1.289         25        640:  83%|########3 | 5/6 [01:30<00:15, 15.00s/it]\n",
      "       4/10         0G       1.47      3.819      1.445      1.267      9.143      1.289         25        640: 100%|##########| 6/6 [01:30<00:00, 15.06s/it]\n",
      "       4/10         0G       1.47      3.819      1.445      1.267      9.143      1.289         25        640: 100%|##########| 6/6 [01:30<00:00, 15.09s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|###3      | 1/3 [00:17<00:34, 17.21s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|######6   | 2/3 [00:31<00:15, 15.43s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:40<00:00, 12.74s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:40<00:00, 13.64s/it]\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "       5/10         0G      1.355      3.467      1.412      1.068      8.568      1.226         24        640:   0%|          | 0/6 [00:14<?, ?it/s]\n",
      "       5/10         0G      1.355      3.467      1.412      1.068      8.568      1.226         24        640:  17%|#6        | 1/6 [00:14<01:14, 14.98s/it]\n",
      "       5/10         0G      1.436      3.472      1.518      1.169      9.135      1.325         21        640:  17%|#6        | 1/6 [00:30<01:14, 14.98s/it]\n",
      "       5/10         0G      1.436      3.472      1.518      1.169      9.135      1.325         21        640:  33%|###3      | 2/6 [00:30<01:00, 15.14s/it]\n",
      "       5/10         0G       1.46      3.568      1.464      1.212       8.74      1.288         29        640:  33%|###3      | 2/6 [00:45<01:00, 15.14s/it]\n",
      "       5/10         0G       1.46      3.568      1.464      1.212       8.74      1.288         29        640:  50%|#####     | 3/6 [00:45<00:45, 15.23s/it]\n",
      "       5/10         0G      1.482      3.563      1.471      1.222      8.899      1.271         22        640:  50%|#####     | 3/6 [01:00<00:45, 15.23s/it]\n",
      "       5/10         0G      1.482      3.563      1.471      1.222      8.899      1.271         22        640:  67%|######6   | 4/6 [01:00<00:30, 15.22s/it]\n",
      "       5/10         0G       1.49      3.528       1.47      1.261      8.875      1.294         24        640:  67%|######6   | 4/6 [01:16<00:30, 15.22s/it]\n",
      "       5/10         0G       1.49      3.528       1.47      1.261      8.875      1.294         24        640:  83%|########3 | 5/6 [01:16<00:15, 15.27s/it]\n",
      "       5/10         0G      1.497      3.535      1.445      1.271      8.661      1.282         30        640:  83%|########3 | 5/6 [01:31<00:15, 15.27s/it]\n",
      "       5/10         0G      1.497      3.535      1.445      1.271      8.661      1.282         30        640: 100%|##########| 6/6 [01:31<00:00, 15.24s/it]\n",
      "       5/10         0G      1.497      3.535      1.445      1.271      8.661      1.282         30        640: 100%|##########| 6/6 [01:31<00:00, 15.22s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|###3      | 1/3 [00:17<00:34, 17.25s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|######6   | 2/3 [00:31<00:15, 15.54s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:40<00:00, 12.73s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:40<00:00, 13.66s/it]\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "       6/10         0G      1.518      3.361      1.526      1.372      9.093      1.455         22        640:   0%|          | 0/6 [00:14<?, ?it/s]\n",
      "       6/10         0G      1.518      3.361      1.526      1.372      9.093      1.455         22        640:  17%|#6        | 1/6 [00:14<01:14, 14.90s/it]\n",
      "       6/10         0G      1.445      3.343      1.413      1.323      8.488      1.322         28        640:  17%|#6        | 1/6 [00:29<01:14, 14.90s/it]\n",
      "       6/10         0G      1.445      3.343      1.413      1.323      8.488      1.322         28        640:  33%|###3      | 2/6 [00:29<00:59, 14.95s/it]\n",
      "       6/10         0G      1.443      3.368      1.445       1.37      9.323      1.406         18        640:  33%|###3      | 2/6 [00:45<00:59, 14.95s/it]\n",
      "       6/10         0G      1.443      3.368      1.445       1.37      9.323      1.406         18        640:  50%|#####     | 3/6 [00:45<00:45, 15.18s/it]\n",
      "       6/10         0G      1.481      3.307      1.462      1.393      8.925       1.39         28        640:  50%|#####     | 3/6 [01:00<00:45, 15.18s/it]\n",
      "       6/10         0G      1.481      3.307      1.462      1.393      8.925       1.39         28        640:  67%|######6   | 4/6 [01:00<00:30, 15.17s/it]\n",
      "       6/10         0G      1.441      3.328      1.433      1.327      8.864      1.345         24        640:  67%|######6   | 4/6 [01:15<00:30, 15.17s/it]\n",
      "       6/10         0G      1.441      3.328      1.433      1.327      8.864      1.345         24        640:  83%|########3 | 5/6 [01:15<00:15, 15.29s/it]\n",
      "       6/10         0G       1.46      3.334      1.447      1.336      8.703      1.345         29        640:  83%|########3 | 5/6 [01:30<00:15, 15.29s/it]\n",
      "       6/10         0G       1.46      3.334      1.447      1.336      8.703      1.345         29        640: 100%|##########| 6/6 [01:30<00:00, 15.12s/it]\n",
      "       6/10         0G       1.46      3.334      1.447      1.336      8.703      1.345         29        640: 100%|##########| 6/6 [01:30<00:00, 15.13s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|###3      | 1/3 [00:17<00:34, 17.21s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|######6   | 2/3 [00:31<00:15, 15.47s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:40<00:00, 12.75s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:40<00:00, 13.66s/it]\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "       7/10         0G      1.431      3.119      1.418      1.251      7.857      1.339         27        640:   0%|          | 0/6 [00:15<?, ?it/s]\n",
      "       7/10         0G      1.431      3.119      1.418      1.251      7.857      1.339         27        640:  17%|#6        | 1/6 [00:15<01:15, 15.09s/it]\n",
      "       7/10         0G       1.63      3.218      1.519      1.449      8.042      1.388         28        640:  17%|#6        | 1/6 [00:30<01:15, 15.09s/it]\n",
      "       7/10         0G       1.63      3.218      1.519      1.449      8.042      1.388         28        640:  33%|###3      | 2/6 [00:30<01:01, 15.37s/it]\n",
      "       7/10         0G      1.603      3.197      1.499      1.429      8.088      1.362         26        640:  33%|###3      | 2/6 [00:46<01:01, 15.37s/it]\n",
      "       7/10         0G      1.603      3.197      1.499      1.429      8.088      1.362         26        640:  50%|#####     | 3/6 [00:46<00:46, 15.38s/it]\n",
      "       7/10         0G      1.561       3.12      1.455      1.369      8.143      1.301         24        640:  50%|#####     | 3/6 [01:01<00:46, 15.38s/it]\n",
      "       7/10         0G      1.561       3.12      1.455      1.369      8.143      1.301         24        640:  67%|######6   | 4/6 [01:01<00:30, 15.23s/it]\n",
      "       7/10         0G      1.574      3.225      1.458      1.392      8.375      1.318         23        640:  67%|######6   | 4/6 [01:16<00:30, 15.23s/it]\n",
      "       7/10         0G      1.574      3.225      1.458      1.392      8.375      1.318         23        640:  83%|########3 | 5/6 [01:16<00:15, 15.28s/it]\n",
      "       7/10         0G       1.53      3.166      1.428      1.382      8.431      1.297         22        640:  83%|########3 | 5/6 [01:30<00:15, 15.28s/it]\n",
      "       7/10         0G       1.53      3.166      1.428      1.382      8.431      1.297         22        640: 100%|##########| 6/6 [01:30<00:00, 14.91s/it]\n",
      "       7/10         0G       1.53      3.166      1.428      1.382      8.431      1.297         22        640: 100%|##########| 6/6 [01:30<00:00, 15.10s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|###3      | 1/3 [00:17<00:34, 17.20s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|######6   | 2/3 [00:31<00:15, 15.46s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:40<00:00, 12.71s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:40<00:00, 13.62s/it]\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "       8/10         0G      1.245      3.351      1.303       1.12      7.732      1.169         28        640:   0%|          | 0/6 [00:15<?, ?it/s]\n",
      "       8/10         0G      1.245      3.351      1.303       1.12      7.732      1.169         28        640:  17%|#6        | 1/6 [00:15<01:16, 15.24s/it]\n",
      "       8/10         0G      1.446      3.271      1.413      1.322      8.684      1.326         21        640:  17%|#6        | 1/6 [00:30<01:16, 15.24s/it]\n",
      "       8/10         0G      1.446      3.271      1.413      1.322      8.684      1.326         21        640:  33%|###3      | 2/6 [00:30<01:00, 15.12s/it]\n",
      "       8/10         0G      1.473       3.15      1.425      1.328       8.49      1.311         25        640:  33%|###3      | 2/6 [00:45<01:00, 15.12s/it]\n",
      "       8/10         0G      1.473       3.15      1.425      1.328       8.49      1.311         25        640:  50%|#####     | 3/6 [00:45<00:45, 15.18s/it]\n",
      "       8/10         0G      1.461      3.126      1.452      1.331      8.519      1.335         23        640:  50%|#####     | 3/6 [01:00<00:45, 15.18s/it]\n",
      "       8/10         0G      1.461      3.126      1.452      1.331      8.519      1.335         23        640:  67%|######6   | 4/6 [01:00<00:30, 15.21s/it]\n",
      "       8/10         0G      1.462      3.074      1.459      1.305      8.429      1.339         25        640:  67%|######6   | 4/6 [01:16<00:30, 15.21s/it]\n",
      "       8/10         0G      1.462      3.074      1.459      1.305      8.429      1.339         25        640:  83%|########3 | 5/6 [01:16<00:15, 15.27s/it]\n",
      "       8/10         0G      1.415      3.047      1.419      1.261      8.232      1.299         28        640:  83%|########3 | 5/6 [01:31<00:15, 15.27s/it]\n",
      "       8/10         0G      1.415      3.047      1.419      1.261      8.232      1.299         28        640: 100%|##########| 6/6 [01:31<00:00, 15.21s/it]\n",
      "       8/10         0G      1.415      3.047      1.419      1.261      8.232      1.299         28        640: 100%|##########| 6/6 [01:31<00:00, 15.21s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|###3      | 1/3 [00:17<00:34, 17.28s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|######6   | 2/3 [00:31<00:15, 15.46s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:40<00:00, 12.71s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:40<00:00, 13.64s/it]\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "       9/10         0G      1.272      2.853      1.262      1.211      9.265       1.21         20        640:   0%|          | 0/6 [00:15<?, ?it/s]\n",
      "       9/10         0G      1.272      2.853      1.262      1.211      9.265       1.21         20        640:  17%|#6        | 1/6 [00:15<01:15, 15.20s/it]\n",
      "       9/10         0G      1.343      2.831      1.346      1.208       9.06      1.235         22        640:  17%|#6        | 1/6 [00:30<01:15, 15.20s/it]\n",
      "       9/10         0G      1.343      2.831      1.346      1.208       9.06      1.235         22        640:  33%|###3      | 2/6 [00:30<01:00, 15.21s/it]\n",
      "       9/10         0G      1.394      2.934      1.332      1.283      8.736      1.226         28        640:  33%|###3      | 2/6 [00:45<01:00, 15.21s/it]\n",
      "       9/10         0G      1.394      2.934      1.332      1.283      8.736      1.226         28        640:  50%|#####     | 3/6 [00:45<00:45, 15.28s/it]\n",
      "       9/10         0G      1.428      2.934      1.367      1.334      8.425      1.269         29        640:  50%|#####     | 3/6 [01:01<00:45, 15.28s/it]\n",
      "       9/10         0G      1.428      2.934      1.367      1.334      8.425      1.269         29        640:  67%|######6   | 4/6 [01:01<00:30, 15.26s/it]\n",
      "       9/10         0G      1.441      2.977      1.355      1.338       8.34       1.27         26        640:  67%|######6   | 4/6 [01:16<00:30, 15.26s/it]\n",
      "       9/10         0G      1.441      2.977      1.355      1.338       8.34       1.27         26        640:  83%|########3 | 5/6 [01:16<00:15, 15.41s/it]\n",
      "       9/10         0G      1.445      3.004      1.369       1.34      8.305      1.289         25        640:  83%|########3 | 5/6 [01:30<00:15, 15.41s/it]\n",
      "       9/10         0G      1.445      3.004      1.369       1.34      8.305      1.289         25        640: 100%|##########| 6/6 [01:30<00:00, 14.87s/it]\n",
      "       9/10         0G      1.445      3.004      1.369       1.34      8.305      1.289         25        640: 100%|##########| 6/6 [01:30<00:00, 15.08s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|###3      | 1/3 [00:17<00:34, 17.37s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|######6   | 2/3 [00:31<00:15, 15.55s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:41<00:00, 12.79s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:41<00:00, 13.72s/it]\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "      10/10         0G      1.405      3.473      1.154      1.302      7.334      1.094         31        640:   0%|          | 0/6 [00:15<?, ?it/s]\n",
      "      10/10         0G      1.405      3.473      1.154      1.302      7.334      1.094         31        640:  17%|#6        | 1/6 [00:15<01:16, 15.31s/it]\n",
      "      10/10         0G      1.434      3.161      1.315      1.355      7.592      1.263         26        640:  17%|#6        | 1/6 [00:30<01:16, 15.31s/it]\n",
      "      10/10         0G      1.434      3.161      1.315      1.355      7.592      1.263         26        640:  33%|###3      | 2/6 [00:30<01:01, 15.31s/it]\n",
      "      10/10         0G      1.379      3.053      1.302      1.248      7.394      1.212         30        640:  33%|###3      | 2/6 [00:46<01:01, 15.31s/it]\n",
      "      10/10         0G      1.379      3.053      1.302      1.248      7.394      1.212         30        640:  50%|#####     | 3/6 [00:46<00:46, 15.35s/it]\n",
      "      10/10         0G      1.383      3.096      1.324      1.291      7.822      1.247         22        640:  50%|#####     | 3/6 [01:01<00:46, 15.35s/it]\n",
      "      10/10         0G      1.383      3.096      1.324      1.291      7.822      1.247         22        640:  67%|######6   | 4/6 [01:01<00:30, 15.25s/it]\n",
      "      10/10         0G      1.386      3.029      1.334      1.298      8.066      1.258         21        640:  67%|######6   | 4/6 [01:16<00:30, 15.25s/it]\n",
      "      10/10         0G      1.386      3.029      1.334      1.298      8.066      1.258         21        640:  83%|########3 | 5/6 [01:16<00:15, 15.25s/it]\n",
      "      10/10         0G      1.367      2.974      1.349      1.295      8.258      1.272         20        640:  83%|########3 | 5/6 [01:30<00:15, 15.25s/it]\n",
      "      10/10         0G      1.367      2.974      1.349      1.295      8.258      1.272         20        640: 100%|##########| 6/6 [01:30<00:00, 14.79s/it]\n",
      "      10/10         0G      1.367      2.974      1.349      1.295      8.258      1.272         20        640: 100%|##########| 6/6 [01:30<00:00, 15.04s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|###3      | 1/3 [00:17<00:34, 17.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|######6   | 2/3 [00:31<00:15, 15.56s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:41<00:00, 12.80s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:41<00:00, 13.72s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|###3      | 1/3 [00:14<00:29, 14.51s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|######6   | 2/3 [00:26<00:13, 13.07s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:35<00:00, 10.97s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:35<00:00, 11.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt, data=C:/Users/sshiv/Desktop/sihProject/data.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, val_period=1, cache=False, device=None, workers=8, project=None, name=train9, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=C:\\Users\\sshiv\\runs\\detect\\train9\n",
      "Overriding model.yaml nc=80 with nc=9\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1      9856  ultralytics.nn.modules.block.SCDown          [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.PSA             [256, 256]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 20                  -1  1     18048  ultralytics.nn.modules.block.SCDown          [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    282624  ultralytics.nn.modules.block.C2fCIB          [384, 256, 1, True, True]     \n",
      " 23        [16, 19, 22]  1    864838  ultralytics.nn.modules.head.v10Detect        [9, [64, 128, 256]]           \n",
      "YOLOv10n summary: 385 layers, 2710550 parameters, 2710534 gradients, 8.4 GFLOPs\n",
      "\n",
      "Transferred 493/595 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "Plotting labels to C:\\Users\\sshiv\\runs\\detect\\train9\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000769, momentum=0.9) with parameter groups 95 weight(decay=0.0), 108 weight(decay=0.0005), 107 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\train9\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         96        150    0.00149     0.0871    0.00222   0.000889\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         96        150     0.0179      0.241     0.0224     0.0113\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         96        150     0.0129       0.51      0.043     0.0237\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         96        150     0.0107      0.608     0.0479     0.0284\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         96        150    0.00947      0.697     0.0517     0.0306\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         96        150    0.00876      0.825     0.0576     0.0356\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         96        150    0.00815      0.937     0.0674     0.0406\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         96        150     0.0074      0.836      0.075     0.0448\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         96        150    0.00692      0.827     0.0893     0.0548\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         96        150    0.00634      0.829     0.0937     0.0598\n",
      "\n",
      "10 epochs completed in 0.372 hours.\n",
      "Optimizer stripped from C:\\Users\\sshiv\\runs\\detect\\train9\\weights\\last.pt, 5.7MB\n",
      "Optimizer stripped from C:\\Users\\sshiv\\runs\\detect\\train9\\weights\\best.pt, 5.7MB\n",
      "\n",
      "Validating C:\\Users\\sshiv\\runs\\detect\\train9\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "                   all         96        150    0.00633      0.829     0.0934     0.0596\n",
      "             Shivanshu         96         79     0.0204      0.987      0.454      0.294\n",
      "                Krishn         96         33     0.0117       0.97      0.226      0.141\n",
      "              Yashwant         96         12     0.0124       0.75     0.0229     0.0128\n",
      "                 Sumit         96          4    0.00523          1     0.0235     0.0136\n",
      "                 Shubh         96          4   0.000473          1    0.00721    0.00315\n",
      "              Gurpreet         96          4    0.00133       0.75    0.00686    0.00363\n",
      "                Aviral         96          5    0.00265          1     0.0282     0.0173\n",
      "                  Aman         96          8    0.00278          1     0.0722     0.0513\n",
      "               Shreyas         96          1          0          0          0          0\n",
      "Speed: 5.3ms preprocess, 225.4ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\train9\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=train epochs=10 batch=16  plots=True model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt data=C:/Users/sshiv/Desktop/sihProject/data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8538f565-76bb-44e0-8175-8dc48aedb676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "image 1/1 C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\5.jpg: 640x480 (no detections), 181.8ms\n",
      "Speed: 0.0ms preprocess, 181.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\predict6\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.05 save=True model=C:\\Users\\sshiv\\runs\\detect\\train9\\weights\\best.pt source=test_images/5.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cacd523f-7fc3-46cc-bb8f-7e1109219ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "image 1/1 C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\3.jpg: 640x384 (no detections), 138.8ms\n",
      "Speed: 4.3ms preprocess, 138.8ms inference, 8.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\predict7\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.05 save=True model=C:\\Users\\sshiv\\runs\\detect\\train9\\weights\\best.pt source=test_images/3.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e290d624-a082-45d7-b994-98e96f9bb6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "image 1/1 C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\5.jpg: 640x480 (no detections), 177.2ms\n",
      "Speed: 0.0ms preprocess, 177.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\predict8\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.25 save=True model=C:\\Users\\sshiv\\runs\\detect\\train9\\weights\\best.pt source=test_images/5.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f3ec12d-20ae-4a3a-af11-db35d31ae55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "image 1/1 C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\3.jpg: 640x384 (no detections), 144.3ms\n",
      "Speed: 1.2ms preprocess, 144.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\predict9\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.05 save=True model=C:\\Users\\sshiv\\runs\\detect\\train9\\weights\\best.pt source=test_images/3.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cbee44e-4a28-45ac-9313-e735e79dc2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "image 1/1 C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\3.jpg: 640x384 (no detections), 143.0ms\n",
      "Speed: 0.0ms preprocess, 143.0ms inference, 6.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\predict10\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.25 save=True model=C:\\Users\\sshiv\\runs\\detect\\train9\\weights\\best.pt source=test_images/3.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df7a67cb-6751-4572-bca5-a7fe75fcb67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "image 1/1 C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\2.jpg: 384x640 (no detections), 142.7ms\n",
      "Speed: 4.0ms preprocess, 142.7ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\predict11\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.25 save=True model=C:\\Users\\sshiv\\runs\\detect\\train9\\weights\\best.pt source=test_images/2.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96cbe6d7-bdfe-45be-9b0f-34b3df88e29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "image 1/1 C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\2.jpg: 384x640 (no detections), 148.7ms\n",
      "Speed: 1.2ms preprocess, 148.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\predict12\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.05 save=True model=C:\\Users\\sshiv\\runs\\detect\\train9\\weights\\best.pt source=test_images/2.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e2c1fbd-32b7-486b-a92c-b2d1217328c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.81 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt, data=C:/Users/sshiv/Desktop/sihProject/data.yaml, epochs=20, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, val_period=1, cache=False, device=None, workers=8, project=None, name=train10, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=C:\\Users\\sshiv\\runs\\detect\\train10\n",
      "Overriding model.yaml nc=80 with nc=9\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1      9856  ultralytics.nn.modules.block.SCDown          [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.PSA             [256, 256]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 20                  -1  1     18048  ultralytics.nn.modules.block.SCDown          [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    282624  ultralytics.nn.modules.block.C2fCIB          [384, 256, 1, True, True]     \n",
      " 23        [16, 19, 22]  1    864838  ultralytics.nn.modules.head.v10Detect        [9, [64, 128, 256]]           \n",
      "YOLOv10n summary: 385 layers, 2710550 parameters, 2710534 gradients, 8.4 GFLOPs\n",
      "\n",
      "Transferred 493/595 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "Plotting labels to C:\\Users\\sshiv\\runs\\detect\\train10\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000769, momentum=0.9) with parameter groups 95 weight(decay=0.0), 108 weight(decay=0.0005), 107 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\train10\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         96        150    0.00198       0.09    0.00274    0.00103\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         96        150      0.021       0.21     0.0258     0.0121\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         96        150     0.0143      0.302     0.0357     0.0199\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         96        150     0.0101      0.483     0.0383      0.023\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         96        150    0.00826      0.546     0.0383     0.0241\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         96        150    0.00882      0.673      0.046      0.028\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         96        150     0.0086      0.838     0.0546     0.0318\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         96        150    0.00757      0.795     0.0703     0.0405\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         96        150    0.00682      0.802     0.0837     0.0535\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         96        150    0.00638      0.945      0.107     0.0641\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         96        150    0.00593      0.919      0.109     0.0601\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         96        150    0.00567      0.808      0.126      0.079\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         96        150    0.00549      0.815      0.181      0.116\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         96        150          1     0.0277      0.206      0.133\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         96        150      0.993     0.0394      0.214      0.142\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         96        150      0.972      0.052      0.246      0.158\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         96        150      0.972     0.0585      0.259      0.165\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         96        150      0.955     0.0668      0.299      0.196\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         96        150      0.953      0.067      0.301      0.202\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "                   all         96        150      0.953      0.082      0.292      0.193\n",
      "\n",
      "20 epochs completed in 0.824 hours.\n",
      "Optimizer stripped from C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\last.pt, 5.7MB\n",
      "Optimizer stripped from C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt, 5.7MB\n",
      "\n",
      "Validating C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "                   all         96        150      0.953     0.0674      0.299      0.201\n",
      "             Shivanshu         96         79      0.814      0.506      0.762      0.529\n",
      "                Krishn         96         33      0.765        0.1      0.454      0.352\n",
      "              Yashwant         96         12          1          0      0.177      0.112\n",
      "                 Sumit         96          4          1          0     0.0308     0.0222\n",
      "                 Shubh         96          4          1          0       0.54      0.369\n",
      "              Gurpreet         96          4          1          0          0          0\n",
      "                Aviral         96          5          1          0      0.465      0.264\n",
      "                  Aman         96          8          1          0      0.258       0.16\n",
      "               Shreyas         96          1          1          0          0          0\n",
      "Speed: 3.8ms preprocess, 140.7ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\train10\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n",
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:276: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\train\\labels.cache... 95 images, 1 backgrounds, 0 corrupt: 100%|##########| 96/96 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\train\\labels.cache... 95 images, 1 backgrounds, 0 corrupt: 100%|##########| 96/96 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\valid\\labels.cache... 95 images, 1 backgrounds, 0 corrupt: 100%|##########| 96/96 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\sshiv\\Desktop\\sihProject\\custom_dataset\\valid\\labels.cache... 95 images, 1 backgrounds, 0 corrupt: 100%|##########| 96/96 [00:00<?, ?it/s]\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "       1/20         0G      1.974      4.313      1.832      1.598       6.76      1.676         53        640:   0%|          | 0/6 [00:17<?, ?it/s]\n",
      "       1/20         0G      1.974      4.313      1.832      1.598       6.76      1.676         53        640:  17%|#6        | 1/6 [00:17<01:27, 17.56s/it]\n",
      "       1/20         0G      1.954      4.435      1.837      1.631      7.153      1.641         44        640:  17%|#6        | 1/6 [00:35<01:27, 17.56s/it]\n",
      "       1/20         0G      1.954      4.435      1.837      1.631      7.153      1.641         44        640:  33%|###3      | 2/6 [00:35<01:10, 17.55s/it]\n",
      "       1/20         0G      1.969       4.44      1.897      1.651      7.331      1.657         41        640:  33%|###3      | 2/6 [00:52<01:10, 17.55s/it]\n",
      "       1/20         0G      1.969       4.44      1.897      1.651      7.331      1.657         41        640:  50%|#####     | 3/6 [00:52<00:52, 17.57s/it]\n",
      "       1/20         0G      1.928      4.409      1.889       1.62      7.272      1.662         47        640:  50%|#####     | 3/6 [01:10<00:52, 17.57s/it]\n",
      "       1/20         0G      1.928      4.409      1.889       1.62      7.272      1.662         47        640:  67%|######6   | 4/6 [01:10<00:35, 17.58s/it]\n",
      "       1/20         0G      1.869      4.403      1.846      1.573      7.328      1.624         40        640:  67%|######6   | 4/6 [01:27<00:35, 17.58s/it]\n",
      "       1/20         0G      1.869      4.403      1.846      1.573      7.328      1.624         40        640:  83%|########3 | 5/6 [01:27<00:17, 17.51s/it]\n",
      "       1/20         0G      1.878      4.452      1.826      1.612      7.445      1.612         41        640:  83%|########3 | 5/6 [01:45<00:17, 17.51s/it]\n",
      "       1/20         0G      1.878      4.452      1.826      1.612      7.445      1.612         41        640: 100%|##########| 6/6 [01:45<00:00, 17.53s/it]\n",
      "       1/20         0G      1.878      4.452      1.826      1.612      7.445      1.612         41        640: 100%|##########| 6/6 [01:45<00:00, 17.54s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|###3      | 1/3 [00:16<00:33, 16.94s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|######6   | 2/3 [00:31<00:15, 15.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:40<00:00, 12.64s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:40<00:00, 13.52s/it]\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "       2/20         0G      1.873       4.45      1.919       1.56      7.696      1.684         40        640:   0%|          | 0/6 [00:15<?, ?it/s]\n",
      "       2/20         0G      1.873       4.45      1.919       1.56      7.696      1.684         40        640:  17%|#6        | 1/6 [00:15<01:16, 15.27s/it]\n",
      "       2/20         0G       1.74      4.425      1.808      1.494      8.039      1.615         33        640:  17%|#6        | 1/6 [00:30<01:16, 15.27s/it]\n",
      "       2/20         0G       1.74      4.425      1.808      1.494      8.039      1.615         33        640:  33%|###3      | 2/6 [00:30<01:01, 15.29s/it]\n",
      "       2/20         0G      1.663      4.397      1.729       1.45      7.645      1.526         48        640:  33%|###3      | 2/6 [00:45<01:01, 15.29s/it]\n",
      "       2/20         0G      1.663      4.397      1.729       1.45      7.645      1.526         48        640:  50%|#####     | 3/6 [00:45<00:45, 15.27s/it]\n",
      "       2/20         0G      1.646      4.335      1.693      1.417      7.452      1.488         48        640:  50%|#####     | 3/6 [01:01<00:45, 15.27s/it]\n",
      "       2/20         0G      1.646      4.335      1.693      1.417      7.452      1.488         48        640:  67%|######6   | 4/6 [01:01<00:30, 15.33s/it]\n",
      "       2/20         0G      1.645      4.298       1.67      1.395      7.144      1.465         69        640:  67%|######6   | 4/6 [01:17<00:30, 15.33s/it]\n",
      "       2/20         0G      1.645      4.298       1.67      1.395      7.144      1.465         69        640:  83%|########3 | 5/6 [01:17<00:15, 15.49s/it]\n",
      "       2/20         0G      1.632      4.267      1.643      1.382      7.029      1.452         54        640:  83%|########3 | 5/6 [01:32<00:15, 15.49s/it]\n",
      "       2/20         0G      1.632      4.267      1.643      1.382      7.029      1.452         54        640: 100%|##########| 6/6 [01:32<00:00, 15.46s/it]\n",
      "       2/20         0G      1.632      4.267      1.643      1.382      7.029      1.452         54        640: 100%|##########| 6/6 [01:32<00:00, 15.40s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|###3      | 1/3 [00:17<00:34, 17.19s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|######6   | 2/3 [00:31<00:15, 15.58s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:41<00:00, 12.78s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:41<00:00, 13.70s/it]\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "       3/20         0G      1.576      4.027      1.628      1.372       6.72      1.405         46        640:   0%|          | 0/6 [00:15<?, ?it/s]\n",
      "       3/20         0G      1.576      4.027      1.628      1.372       6.72      1.405         46        640:  17%|#6        | 1/6 [00:15<01:17, 15.44s/it]\n",
      "       3/20         0G       1.53      3.958      1.607      1.304      6.837      1.415         41        640:  17%|#6        | 1/6 [00:30<01:17, 15.44s/it]\n",
      "       3/20         0G       1.53      3.958      1.607      1.304      6.837      1.415         41        640:  33%|###3      | 2/6 [00:30<01:00, 15.22s/it]\n",
      "       3/20         0G       1.51      3.917      1.561      1.316      6.638      1.385         54        640:  33%|###3      | 2/6 [00:45<01:00, 15.22s/it]\n",
      "       3/20         0G       1.51      3.917      1.561      1.316      6.638      1.385         54        640:  50%|#####     | 3/6 [00:45<00:45, 15.18s/it]\n",
      "       3/20         0G      1.502      3.889      1.521       1.31      6.653      1.353         45        640:  50%|#####     | 3/6 [01:00<00:45, 15.18s/it]\n",
      "       3/20         0G      1.502      3.889      1.521       1.31      6.653      1.353         45        640:  67%|######6   | 4/6 [01:00<00:30, 15.16s/it]\n",
      "       3/20         0G      1.499      3.851      1.499      1.309      6.549      1.336         51        640:  67%|######6   | 4/6 [01:16<00:30, 15.16s/it]\n",
      "       3/20         0G      1.499      3.851      1.499      1.309      6.549      1.336         51        640:  83%|########3 | 5/6 [01:16<00:15, 15.28s/it]\n",
      "       3/20         0G      1.466      3.802      1.474      1.286      6.527      1.335         44        640:  83%|########3 | 5/6 [01:31<00:15, 15.28s/it]\n",
      "       3/20         0G      1.466      3.802      1.474      1.286      6.527      1.335         44        640: 100%|##########| 6/6 [01:31<00:00, 15.40s/it]\n",
      "       3/20         0G      1.466      3.802      1.474      1.286      6.527      1.335         44        640: 100%|##########| 6/6 [01:31<00:00, 15.31s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|###3      | 1/3 [00:17<00:34, 17.26s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|######6   | 2/3 [00:31<00:15, 15.54s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:41<00:00, 12.83s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:41<00:00, 13.73s/it]\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "       4/20         0G      1.546      3.626      1.443      1.366      6.233      1.236         48        640:   0%|          | 0/6 [00:15<?, ?it/s]\n",
      "       4/20         0G      1.546      3.626      1.443      1.366      6.233      1.236         48        640:  17%|#6        | 1/6 [00:15<01:16, 15.35s/it]\n",
      "       4/20         0G      1.589      3.718      1.404      1.433      6.131      1.243         56        640:  17%|#6        | 1/6 [00:30<01:16, 15.35s/it]\n",
      "       4/20         0G      1.589      3.718      1.404      1.433      6.131      1.243         56        640:  33%|###3      | 2/6 [00:30<01:01, 15.32s/it]\n",
      "       4/20         0G      1.521      3.631      1.399      1.369      6.234       1.27         42        640:  33%|###3      | 2/6 [00:45<01:01, 15.32s/it]\n",
      "       4/20         0G      1.521      3.631      1.399      1.369      6.234       1.27         42        640:  50%|#####     | 3/6 [00:45<00:45, 15.30s/it]\n",
      "       4/20         0G      1.503      3.599       1.39      1.372      6.126      1.266         53        640:  50%|#####     | 3/6 [01:01<00:45, 15.30s/it]\n",
      "       4/20         0G      1.503      3.599       1.39      1.372      6.126      1.266         53        640:  67%|######6   | 4/6 [01:01<00:30, 15.37s/it]\n",
      "       4/20         0G      1.522      3.553      1.414      1.393      6.213      1.302         41        640:  67%|######6   | 4/6 [01:16<00:30, 15.37s/it]\n",
      "       4/20         0G      1.522      3.553      1.414      1.393      6.213      1.302         41        640:  83%|########3 | 5/6 [01:16<00:15, 15.43s/it]\n",
      "       4/20         0G      1.516      3.542      1.407      1.394      6.135      1.291         52        640:  83%|########3 | 5/6 [01:32<00:15, 15.43s/it]\n",
      "       4/20         0G      1.516      3.542      1.407      1.394      6.135      1.291         52        640: 100%|##########| 6/6 [01:32<00:00, 15.33s/it]\n",
      "       4/20         0G      1.516      3.542      1.407      1.394      6.135      1.291         52        640: 100%|##########| 6/6 [01:32<00:00, 15.35s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|###3      | 1/3 [00:17<00:34, 17.17s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|######6   | 2/3 [00:31<00:15, 15.33s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:40<00:00, 12.57s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:40<00:00, 13.50s/it]\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "       5/20         0G      1.408      3.415      1.357      1.253       6.04      1.224         45        640:   0%|          | 0/6 [00:15<?, ?it/s]\n",
      "       5/20         0G      1.408      3.415      1.357      1.253       6.04      1.224         45        640:  17%|#6        | 1/6 [00:15<01:15, 15.06s/it]\n",
      "       5/20         0G      1.449      3.397      1.368      1.288      6.193      1.248         43        640:  17%|#6        | 1/6 [00:30<01:15, 15.06s/it]\n",
      "       5/20         0G      1.449      3.397      1.368      1.288      6.193      1.248         43        640:  33%|###3      | 2/6 [00:30<01:00, 15.13s/it]\n",
      "       5/20         0G       1.43      3.273      1.341      1.305      5.955      1.238         50        640:  33%|###3      | 2/6 [00:45<01:00, 15.13s/it]\n",
      "       5/20         0G       1.43      3.273      1.341      1.305      5.955      1.238         50        640:  50%|#####     | 3/6 [00:45<00:45, 15.04s/it]\n",
      "       5/20         0G      1.449      3.176      1.342       1.35      5.875      1.237         47        640:  50%|#####     | 3/6 [01:00<00:45, 15.04s/it]\n",
      "       5/20         0G      1.449      3.176      1.342       1.35      5.875      1.237         47        640:  67%|######6   | 4/6 [01:00<00:30, 15.07s/it]\n",
      "       5/20         0G      1.466       3.15      1.375      1.336      5.828      1.263         49        640:  67%|######6   | 4/6 [01:15<00:30, 15.07s/it]\n",
      "       5/20         0G      1.466       3.15      1.375      1.336      5.828      1.263         49        640:  83%|########3 | 5/6 [01:15<00:15, 15.12s/it]\n",
      "       5/20         0G      1.517      3.177      1.396      1.394       5.93      1.295         46        640:  83%|########3 | 5/6 [01:30<00:15, 15.12s/it]\n",
      "       5/20         0G      1.517      3.177      1.396      1.394       5.93      1.295         46        640: 100%|##########| 6/6 [01:30<00:00, 15.16s/it]\n",
      "       5/20         0G      1.517      3.177      1.396      1.394       5.93      1.295         46        640: 100%|##########| 6/6 [01:30<00:00, 15.13s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|###3      | 1/3 [00:16<00:33, 16.87s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|######6   | 2/3 [00:31<00:15, 15.27s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:40<00:00, 12.54s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:40<00:00, 13.44s/it]\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "       6/20         0G      1.716      3.071       1.64      1.686      6.109      1.559         44        640:   0%|          | 0/6 [00:15<?, ?it/s]\n",
      "       6/20         0G      1.716      3.071       1.64      1.686      6.109      1.559         44        640:  17%|#6        | 1/6 [00:15<01:15, 15.13s/it]\n",
      "       6/20         0G       1.65      3.123      1.548      1.542      6.119      1.434         46        640:  17%|#6        | 1/6 [00:29<01:15, 15.13s/it]\n",
      "       6/20         0G       1.65      3.123      1.548      1.542      6.119      1.434         46        640:  33%|###3      | 2/6 [00:29<00:59, 14.93s/it]\n",
      "       6/20         0G      1.612      3.097      1.507       1.47      6.182      1.419         40        640:  33%|###3      | 2/6 [00:44<00:59, 14.93s/it]\n",
      "       6/20         0G      1.612      3.097      1.507       1.47      6.182      1.419         40        640:  50%|#####     | 3/6 [00:44<00:44, 14.85s/it]\n",
      "       6/20         0G      1.552      3.107      1.461      1.424       5.89      1.372         66        640:  50%|#####     | 3/6 [00:58<00:44, 14.85s/it]\n",
      "       6/20         0G      1.552      3.107      1.461      1.424       5.89      1.372         66        640:  67%|######6   | 4/6 [00:58<00:28, 14.47s/it]\n",
      "       6/20         0G      1.559      3.075      1.447      1.403        5.7      1.362         61        640:  67%|######6   | 4/6 [01:13<00:28, 14.47s/it]\n",
      "       6/20         0G      1.559      3.075      1.447      1.403        5.7      1.362         61        640:  83%|########3 | 5/6 [01:13<00:14, 14.78s/it]\n",
      "       6/20         0G      1.554      3.033      1.423      1.397       5.59       1.34         59        640:  83%|########3 | 5/6 [01:29<00:14, 14.78s/it]\n",
      "       6/20         0G      1.554      3.033      1.423      1.397       5.59       1.34         59        640: 100%|##########| 6/6 [01:29<00:00, 14.98s/it]\n",
      "       6/20         0G      1.554      3.033      1.423      1.397       5.59       1.34         59        640: 100%|##########| 6/6 [01:29<00:00, 14.88s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|###3      | 1/3 [00:16<00:33, 16.57s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|######6   | 2/3 [00:28<00:14, 14.08s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:38<00:00, 11.92s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:38<00:00, 12.75s/it]\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "       7/20         0G      1.609      2.878      1.462      1.541      5.255      1.395         56        640:   0%|          | 0/6 [00:15<?, ?it/s]\n",
      "       7/20         0G      1.609      2.878      1.462      1.541      5.255      1.395         56        640:  17%|#6        | 1/6 [00:15<01:17, 15.41s/it]\n",
      "       7/20         0G      1.537      2.794      1.414      1.434      5.142      1.318         54        640:  17%|#6        | 1/6 [00:30<01:17, 15.41s/it]\n",
      "       7/20         0G      1.537      2.794      1.414      1.434      5.142      1.318         54        640:  33%|###3      | 2/6 [00:30<01:00, 15.22s/it]\n",
      "       7/20         0G      1.539      2.786      1.416       1.44      5.618      1.351         37        640:  33%|###3      | 2/6 [00:45<01:00, 15.22s/it]\n",
      "       7/20         0G      1.539      2.786      1.416       1.44      5.618      1.351         37        640:  50%|#####     | 3/6 [00:45<00:45, 15.04s/it]\n",
      "       7/20         0G       1.56      2.835      1.419      1.449      5.654      1.343         47        640:  50%|#####     | 3/6 [01:00<00:45, 15.04s/it]\n",
      "       7/20         0G       1.56      2.835      1.419      1.449      5.654      1.343         47        640:  67%|######6   | 4/6 [01:00<00:30, 15.05s/it]\n",
      "       7/20         0G       1.55      2.788      1.413      1.429      5.536      1.325         54        640:  67%|######6   | 4/6 [01:16<00:30, 15.05s/it]\n",
      "       7/20         0G       1.55      2.788      1.413      1.429      5.536      1.325         54        640:  83%|########3 | 5/6 [01:16<00:15, 15.27s/it]\n",
      "       7/20         0G      1.519      2.773        1.4      1.399      5.622      1.312         39        640:  83%|########3 | 5/6 [01:31<00:15, 15.27s/it]\n",
      "       7/20         0G      1.519      2.773        1.4      1.399      5.622      1.312         39        640: 100%|##########| 6/6 [01:31<00:00, 15.26s/it]\n",
      "       7/20         0G      1.519      2.773        1.4      1.399      5.622      1.312         39        640: 100%|##########| 6/6 [01:31<00:00, 15.22s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|###3      | 1/3 [00:16<00:33, 16.96s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|######6   | 2/3 [00:30<00:14, 14.97s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:39<00:00, 12.37s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:39<00:00, 13.27s/it]\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "       8/20         0G       1.45      2.538      1.341      1.344      4.834      1.247         60        640:   0%|          | 0/6 [00:15<?, ?it/s]\n",
      "       8/20         0G       1.45      2.538      1.341      1.344      4.834      1.247         60        640:  17%|#6        | 1/6 [00:15<01:17, 15.55s/it]\n",
      "       8/20         0G      1.432      2.679      1.376      1.323      5.163      1.271         47        640:  17%|#6        | 1/6 [00:30<01:17, 15.55s/it]\n",
      "       8/20         0G      1.432      2.679      1.376      1.323      5.163      1.271         47        640:  33%|###3      | 2/6 [00:30<01:01, 15.25s/it]\n",
      "       8/20         0G       1.45      2.749      1.373      1.326       5.19      1.253         53        640:  33%|###3      | 2/6 [00:45<01:01, 15.25s/it]\n",
      "       8/20         0G       1.45      2.749      1.373      1.326       5.19      1.253         53        640:  50%|#####     | 3/6 [00:45<00:45, 15.01s/it]\n",
      "       8/20         0G      1.459      2.688        1.4      1.321      5.163      1.274         52        640:  50%|#####     | 3/6 [01:00<00:45, 15.01s/it]\n",
      "       8/20         0G      1.459      2.688        1.4      1.321      5.163      1.274         52        640:  67%|######6   | 4/6 [01:00<00:30, 15.06s/it]\n",
      "       8/20         0G      1.467      2.694      1.395      1.329       5.17      1.254         52        640:  67%|######6   | 4/6 [01:15<00:30, 15.06s/it]\n",
      "       8/20         0G      1.467      2.694      1.395      1.329       5.17      1.254         52        640:  83%|########3 | 5/6 [01:15<00:15, 15.17s/it]\n",
      "       8/20         0G      1.448      2.657      1.386      1.315      5.134      1.251         52        640:  83%|########3 | 5/6 [01:31<00:15, 15.17s/it]\n",
      "       8/20         0G      1.448      2.657      1.386      1.315      5.134      1.251         52        640: 100%|##########| 6/6 [01:31<00:00, 15.19s/it]\n",
      "       8/20         0G      1.448      2.657      1.386      1.315      5.134      1.251         52        640: 100%|##########| 6/6 [01:31<00:00, 15.18s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|###3      | 1/3 [00:17<00:34, 17.05s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|######6   | 2/3 [00:30<00:15, 15.01s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:40<00:00, 12.51s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:40<00:00, 13.39s/it]\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "       9/20         0G      1.544      2.823       1.44      1.249      5.283      1.236         53        640:   0%|          | 0/6 [00:15<?, ?it/s]\n",
      "       9/20         0G      1.544      2.823       1.44      1.249      5.283      1.236         53        640:  17%|#6        | 1/6 [00:15<01:15, 15.14s/it]\n",
      "       9/20         0G      1.514      2.672      1.435      1.321      5.364      1.245         45        640:  17%|#6        | 1/6 [00:30<01:15, 15.14s/it]\n",
      "       9/20         0G      1.514      2.672      1.435      1.321      5.364      1.245         45        640:  33%|###3      | 2/6 [00:30<01:00, 15.09s/it]\n",
      "       9/20         0G      1.535      2.809      1.502      1.399      6.085      1.306         31        640:  33%|###3      | 2/6 [00:44<01:00, 15.09s/it]\n",
      "       9/20         0G      1.535      2.809      1.502      1.399      6.085      1.306         31        640:  50%|#####     | 3/6 [00:44<00:44, 14.95s/it]\n",
      "       9/20         0G      1.508       2.78      1.452      1.396      5.878       1.27         54        640:  50%|#####     | 3/6 [01:00<00:44, 14.95s/it]\n",
      "       9/20         0G      1.508       2.78      1.452      1.396      5.878       1.27         54        640:  67%|######6   | 4/6 [01:00<00:30, 15.11s/it]\n",
      "       9/20         0G      1.531       2.76      1.435      1.428      5.641       1.27         70        640:  67%|######6   | 4/6 [01:15<00:30, 15.11s/it]\n",
      "       9/20         0G      1.531       2.76      1.435      1.428      5.641       1.27         70        640:  83%|########3 | 5/6 [01:15<00:15, 15.26s/it]\n",
      "       9/20         0G      1.533      2.742      1.424      1.426      5.529       1.27         57        640:  83%|########3 | 5/6 [01:31<00:15, 15.26s/it]\n",
      "       9/20         0G      1.533      2.742      1.424      1.426      5.529       1.27         57        640: 100%|##########| 6/6 [01:31<00:00, 15.30s/it]\n",
      "       9/20         0G      1.533      2.742      1.424      1.426      5.529       1.27         57        640: 100%|##########| 6/6 [01:31<00:00, 15.21s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|###3      | 1/3 [00:17<00:34, 17.05s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|######6   | 2/3 [00:30<00:15, 15.22s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:40<00:00, 12.56s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:40<00:00, 13.46s/it]\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "      10/20         0G      1.389      2.565       1.32      1.241      5.015       1.21         55        640:   0%|          | 0/6 [00:15<?, ?it/s]\n",
      "      10/20         0G      1.389      2.565       1.32      1.241      5.015       1.21         55        640:  17%|#6        | 1/6 [00:15<01:16, 15.22s/it]\n",
      "      10/20         0G      1.342       2.37      1.353      1.192      5.038      1.231         46        640:  17%|#6        | 1/6 [00:30<01:16, 15.22s/it]\n",
      "      10/20         0G      1.342       2.37      1.353      1.192      5.038      1.231         46        640:  33%|###3      | 2/6 [00:30<01:00, 15.08s/it]\n",
      "      10/20         0G      1.421       2.51      1.363      1.281      4.971      1.223         67        640:  33%|###3      | 2/6 [00:45<01:00, 15.08s/it]\n",
      "      10/20         0G      1.421       2.51      1.363      1.281      4.971      1.223         67        640:  50%|#####     | 3/6 [00:45<00:45, 15.04s/it]\n",
      "      10/20         0G      1.403      2.466      1.357      1.264      4.908      1.212         56        640:  50%|#####     | 3/6 [01:00<00:45, 15.04s/it]\n",
      "      10/20         0G      1.403      2.466      1.357      1.264      4.908      1.212         56        640:  67%|######6   | 4/6 [01:00<00:30, 15.13s/it]\n",
      "      10/20         0G      1.387      2.453      1.358      1.266      4.931      1.222         50        640:  67%|######6   | 4/6 [01:15<00:30, 15.13s/it]\n",
      "      10/20         0G      1.387      2.453      1.358      1.266      4.931      1.222         50        640:  83%|########3 | 5/6 [01:15<00:15, 15.13s/it]\n",
      "      10/20         0G      1.377      2.478      1.348      1.249      4.895      1.212         60        640:  83%|########3 | 5/6 [01:31<00:15, 15.13s/it]\n",
      "      10/20         0G      1.377      2.478      1.348      1.249      4.895      1.212         60        640: 100%|##########| 6/6 [01:31<00:00, 15.26s/it]\n",
      "      10/20         0G      1.377      2.478      1.348      1.249      4.895      1.212         60        640: 100%|##########| 6/6 [01:31<00:00, 15.18s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|###3      | 1/3 [00:16<00:33, 17.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|######6   | 2/3 [00:30<00:15, 15.23s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:40<00:00, 12.52s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:40<00:00, 13.43s/it]\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "      11/20         0G      1.333      2.835      1.399      1.396      8.402      1.268         23        640:   0%|          | 0/6 [00:15<?, ?it/s]\n",
      "      11/20         0G      1.333      2.835      1.399      1.396      8.402      1.268         23        640:  17%|#6        | 1/6 [00:15<01:15, 15.09s/it]\n",
      "      11/20         0G      1.439      2.872      1.442      1.423      7.937      1.281         28        640:  17%|#6        | 1/6 [00:30<01:15, 15.09s/it]\n",
      "      11/20         0G      1.439      2.872      1.442      1.423      7.937      1.281         28        640:  33%|###3      | 2/6 [00:30<01:00, 15.18s/it]\n",
      "      11/20         0G      1.421      2.787      1.436      1.376       8.17      1.296         22        640:  33%|###3      | 2/6 [00:44<01:00, 15.18s/it]\n",
      "      11/20         0G      1.421      2.787      1.436      1.376       8.17      1.296         22        640:  50%|#####     | 3/6 [00:44<00:44, 14.86s/it]\n",
      "      11/20         0G      1.395      2.783      1.392      1.361      7.831      1.264         31        640:  50%|#####     | 3/6 [01:00<00:44, 14.86s/it]\n",
      "      11/20         0G      1.395      2.783      1.392      1.361      7.831      1.264         31        640:  67%|######6   | 4/6 [01:00<00:29, 15.00s/it]\n",
      "      11/20         0G      1.389       2.71      1.405      1.332      8.028      1.278         20        640:  67%|######6   | 4/6 [01:15<00:29, 15.00s/it]\n",
      "      11/20         0G      1.389       2.71      1.405      1.332      8.028      1.278         20        640:  83%|########3 | 5/6 [01:15<00:15, 15.12s/it]\n",
      "      11/20         0G      1.424      2.734      1.409      1.363      7.969      1.282         26        640:  83%|########3 | 5/6 [01:30<00:15, 15.12s/it]\n",
      "      11/20         0G      1.424      2.734      1.409      1.363      7.969      1.282         26        640: 100%|##########| 6/6 [01:30<00:00, 15.09s/it]\n",
      "      11/20         0G      1.424      2.734      1.409      1.363      7.969      1.282         26        640: 100%|##########| 6/6 [01:30<00:00, 15.06s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|###3      | 1/3 [00:17<00:34, 17.09s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|######6   | 2/3 [00:31<00:15, 15.28s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:40<00:00, 12.67s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:40<00:00, 13.55s/it]\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "      12/20         0G      1.516      2.742      1.384      1.458      6.627      1.172         33        640:   0%|          | 0/6 [00:15<?, ?it/s]\n",
      "      12/20         0G      1.516      2.742      1.384      1.458      6.627      1.172         33        640:  17%|#6        | 1/6 [00:15<01:16, 15.32s/it]\n",
      "      12/20         0G      1.431       2.71      1.353      1.354      6.778       1.23         29        640:  17%|#6        | 1/6 [00:30<01:16, 15.32s/it]\n",
      "      12/20         0G      1.431       2.71      1.353      1.354      6.778       1.23         29        640:  33%|###3      | 2/6 [00:30<01:01, 15.28s/it]\n",
      "      12/20         0G      1.419      2.624      1.373      1.363      7.293      1.267         22        640:  33%|###3      | 2/6 [08:30<01:01, 15.28s/it]\n",
      "      12/20         0G      1.419      2.624      1.373      1.363      7.293      1.267         22        640:  50%|#####     | 3/6 [08:30<11:21, 227.25s/it]\n",
      "      12/20         0G      1.394      2.665      1.339      1.319      7.522      1.237         23        640:  50%|#####     | 3/6 [08:45<11:21, 227.25s/it]\n",
      "      12/20         0G      1.394      2.665      1.339      1.319      7.522      1.237         23        640:  67%|######6   | 4/6 [08:45<04:47, 143.66s/it]\n",
      "      12/20         0G      1.367      2.609      1.322      1.263      7.605      1.207         22        640:  67%|######6   | 4/6 [09:01<04:47, 143.66s/it]\n",
      "      12/20         0G      1.367      2.609      1.322      1.263      7.605      1.207         22        640:  83%|########3 | 5/6 [09:01<01:37, 97.50s/it] \n",
      "      12/20         0G      1.421      2.602      1.375      1.318      7.846      1.243         21        640:  83%|########3 | 5/6 [09:15<01:37, 97.50s/it]\n",
      "      12/20         0G      1.421      2.602      1.375      1.318      7.846      1.243         21        640: 100%|##########| 6/6 [09:15<00:00, 69.12s/it]\n",
      "      12/20         0G      1.421      2.602      1.375      1.318      7.846      1.243         21        640: 100%|##########| 6/6 [09:15<00:00, 92.55s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|###3      | 1/3 [00:17<00:35, 17.57s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|######6   | 2/3 [00:31<00:15, 15.61s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:41<00:00, 12.76s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:41<00:00, 13.73s/it]\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "      13/20         0G      1.321      2.586      1.221      1.193      7.188      1.068         27        640:   0%|          | 0/6 [00:15<?, ?it/s]\n",
      "      13/20         0G      1.321      2.586      1.221      1.193      7.188      1.068         27        640:  17%|#6        | 1/6 [00:15<01:15, 15.20s/it]\n",
      "      13/20         0G       1.37      2.752      1.319      1.258      7.401      1.138         27        640:  17%|#6        | 1/6 [00:29<01:15, 15.20s/it]\n",
      "      13/20         0G       1.37      2.752      1.319      1.258      7.401      1.138         27        640:  33%|###3      | 2/6 [00:29<00:59, 14.75s/it]\n",
      "      13/20         0G        1.4       2.74      1.301       1.31      7.391      1.154         27        640:  33%|###3      | 2/6 [00:44<00:59, 14.75s/it]\n",
      "      13/20         0G        1.4       2.74      1.301       1.31      7.391      1.154         27        640:  50%|#####     | 3/6 [00:44<00:44, 14.92s/it]\n",
      "      13/20         0G      1.383      2.709      1.313      1.289      7.603      1.165         22        640:  50%|#####     | 3/6 [00:59<00:44, 14.92s/it]\n",
      "      13/20         0G      1.383      2.709      1.313      1.289      7.603      1.165         22        640:  67%|######6   | 4/6 [00:59<00:30, 15.00s/it]\n",
      "      13/20         0G        1.4      2.707      1.324      1.301      7.734      1.187         23        640:  67%|######6   | 4/6 [01:14<00:30, 15.00s/it]\n",
      "      13/20         0G        1.4      2.707      1.324      1.301      7.734      1.187         23        640:  83%|########3 | 5/6 [01:14<00:15, 15.03s/it]\n",
      "      13/20         0G      1.411      2.663      1.346      1.305      7.764      1.212         24        640:  83%|########3 | 5/6 [01:29<00:15, 15.03s/it]\n",
      "      13/20         0G      1.411      2.663      1.346      1.305      7.764      1.212         24        640: 100%|##########| 6/6 [01:29<00:00, 14.89s/it]\n",
      "      13/20         0G      1.411      2.663      1.346      1.305      7.764      1.212         24        640: 100%|##########| 6/6 [01:29<00:00, 14.93s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|###3      | 1/3 [00:17<00:34, 17.23s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|######6   | 2/3 [00:31<00:15, 15.39s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:40<00:00, 12.60s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:40<00:00, 13.53s/it]\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "      14/20         0G      1.444      2.424      1.293      1.293      7.467       1.15         25        640:   0%|          | 0/6 [00:15<?, ?it/s]\n",
      "      14/20         0G      1.444      2.424      1.293      1.293      7.467       1.15         25        640:  17%|#6        | 1/6 [00:15<01:15, 15.09s/it]\n",
      "      14/20         0G      1.461      2.487       1.37       1.28      7.765       1.23         23        640:  17%|#6        | 1/6 [00:29<01:15, 15.09s/it]\n",
      "      14/20         0G      1.461      2.487       1.37       1.28      7.765       1.23         23        640:  33%|###3      | 2/6 [00:29<00:59, 14.91s/it]\n",
      "      14/20         0G      1.402      2.608       1.33      1.267      7.649      1.216         27        640:  33%|###3      | 2/6 [00:45<00:59, 14.91s/it]\n",
      "      14/20         0G      1.402      2.608       1.33      1.267      7.649      1.216         27        640:  50%|#####     | 3/6 [00:45<00:45, 15.13s/it]\n",
      "      14/20         0G      1.349      2.591      1.291      1.259        7.5      1.187         26        640:  50%|#####     | 3/6 [01:00<00:45, 15.13s/it]\n",
      "      14/20         0G      1.349      2.591      1.291      1.259        7.5      1.187         26        640:  67%|######6   | 4/6 [01:00<00:30, 15.28s/it]\n",
      "      14/20         0G      1.323       2.54      1.293      1.241      7.562      1.191         22        640:  67%|######6   | 4/6 [01:15<00:30, 15.28s/it]\n",
      "      14/20         0G      1.323       2.54      1.293      1.241      7.562      1.191         22        640:  83%|########3 | 5/6 [01:15<00:15, 15.24s/it]\n",
      "      14/20         0G      1.318      2.563      1.289      1.242      7.491      1.187         27        640:  83%|########3 | 5/6 [01:30<00:15, 15.24s/it]\n",
      "      14/20         0G      1.318      2.563      1.289      1.242      7.491      1.187         27        640: 100%|##########| 6/6 [01:30<00:00, 15.03s/it]\n",
      "      14/20         0G      1.318      2.563      1.289      1.242      7.491      1.187         27        640: 100%|##########| 6/6 [01:30<00:00, 15.09s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|###3      | 1/3 [00:17<00:34, 17.07s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|######6   | 2/3 [00:30<00:15, 15.08s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:39<00:00, 12.37s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:39<00:00, 13.30s/it]\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "      15/20         0G      1.399      2.601       1.33      1.317      7.835      1.203         24        640:   0%|          | 0/6 [00:14<?, ?it/s]\n",
      "      15/20         0G      1.399      2.601       1.33      1.317      7.835      1.203         24        640:  17%|#6        | 1/6 [00:14<01:13, 14.76s/it]\n",
      "      15/20         0G      1.344      2.473      1.313      1.278      7.585      1.188         25        640:  17%|#6        | 1/6 [00:28<01:13, 14.76s/it]\n",
      "      15/20         0G      1.344      2.473      1.313      1.278      7.585      1.188         25        640:  33%|###3      | 2/6 [00:28<00:56, 14.16s/it]\n",
      "      15/20         0G      1.393      2.539      1.303      1.343       7.27      1.196         32        640:  33%|###3      | 2/6 [00:43<00:56, 14.16s/it]\n",
      "      15/20         0G      1.393      2.539      1.303      1.343       7.27      1.196         32        640:  50%|#####     | 3/6 [00:43<00:43, 14.51s/it]\n",
      "      15/20         0G      1.363      2.437      1.288      1.303      7.454      1.177         21        640:  50%|#####     | 3/6 [02:47<00:43, 14.51s/it]\n",
      "      15/20         0G      1.363      2.437      1.288      1.303      7.454      1.177         21        640:  67%|######6   | 4/6 [02:47<01:55, 57.76s/it]\n",
      "      15/20         0G      1.316      2.389      1.264      1.267      7.371      1.171         25        640:  67%|######6   | 4/6 [02:57<01:55, 57.76s/it]\n",
      "      15/20         0G      1.316      2.389      1.264      1.267      7.371      1.171         25        640:  83%|########3 | 5/6 [02:57<00:40, 40.53s/it]\n",
      "      15/20         0G      1.322      2.416      1.276      1.278      7.503      1.192         23        640:  83%|########3 | 5/6 [03:08<00:40, 40.53s/it]\n",
      "      15/20         0G      1.322      2.416      1.276      1.278      7.503      1.192         23        640: 100%|##########| 6/6 [03:08<00:00, 30.46s/it]\n",
      "      15/20         0G      1.322      2.416      1.276      1.278      7.503      1.192         23        640: 100%|##########| 6/6 [03:08<00:00, 31.40s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|###3      | 1/3 [00:11<00:23, 11.96s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|######6   | 2/3 [00:21<00:10, 10.58s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:28<00:00,  8.75s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:28<00:00,  9.38s/it]\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "      16/20         0G      1.297      2.617      1.271        1.2      6.782      1.115         30        640:   0%|          | 0/6 [00:09<?, ?it/s]\n",
      "      16/20         0G      1.297      2.617      1.271        1.2      6.782      1.115         30        640:  17%|#6        | 1/6 [00:09<00:49,  9.98s/it]\n",
      "      16/20         0G      1.175       2.46      1.218       1.14      7.244      1.121         22        640:  17%|#6        | 1/6 [00:20<00:49,  9.98s/it]\n",
      "      16/20         0G      1.175       2.46      1.218       1.14      7.244      1.121         22        640:  33%|###3      | 2/6 [00:20<00:40, 10.01s/it]\n",
      "      16/20         0G      1.221      2.419      1.264       1.17      7.544      1.183         21        640:  33%|###3      | 2/6 [00:29<00:40, 10.01s/it]\n",
      "      16/20         0G      1.221      2.419      1.264       1.17      7.544      1.183         21        640:  50%|#####     | 3/6 [00:29<00:29,  9.97s/it]\n",
      "      16/20         0G      1.244      2.338      1.266      1.207      7.665      1.173         21        640:  50%|#####     | 3/6 [00:39<00:29,  9.97s/it]\n",
      "      16/20         0G      1.244      2.338      1.266      1.207      7.665      1.173         21        640:  67%|######6   | 4/6 [00:39<00:19,  9.87s/it]\n",
      "      16/20         0G      1.286      2.415      1.264      1.236      7.584      1.154         28        640:  67%|######6   | 4/6 [00:49<00:19,  9.87s/it]\n",
      "      16/20         0G      1.286      2.415      1.264      1.236      7.584      1.154         28        640:  83%|########3 | 5/6 [00:49<00:09,  9.90s/it]\n",
      "      16/20         0G      1.289      2.375      1.267      1.227      7.441      1.146         27        640:  83%|########3 | 5/6 [00:59<00:09,  9.90s/it]\n",
      "      16/20         0G      1.289      2.375      1.267      1.227      7.441      1.146         27        640: 100%|##########| 6/6 [00:59<00:00,  9.91s/it]\n",
      "      16/20         0G      1.289      2.375      1.267      1.227      7.441      1.146         27        640: 100%|##########| 6/6 [00:59<00:00,  9.92s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|###3      | 1/3 [00:11<00:22, 11.05s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|######6   | 2/3 [00:19<00:09,  9.72s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:25<00:00,  8.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:25<00:00,  8.60s/it]\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "      17/20         0G      1.264      2.557       1.24      1.329      7.488      1.015         26        640:   0%|          | 0/6 [00:09<?, ?it/s]\n",
      "      17/20         0G      1.264      2.557       1.24      1.329      7.488      1.015         26        640:  17%|#6        | 1/6 [00:09<00:46,  9.25s/it]\n",
      "      17/20         0G      1.249      2.337      1.265      1.208      7.241       1.12         24        640:  17%|#6        | 1/6 [00:18<00:46,  9.25s/it]\n",
      "      17/20         0G      1.249      2.337      1.265      1.208      7.241       1.12         24        640:  33%|###3      | 2/6 [00:18<00:37,  9.45s/it]\n",
      "      17/20         0G      1.278      2.352      1.283      1.215      7.361      1.135         24        640:  33%|###3      | 2/6 [00:28<00:37,  9.45s/it]\n",
      "      17/20         0G      1.278      2.352      1.283      1.215      7.361      1.135         24        640:  50%|#####     | 3/6 [00:28<00:28,  9.53s/it]\n",
      "      17/20         0G       1.32      2.407      1.311      1.242      7.515      1.179         23        640:  50%|#####     | 3/6 [00:38<00:28,  9.53s/it]\n",
      "      17/20         0G       1.32      2.407      1.311      1.242      7.515      1.179         23        640:  67%|######6   | 4/6 [00:38<00:19,  9.60s/it]\n",
      "      17/20         0G      1.323      2.382      1.297      1.245      7.303      1.163         30        640:  67%|######6   | 4/6 [00:48<00:19,  9.60s/it]\n",
      "      17/20         0G      1.323      2.382      1.297      1.245      7.303      1.163         30        640:  83%|########3 | 5/6 [00:48<00:09,  9.74s/it]\n",
      "      17/20         0G      1.302      2.356      1.298       1.23      7.314      1.175         23        640:  83%|########3 | 5/6 [00:57<00:09,  9.74s/it]\n",
      "      17/20         0G      1.302      2.356      1.298       1.23      7.314      1.175         23        640: 100%|##########| 6/6 [00:57<00:00,  9.74s/it]\n",
      "      17/20         0G      1.302      2.356      1.298       1.23      7.314      1.175         23        640: 100%|##########| 6/6 [00:57<00:00,  9.65s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|###3      | 1/3 [00:11<00:22, 11.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|######6   | 2/3 [00:20<00:09,  9.97s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:26<00:00,  8.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:26<00:00,  8.77s/it]\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "      18/20         0G      1.189      2.426      1.261      1.077      7.297      1.168         25        640:   0%|          | 0/6 [00:09<?, ?it/s]\n",
      "      18/20         0G      1.189      2.426      1.261      1.077      7.297      1.168         25        640:  17%|#6        | 1/6 [00:09<00:48,  9.69s/it]\n",
      "      18/20         0G      1.247      2.457      1.262      1.123       7.04      1.157         28        640:  17%|#6        | 1/6 [00:19<00:48,  9.69s/it]\n",
      "      18/20         0G      1.247      2.457      1.262      1.123       7.04      1.157         28        640:  33%|###3      | 2/6 [00:19<00:38,  9.71s/it]\n",
      "      18/20         0G      1.267      2.428      1.277      1.154       7.16      1.163         24        640:  33%|###3      | 2/6 [00:28<00:38,  9.71s/it]\n",
      "      18/20         0G      1.267      2.428      1.277      1.154       7.16      1.163         24        640:  50%|#####     | 3/6 [00:28<00:28,  9.63s/it]\n",
      "      18/20         0G      1.245      2.372      1.264      1.151      7.046      1.163         26        640:  50%|#####     | 3/6 [00:38<00:28,  9.63s/it]\n",
      "      18/20         0G      1.245      2.372      1.264      1.151      7.046      1.163         26        640:  67%|######6   | 4/6 [00:38<00:19,  9.62s/it]\n",
      "      18/20         0G      1.272      2.383      1.301      1.187       7.18      1.205         23        640:  67%|######6   | 4/6 [00:48<00:19,  9.62s/it]\n",
      "      18/20         0G      1.272      2.383      1.301      1.187       7.18      1.205         23        640:  83%|########3 | 5/6 [00:48<00:09,  9.60s/it]\n",
      "      18/20         0G      1.242      2.326      1.282      1.164      7.168      1.186         24        640:  83%|########3 | 5/6 [00:57<00:09,  9.60s/it]\n",
      "      18/20         0G      1.242      2.326      1.282      1.164      7.168      1.186         24        640: 100%|##########| 6/6 [00:57<00:00,  9.62s/it]\n",
      "      18/20         0G      1.242      2.326      1.282      1.164      7.168      1.186         24        640: 100%|##########| 6/6 [00:57<00:00,  9.63s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|###3      | 1/3 [00:10<00:21, 10.95s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|######6   | 2/3 [00:19<00:09,  9.68s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:25<00:00,  7.97s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:25<00:00,  8.56s/it]\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "      19/20         0G      1.277      2.282      1.312      1.176      7.089       1.22         24        640:   0%|          | 0/6 [00:09<?, ?it/s]\n",
      "      19/20         0G      1.277      2.282      1.312      1.176      7.089       1.22         24        640:  17%|#6        | 1/6 [00:09<00:46,  9.28s/it]\n",
      "      19/20         0G      1.233      2.219      1.284      1.163      6.725      1.184         29        640:  17%|#6        | 1/6 [00:18<00:46,  9.28s/it]\n",
      "      19/20         0G      1.233      2.219      1.284      1.163      6.725      1.184         29        640:  33%|###3      | 2/6 [00:18<00:37,  9.44s/it]\n",
      "      19/20         0G      1.256      2.163      1.297       1.18      7.197      1.178         21        640:  33%|###3      | 2/6 [00:28<00:37,  9.44s/it]\n",
      "      19/20         0G      1.256      2.163      1.297       1.18      7.197      1.178         21        640:  50%|#####     | 3/6 [00:28<00:28,  9.56s/it]\n",
      "      19/20         0G      1.265      2.237      1.272       1.22      7.063       1.17         29        640:  50%|#####     | 3/6 [00:38<00:28,  9.56s/it]\n",
      "      19/20         0G      1.265      2.237      1.272       1.22      7.063       1.17         29        640:  67%|######6   | 4/6 [00:38<00:19,  9.59s/it]\n",
      "      19/20         0G      1.274       2.19      1.281      1.236      7.157      1.176         22        640:  67%|######6   | 4/6 [00:47<00:19,  9.59s/it]\n",
      "      19/20         0G      1.274       2.19      1.281      1.236      7.157      1.176         22        640:  83%|########3 | 5/6 [00:47<00:09,  9.61s/it]\n",
      "      19/20         0G       1.25      2.204      1.252       1.21      7.144       1.15         25        640:  83%|########3 | 5/6 [00:57<00:09,  9.61s/it]\n",
      "      19/20         0G       1.25      2.204      1.252       1.21      7.144       1.15         25        640: 100%|##########| 6/6 [00:57<00:00,  9.67s/it]\n",
      "      19/20         0G       1.25      2.204      1.252       1.21      7.144       1.15         25        640: 100%|##########| 6/6 [00:57<00:00,  9.60s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|###3      | 1/3 [00:10<00:21, 10.99s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|######6   | 2/3 [00:19<00:09,  9.74s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:25<00:00,  7.97s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:25<00:00,  8.57s/it]\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "      20/20         0G      1.278      2.245      1.222      1.211       6.87      1.149         26        640:   0%|          | 0/6 [00:09<?, ?it/s]\n",
      "      20/20         0G      1.278      2.245      1.222      1.211       6.87      1.149         26        640:  17%|#6        | 1/6 [00:09<00:46,  9.34s/it]\n",
      "      20/20         0G      1.234      2.208      1.287      1.141      8.015      1.177         17        640:  17%|#6        | 1/6 [00:18<00:46,  9.34s/it]\n",
      "      20/20         0G      1.234      2.208      1.287      1.141      8.015      1.177         17        640:  33%|###3      | 2/6 [00:18<00:37,  9.48s/it]\n",
      "      20/20         0G       1.26      2.183      1.301      1.195      7.791      1.184         24        640:  33%|###3      | 2/6 [00:28<00:37,  9.48s/it]\n",
      "      20/20         0G       1.26      2.183      1.301      1.195      7.791      1.184         24        640:  50%|#####     | 3/6 [00:28<00:28,  9.62s/it]\n",
      "      20/20         0G      1.256      2.196      1.267      1.198      7.336      1.161         32        640:  50%|#####     | 3/6 [00:38<00:28,  9.62s/it]\n",
      "      20/20         0G      1.256      2.196      1.267      1.198      7.336      1.161         32        640:  67%|######6   | 4/6 [00:38<00:19,  9.68s/it]\n",
      "      20/20         0G       1.25      2.248      1.239      1.221       7.19      1.147         29        640:  67%|######6   | 4/6 [00:48<00:19,  9.68s/it]\n",
      "      20/20         0G       1.25      2.248      1.239      1.221       7.19      1.147         29        640:  83%|########3 | 5/6 [00:48<00:09,  9.70s/it]\n",
      "      20/20         0G      1.258      2.242      1.245      1.206      7.268      1.142         22        640:  83%|########3 | 5/6 [00:58<00:09,  9.70s/it]\n",
      "      20/20         0G      1.258      2.242      1.245      1.206      7.268      1.142         22        640: 100%|##########| 6/6 [00:58<00:00,  9.78s/it]\n",
      "      20/20         0G      1.258      2.242      1.245      1.206      7.268      1.142         22        640: 100%|##########| 6/6 [00:58<00:00,  9.69s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|###3      | 1/3 [00:11<00:22, 11.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|######6   | 2/3 [00:19<00:09,  9.76s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:25<00:00,  8.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:25<00:00,  8.60s/it]\n",
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33%|###3      | 1/3 [00:09<00:18,  9.38s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67%|######6   | 2/3 [00:17<00:08,  8.42s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:22<00:00,  6.93s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|##########| 3/3 [00:22<00:00,  7.43s/it]\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=train epochs=20 batch=16  plots=True model=C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\weights\\yolov10n.pt data=C:/Users/sshiv/Desktop/sihProject/data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f68ed20-c2eb-4e22-a7c0-8a341b415841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "image 1/1 C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\2.jpg: 384x640 (no detections), 87.5ms\n",
      "Speed: 2.1ms preprocess, 87.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\predict13\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.02 save=True model=C:\\Users\\sshiv\\runs\\detect\\train9\\weights\\best.pt source=test_images/2.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e90ac0b1-0dc2-4a51-b4bb-406b61e54ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "image 1/1 C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\2.jpg: 384x640 3 Shivanshus, 87.5ms\n",
      "Speed: 2.1ms preprocess, 87.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\predict14\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.02 save=True model=C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt source=test_images/2.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fac5010-c8cf-41a9-aefb-aa3e860b2297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "image 1/1 C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\5.jpg: 640x480 3 Shivanshus, 114.3ms\n",
      "Speed: 3.0ms preprocess, 114.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\predict15\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.02 save=True model=C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt source=test_images/5.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2a345a5-df14-48a2-ad76-0db919b0cc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "image 1/1 C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\3.jpg: 640x384 1 Shivanshu, 81.6ms\n",
      "Speed: 3.1ms preprocess, 81.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\predict16\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.01 save=True model=C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt source=test_images/3.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9f10124-b1ab-4196-b8cc-2ad5d8180c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "image 1/1 C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\6.jpg: 384x640 8 Shivanshus, 82.2ms\n",
      "Speed: 3.2ms preprocess, 82.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\predict17\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.01 save=True model=C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt source=test_images/6.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "641ea2ce-09e0-40be-b0d6-3752870761b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "image 1/1 C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\6.jpg: 384x640 1 Shivanshu, 84.0ms\n",
      "Speed: 2.7ms preprocess, 84.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\predict18\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.03 save=True model=C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt source=test_images/6.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e8cf164-a3a5-4848-a18c-dba9749536f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "image 1/1 C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\7.jpg: 384x640 (no detections), 79.2ms\n",
      "Speed: 3.3ms preprocess, 79.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\predict19\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.03 save=True model=C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt source=test_images/7.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8caa9455-a0b2-4987-9c45-ff9f29f3d540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "image 1/1 C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\7.jpg: 384x640 (no detections), 77.3ms\n",
      "Speed: 3.1ms preprocess, 77.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\predict20\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.02 save=True model=C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt source=test_images/7.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f689a80b-9c47-4c76-b305-d10a741c4cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "image 1/1 C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\8.jpg: 640x384 2 Shivanshus, 80.1ms\n",
      "Speed: 2.1ms preprocess, 80.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\predict21\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.02 save=True model=C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt source=test_images/8.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "287825d7-b27a-41c2-b1ae-3c4d95959558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "image 1/1 C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\9.jpg: 640x640 (no detections), 120.8ms\n",
      "Speed: 4.6ms preprocess, 120.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\predict22\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.02 save=True model=C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt source=test_images/9.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4499ff22-1644-4216-8796-66769ba30703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "image 1/1 C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\8.jpg: 640x384 3 Shivanshus, 77.1ms\n",
      "Speed: 2.1ms preprocess, 77.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\predict23\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.01 save=True model=C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt source=test_images/8.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "794c0f98-53ee-49e3-bfc7-6f17e985404f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "image 1/1 C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\9.jpg: 640x640 3 Shivanshus, 116.1ms\n",
      "Speed: 3.1ms preprocess, 116.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\predict24\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.01 save=True model=C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt source=test_images/9.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "296a6d1f-2d7f-493f-bfdd-8d2ed58d9470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "image 1/1 C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\10.jpg: 480x640 3 Shivanshus, 1 Krishn, 108.5ms\n",
      "Speed: 3.1ms preprocess, 108.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\predict25\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.02 save=True model=C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt source=test_images/10.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b867033a-d28b-4a7f-be2b-3d34aaf4e83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "image 1/1 C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\11.jpg: 640x480 (no detections), 96.1ms\n",
      "Speed: 2.1ms preprocess, 96.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\predict26\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.02 save=True model=C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt source=test_images/10.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b963cf72-2367-4a1d-ae8f-85623cd06384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "image 1/1 C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\10.jpg: 480x640 3 Shivanshus, 5 Krishns, 1 Yashwant, 102.6ms\n",
      "Speed: 2.1ms preprocess, 102.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\predict27\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.01 save=True model=C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt source=test_images/10.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8f522041-9d0c-419c-89b9-cd676b9b0ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "image 1/1 C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\11.jpg: 640x480 (no detections), 90.8ms\n",
      "Speed: 2.1ms preprocess, 90.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\predict28\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.01 save=True model=C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt source=test_images/11.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "284ba779-49c0-4fed-b2a2-987d4c1f8960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "image 1/1 C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\12.jpg: 480x640 2 Shivanshus, 97.3ms\n",
      "Speed: 3.1ms preprocess, 97.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\predict29\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.02 save=True model=C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt source=test_images/12.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e046ecfb-ba79-43c8-8b3c-c03786007ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "video 1/1 (frame 1/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 3 Shivanshus, 91.8ms\n",
      "video 1/1 (frame 2/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 3 Shivanshus, 80.6ms\n",
      "video 1/1 (frame 3/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 3 Shivanshus, 79.9ms\n",
      "video 1/1 (frame 4/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 3 Shivanshus, 80.3ms\n",
      "video 1/1 (frame 5/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 3 Shivanshus, 80.2ms\n",
      "video 1/1 (frame 6/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 3 Shivanshus, 79.5ms\n",
      "video 1/1 (frame 7/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 3 Shivanshus, 78.9ms\n",
      "video 1/1 (frame 8/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 3 Shivanshus, 76.2ms\n",
      "video 1/1 (frame 9/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 3 Shivanshus, 76.0ms\n",
      "video 1/1 (frame 10/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 3 Shivanshus, 76.0ms\n",
      "video 1/1 (frame 11/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 3 Shivanshus, 76.8ms\n",
      "video 1/1 (frame 12/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 3 Shivanshus, 77.9ms\n",
      "video 1/1 (frame 13/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 2 Shivanshus, 73.4ms\n",
      "video 1/1 (frame 14/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 3 Shivanshus, 73.2ms\n",
      "video 1/1 (frame 15/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 2 Shivanshus, 72.4ms\n",
      "video 1/1 (frame 16/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 2 Shivanshus, 73.9ms\n",
      "video 1/1 (frame 17/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 2 Shivanshus, 71.7ms\n",
      "video 1/1 (frame 18/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 4 Shivanshus, 72.1ms\n",
      "video 1/1 (frame 19/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 3 Shivanshus, 74.5ms\n",
      "video 1/1 (frame 20/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 4 Shivanshus, 72.4ms\n",
      "video 1/1 (frame 21/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 3 Shivanshus, 73.4ms\n",
      "video 1/1 (frame 22/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 3 Shivanshus, 75.5ms\n",
      "video 1/1 (frame 23/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 3 Shivanshus, 77.2ms\n",
      "video 1/1 (frame 24/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 3 Shivanshus, 73.9ms\n",
      "video 1/1 (frame 25/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 2 Shivanshus, 71.3ms\n",
      "video 1/1 (frame 26/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 2 Shivanshus, 72.9ms\n",
      "video 1/1 (frame 27/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 3 Shivanshus, 73.9ms\n",
      "video 1/1 (frame 28/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 4 Shivanshus, 71.9ms\n",
      "video 1/1 (frame 29/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 3 Shivanshus, 75.3ms\n",
      "video 1/1 (frame 30/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 2 Shivanshus, 77.5ms\n",
      "video 1/1 (frame 31/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 3 Shivanshus, 78.2ms\n",
      "video 1/1 (frame 32/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 3 Shivanshus, 76.9ms\n",
      "video 1/1 (frame 33/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 2 Shivanshus, 76.0ms\n",
      "video 1/1 (frame 34/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 2 Shivanshus, 74.1ms\n",
      "video 1/1 (frame 35/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 2 Shivanshus, 74.5ms\n",
      "video 1/1 (frame 36/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 3 Shivanshus, 75.6ms\n",
      "video 1/1 (frame 37/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 4 Shivanshus, 84.8ms\n",
      "video 1/1 (frame 38/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 3 Shivanshus, 69.6ms\n",
      "video 1/1 (frame 39/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 2 Shivanshus, 72.6ms\n",
      "video 1/1 (frame 40/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 2 Shivanshus, 73.3ms\n",
      "video 1/1 (frame 41/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 2 Shivanshus, 76.7ms\n",
      "video 1/1 (frame 42/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 2 Shivanshus, 79.2ms\n",
      "video 1/1 (frame 43/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 2 Shivanshus, 78.6ms\n",
      "video 1/1 (frame 44/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 4 Shivanshus, 78.2ms\n",
      "video 1/1 (frame 45/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 2 Shivanshus, 71.4ms\n",
      "video 1/1 (frame 46/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 2 Shivanshus, 70.4ms\n",
      "video 1/1 (frame 47/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 2 Shivanshus, 71.3ms\n",
      "video 1/1 (frame 48/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 2 Shivanshus, 72.1ms\n",
      "video 1/1 (frame 49/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 2 Shivanshus, 76.7ms\n",
      "video 1/1 (frame 50/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 2 Shivanshus, 73.1ms\n",
      "video 1/1 (frame 51/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 2 Shivanshus, 74.2ms\n",
      "video 1/1 (frame 52/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 3 Shivanshus, 71.8ms\n",
      "video 1/1 (frame 53/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 3 Shivanshus, 71.1ms\n",
      "video 1/1 (frame 54/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 2 Shivanshus, 73.2ms\n",
      "video 1/1 (frame 55/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 2 Shivanshus, 73.1ms\n",
      "video 1/1 (frame 56/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 2 Shivanshus, 70.8ms\n",
      "video 1/1 (frame 57/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 2 Shivanshus, 71.4ms\n",
      "video 1/1 (frame 58/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 2 Shivanshus, 70.6ms\n",
      "video 1/1 (frame 59/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 2 Shivanshus, 72.6ms\n",
      "video 1/1 (frame 60/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 3 Shivanshus, 71.6ms\n",
      "video 1/1 (frame 61/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 4 Shivanshus, 71.6ms\n",
      "video 1/1 (frame 62/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 3 Shivanshus, 70.5ms\n",
      "video 1/1 (frame 63/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 3 Shivanshus, 73.1ms\n",
      "video 1/1 (frame 64/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 4 Shivanshus, 79.3ms\n",
      "video 1/1 (frame 65/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 3 Shivanshus, 77.9ms\n",
      "video 1/1 (frame 66/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 2 Shivanshus, 75.4ms\n",
      "video 1/1 (frame 67/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 2 Shivanshus, 73.2ms\n",
      "video 1/1 (frame 68/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 2 Shivanshus, 73.4ms\n",
      "video 1/1 (frame 69/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 2 Shivanshus, 73.9ms\n",
      "video 1/1 (frame 70/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 2 Shivanshus, 75.6ms\n",
      "video 1/1 (frame 71/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 2 Shivanshus, 72.3ms\n",
      "video 1/1 (frame 72/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 2 Shivanshus, 74.1ms\n",
      "video 1/1 (frame 73/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 2 Shivanshus, 72.8ms\n",
      "video 1/1 (frame 74/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 2 Shivanshus, 75.0ms\n",
      "video 1/1 (frame 75/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 2 Shivanshus, 75.5ms\n",
      "video 1/1 (frame 76/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 3 Shivanshus, 78.5ms\n",
      "video 1/1 (frame 77/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 3 Shivanshus, 73.2ms\n",
      "video 1/1 (frame 78/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 4 Shivanshus, 73.1ms\n",
      "video 1/1 (frame 79/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 4 Shivanshus, 69.6ms\n",
      "video 1/1 (frame 80/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 3 Shivanshus, 69.3ms\n",
      "video 1/1 (frame 81/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 2 Shivanshus, 69.9ms\n",
      "video 1/1 (frame 82/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 3 Shivanshus, 69.8ms\n",
      "video 1/1 (frame 83/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 3 Shivanshus, 74.9ms\n",
      "video 1/1 (frame 84/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 3 Shivanshus, 68.8ms\n",
      "video 1/1 (frame 85/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 4 Shivanshus, 71.5ms\n",
      "video 1/1 (frame 86/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 4 Shivanshus, 71.0ms\n",
      "video 1/1 (frame 87/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 4 Shivanshus, 69.3ms\n",
      "video 1/1 (frame 88/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 4 Shivanshus, 69.4ms\n",
      "video 1/1 (frame 89/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 4 Shivanshus, 70.0ms\n",
      "video 1/1 (frame 90/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 4 Shivanshus, 69.8ms\n",
      "video 1/1 (frame 91/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 4 Shivanshus, 69.2ms\n",
      "video 1/1 (frame 92/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 4 Shivanshus, 70.4ms\n",
      "video 1/1 (frame 93/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 3 Shivanshus, 69.7ms\n",
      "video 1/1 (frame 94/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 4 Shivanshus, 69.4ms\n",
      "video 1/1 (frame 95/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 3 Shivanshus, 69.1ms\n",
      "video 1/1 (frame 96/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 4 Shivanshus, 70.5ms\n",
      "video 1/1 (frame 97/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 4 Shivanshus, 70.9ms\n",
      "video 1/1 (frame 98/98) C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\13.mp4: 384x640 4 Shivanshus, 69.4ms\n",
      "Speed: 1.6ms preprocess, 73.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\predict\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.02 save=True model=C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt source=test_images/13.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d1e86137-3ccd-4bd7-9d02-d7567aa10fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\sshiv\\AppData\\Local\\Temp\\ipykernel_1804\\2067619954.py:2: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  model=YOLO(\"Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt\")\n",
      "C:\\Users\\sshiv\\AppData\\Local\\Temp\\ipykernel_1804\\2067619954.py:2: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  model=YOLO(\"Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt\")\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Users\\\\sshiv\\runs\\\\detect\\train10\\\\weights\\x08est.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[1;32m----> 2\u001b[0m model\u001b[38;5;241m=\u001b[39m\u001b[43mYOLO\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43msshiv\u001b[39;49m\u001b[38;5;130;43;01m\\r\u001b[39;49;00m\u001b[38;5;124;43muns\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mdetect\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43mrain10\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mweights\u001b[39;49m\u001b[38;5;130;43;01m\\b\u001b[39;49;00m\u001b[38;5;124;43mest.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mexport(\u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtfilte\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\models\\yolo\\model.py:28\u001b[0m, in \u001b[0;36mYOLO.__init__\u001b[1;34m(self, model, task, verbose)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m \u001b[38;5;241m=\u001b[39m new_instance\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# Continue with default YOLO initialization\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py:141\u001b[0m, in \u001b[0;36mModel.__init__\u001b[1;34m(self, model, task, verbose)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(model, task\u001b[38;5;241m=\u001b[39mtask, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 141\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py:230\u001b[0m, in \u001b[0;36mModel._load\u001b[1;34m(self, weights, task)\u001b[0m\n\u001b[0;32m    227\u001b[0m weights \u001b[38;5;241m=\u001b[39m checks\u001b[38;5;241m.\u001b[39mcheck_model_file_from_stem(weights)  \u001b[38;5;66;03m# add suffix, i.e. yolov8n -> yolov8n.pt\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Path(weights)\u001b[38;5;241m.\u001b[39msuffix \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 230\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;241m=\u001b[39m \u001b[43mattempt_load_one_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset_ckpt_args(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:807\u001b[0m, in \u001b[0;36mattempt_load_one_weight\u001b[1;34m(weight, device, inplace, fuse)\u001b[0m\n\u001b[0;32m    805\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mattempt_load_one_weight\u001b[39m(weight, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fuse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    806\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a single model weights.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 807\u001b[0m     ckpt, weight \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_safe_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# load ckpt\u001b[39;00m\n\u001b[0;32m    808\u001b[0m     args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mDEFAULT_CFG_DICT, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_args\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))}  \u001b[38;5;66;03m# combine model and default args, preferring model args\u001b[39;00m\n\u001b[0;32m    809\u001b[0m     model \u001b[38;5;241m=\u001b[39m (ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mema\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m ckpt[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# FP32 model\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733\u001b[0m, in \u001b[0;36mtorch_safe_load\u001b[1;34m(weight)\u001b[0m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    726\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m temporary_modules(\n\u001b[0;32m    727\u001b[0m         {\n\u001b[0;32m    728\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124multralytics.yolo.utils\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124multralytics.utils\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    731\u001b[0m         }\n\u001b[0;32m    732\u001b[0m     ):  \u001b[38;5;66;03m# for legacy 8.0 Classify and Pose models\u001b[39;00m\n\u001b[1;32m--> 733\u001b[0m         ckpt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# e.name is missing module name\u001b[39;00m\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:1065\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1063\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m-> 1065\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m   1066\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1067\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1068\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1069\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1070\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:468\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 468\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    470\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:449\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Users\\\\sshiv\\runs\\\\detect\\train10\\\\weights\\x08est.pt'"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model=YOLO(\"Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt\")\n",
    "model.export(format='tfilte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8c0db554-7bce-47a5-91d9-45b26043bed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python: can't open file 'C:\\\\Users\\\\sshiv\\\\Desktop\\\\sihProject\\\\export.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python export.py --weights C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt --include tflite --img 416"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4f95146a-b92d-4127-a73e-d82398789cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is 20FD-A684\n",
      "\n",
      " Directory of C:\\Users\\sshiv\\Desktop\\sihProject\n",
      "\n",
      "25-08-2024  20:37    <DIR>          .\n",
      "25-08-2024  00:29    <DIR>          ..\n",
      "24-08-2024  08:42    <DIR>          .ipynb_checkpoints\n",
      "25-08-2024  00:23    <DIR>          custom_dataset\n",
      "25-08-2024  13:32               308 data.yaml\n",
      "25-08-2024  16:16    <DIR>          test_images\n",
      "25-08-2024  20:37           586,954 Untitled.ipynb\n",
      "24-08-2024  20:04    <DIR>          yolov10\n",
      "               2 File(s)        587,262 bytes\n",
      "               6 Dir(s)  124,758,986,752 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "58220f9e-c8d9-428d-abb4-869fd04cc7a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\sshiv\\\\Desktop\\\\sihProject'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "02633a7f-695d-4533-b0f3-68fabd33ac5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd yolov10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5ccf7dd8-16b4-43ac-9c25-6655964cf8df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\sshiv\\\\Desktop\\\\sihProject\\\\yolov10'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5c77b22a-7e0b-461d-98fa-a16f5fcd31d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is 20FD-A684\n",
      "\n",
      " Directory of C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\n",
      "\n",
      "24-08-2024  20:04    <DIR>          .\n",
      "25-08-2024  20:37    <DIR>          ..\n",
      "24-08-2024  08:43             2,468 .gitignore\n",
      "24-08-2024  08:43             2,391 .pre-commit-config.yaml\n",
      "24-08-2024  08:43             5,688 app.py\n",
      "24-08-2024  08:45    <DIR>          build\n",
      "24-08-2024  08:43             5,681 CONTRIBUTING.md\n",
      "24-08-2024  08:43    <DIR>          docker\n",
      "24-08-2024  08:43    <DIR>          docs\n",
      "24-08-2024  08:43    <DIR>          examples\n",
      "24-08-2024  08:43    <DIR>          figures\n",
      "24-08-2024  08:43               219 flops.py\n",
      "24-08-2024  20:04            75,348 gratisography-cyber-kitty-800x525.jpg\n",
      "24-08-2024  08:43            35,184 LICENSE\n",
      "24-08-2024  08:43    <DIR>          logs\n",
      "24-08-2024  08:43            32,631 mkdocs.yml\n",
      "24-08-2024  08:43             7,003 pyproject.toml\n",
      "24-08-2024  08:43            12,545 README.md\n",
      "24-08-2024  08:43               281 requirements.txt\n",
      "24-08-2024  08:43    <DIR>          tests\n",
      "24-08-2024  08:43    <DIR>          ultralytics\n",
      "24-08-2024  08:45    <DIR>          ultralytics.egg-info\n",
      "24-08-2024  08:53    <DIR>          weights\n",
      "24-08-2024  20:01            54,613 zoo-8378189_640.jpg\n",
      "              12 File(s)        234,052 bytes\n",
      "              12 Dir(s)  124,781,703,168 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "255eb43f-e25f-4c5b-902a-137674788105",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python: can't open file 'C:\\\\Users\\\\sshiv\\\\Desktop\\\\sihProject\\\\yolov10\\\\export.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python export.py --weights C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt --include tflite --img 416"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8e65bd6b-d728-4b30-922c-0d2402bedb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\Desktop\\sihProject\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c54828db-02e0-455d-9cb7-41b76cca06eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1546897900.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[53], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    python models/tf.py --weights runs/train/exp6/weights/best.pt --cfg yolov5s.yaml\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "python models/tf.py --weights runs/train/exp6/weights/best.pt --cfg yolov5s.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b7bf38a1-3b45-4615-a95a-176f88868ef4",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3602348805.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[54], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    python models/tf.py --weights C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt --cfg models/yolov5s.yaml\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "python models/tf.py --weights C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt --cfg models/yolov5s.yaml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e4ef819c-a894-407f-8d0d-51431847f399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 300, 6) (5.5 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnx>=1.12.0', 'onnx2tf>=1.15.4,<=1.17.5', 'sng4onnx>=1.0.1', 'onnxslim==0.1.31', 'onnx_graphsurgeon>=0.3.26', 'tflite_support', 'onnxruntime'] not found, attempting AutoUpdate...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m â�Œ Command 'pip install --no-cache \"onnx>=1.12.0\" \"onnx2tf>=1.15.4,<=1.17.5\" \"sng4onnx>=1.0.1\" \"onnxslim==0.1.31\" \"onnx_graphsurgeon>=0.3.26\" \"tflite_support\" \"onnxruntime\" --extra-index-url https://pypi.ngc.nvidia.com' returned non-zero exit status 1.\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.17.0...\n",
      "WARNING âš ï¸� tensorflow<=2.13.1 is required, but tensorflow==2.17.0 is currently installed https://github.com/ultralytics/ultralytics/issues/5161\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export failure â�Œ 41.9s: No module named 'onnx2tf'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [84 lines of output]\n",
      "  C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\setuptools\\__init__.py:88: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
      "  !!\n",
      "  \n",
      "          ********************************************************************************\n",
      "          Requirements should be satisfied by a PEP 517 installer.\n",
      "          If you are using pip, you can try `pip install --use-pep517`.\n",
      "          ********************************************************************************\n",
      "  \n",
      "  !!\n",
      "    dist.fetch_build_eggs(dist.setup_requires)\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-312\n",
      "  creating build\\lib.win-amd64-cpython-312\\tflite_support\n",
      "  copying tflite_support\\codegen.py -> build\\lib.win-amd64-cpython-312\\tflite_support\n",
      "  copying tflite_support\\metadata.py -> build\\lib.win-amd64-cpython-312\\tflite_support\n",
      "  copying tflite_support\\metadata_schema_py_generated.py -> build\\lib.win-amd64-cpython-312\\tflite_support\n",
      "  copying tflite_support\\schema_py_generated.py -> build\\lib.win-amd64-cpython-312\\tflite_support\n",
      "  copying tflite_support\\__init__.py -> build\\lib.win-amd64-cpython-312\\tflite_support\n",
      "  running egg_info\n",
      "  writing tflite_support.egg-info\\PKG-INFO\n",
      "  writing dependency_links to tflite_support.egg-info\\dependency_links.txt\n",
      "  writing entry points to tflite_support.egg-info\\entry_points.txt\n",
      "  writing requirements to tflite_support.egg-info\\requires.txt\n",
      "  writing top-level names to tflite_support.egg-info\\top_level.txt\n",
      "  reading manifest file 'tflite_support.egg-info\\SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  writing manifest file 'tflite_support.egg-info\\SOURCES.txt'\n",
      "  C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\setuptools\\command\\build_py.py:218: _Warning: Package 'tflite_support.flatbuffers' is absent from the `packages` configuration.\n",
      "  !!\n",
      "  \n",
      "          ********************************************************************************\n",
      "          ############################\n",
      "          # Package would be ignored #\n",
      "          ############################\n",
      "          Python recognizes 'tflite_support.flatbuffers' as an importable package[^1],\n",
      "          but it is absent from setuptools' `packages` configuration.\n",
      "  \n",
      "          This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "          package, please make sure that 'tflite_support.flatbuffers' is explicitly added\n",
      "          to the `packages` configuration field.\n",
      "  \n",
      "          Alternatively, you can also rely on setuptools' discovery methods\n",
      "          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "          instead of `find_packages(...)`/`find:`).\n",
      "  \n",
      "          You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \n",
      "          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \n",
      "          If you don't want 'tflite_support.flatbuffers' to be distributed and are\n",
      "          already explicitly excluding 'tflite_support.flatbuffers' via\n",
      "          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "          you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "          combination with a more fine grained `package-data` configuration.\n",
      "  \n",
      "          You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \n",
      "          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \n",
      "  \n",
      "          [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                even if it does not contain any `.py` files.\n",
      "                On the other hand, currently there is no concept of package data\n",
      "                directory, all directories are treated like packages.\n",
      "          ********************************************************************************\n",
      "  \n",
      "  !!\n",
      "    check.warn(importable)\n",
      "  copying tflite_support\\metadata_schema.fbs -> build\\lib.win-amd64-cpython-312\\tflite_support\n",
      "  creating build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "  copying tflite_support\\flatbuffers\\__init__.py -> build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "  copying tflite_support\\flatbuffers\\builder.py -> build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "  copying tflite_support\\flatbuffers\\compat.py -> build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "  copying tflite_support\\flatbuffers\\encode.py -> build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "  copying tflite_support\\flatbuffers\\number_types.py -> build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "  copying tflite_support\\flatbuffers\\packer.py -> build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "  copying tflite_support\\flatbuffers\\table.py -> build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "  copying tflite_support\\flatbuffers\\util.py -> build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "  running build_ext\n",
      "  building '_pywrap_codegen' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for tflite_support\n",
      "ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (tflite_support)\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 594, in entrypoint\n",
      "    getattr(model, mode)(**overrides)  # default args from model\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 590, in export\n",
      "    return Exporter(overrides=args, _callbacks=self.callbacks)(model=self.model)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\exporter.py\", line 297, in __call__\n",
      "    f[5], keras_model = self.export_saved_model()\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\exporter.py\", line 138, in outer_func\n",
      "    raise e\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\exporter.py\", line 133, in outer_func\n",
      "    f, model = inner_func(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\exporter.py\", line 762, in export_saved_model\n",
      "    import onnx2tf\n",
      "ModuleNotFoundError: No module named 'onnx2tf'\n"
     ]
    }
   ],
   "source": [
    "!yolo export model=C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt format=tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2823fa7f-5c6d-4121-b37b-3f22ab32ce11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow-addons (from versions: none)\n",
      "ERROR: No matching distribution found for tensorflow-addons\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1da56fa1-3d92-41ba-ba7c-b715e685c657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 300, 6) (5.5 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnx2tf>=1.15.4,<=1.17.5', 'sng4onnx>=1.0.1', 'onnxslim==0.1.31', 'onnx_graphsurgeon>=0.3.26', 'tflite_support', 'onnxruntime'] not found, attempting AutoUpdate...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m â�Œ Command 'pip install --no-cache \"onnx2tf>=1.15.4,<=1.17.5\" \"sng4onnx>=1.0.1\" \"onnxslim==0.1.31\" \"onnx_graphsurgeon>=0.3.26\" \"tflite_support\" \"onnxruntime\" --extra-index-url https://pypi.ngc.nvidia.com' returned non-zero exit status 1.\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.17.0...\n",
      "WARNING âš ï¸� tensorflow<=2.13.1 is required, but tensorflow==2.17.0 is currently installed https://github.com/ultralytics/ultralytics/issues/5161\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export failure â�Œ 31.9s: No module named 'onnx2tf'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [84 lines of output]\n",
      "  C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\setuptools\\__init__.py:88: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
      "  !!\n",
      "  \n",
      "          ********************************************************************************\n",
      "          Requirements should be satisfied by a PEP 517 installer.\n",
      "          If you are using pip, you can try `pip install --use-pep517`.\n",
      "          ********************************************************************************\n",
      "  \n",
      "  !!\n",
      "    dist.fetch_build_eggs(dist.setup_requires)\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-312\n",
      "  creating build\\lib.win-amd64-cpython-312\\tflite_support\n",
      "  copying tflite_support\\codegen.py -> build\\lib.win-amd64-cpython-312\\tflite_support\n",
      "  copying tflite_support\\metadata.py -> build\\lib.win-amd64-cpython-312\\tflite_support\n",
      "  copying tflite_support\\metadata_schema_py_generated.py -> build\\lib.win-amd64-cpython-312\\tflite_support\n",
      "  copying tflite_support\\schema_py_generated.py -> build\\lib.win-amd64-cpython-312\\tflite_support\n",
      "  copying tflite_support\\__init__.py -> build\\lib.win-amd64-cpython-312\\tflite_support\n",
      "  running egg_info\n",
      "  writing tflite_support.egg-info\\PKG-INFO\n",
      "  writing dependency_links to tflite_support.egg-info\\dependency_links.txt\n",
      "  writing entry points to tflite_support.egg-info\\entry_points.txt\n",
      "  writing requirements to tflite_support.egg-info\\requires.txt\n",
      "  writing top-level names to tflite_support.egg-info\\top_level.txt\n",
      "  reading manifest file 'tflite_support.egg-info\\SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  writing manifest file 'tflite_support.egg-info\\SOURCES.txt'\n",
      "  C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\setuptools\\command\\build_py.py:218: _Warning: Package 'tflite_support.flatbuffers' is absent from the `packages` configuration.\n",
      "  !!\n",
      "  \n",
      "          ********************************************************************************\n",
      "          ############################\n",
      "          # Package would be ignored #\n",
      "          ############################\n",
      "          Python recognizes 'tflite_support.flatbuffers' as an importable package[^1],\n",
      "          but it is absent from setuptools' `packages` configuration.\n",
      "  \n",
      "          This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "          package, please make sure that 'tflite_support.flatbuffers' is explicitly added\n",
      "          to the `packages` configuration field.\n",
      "  \n",
      "          Alternatively, you can also rely on setuptools' discovery methods\n",
      "          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "          instead of `find_packages(...)`/`find:`).\n",
      "  \n",
      "          You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \n",
      "          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \n",
      "          If you don't want 'tflite_support.flatbuffers' to be distributed and are\n",
      "          already explicitly excluding 'tflite_support.flatbuffers' via\n",
      "          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "          you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "          combination with a more fine grained `package-data` configuration.\n",
      "  \n",
      "          You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \n",
      "          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \n",
      "  \n",
      "          [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                even if it does not contain any `.py` files.\n",
      "                On the other hand, currently there is no concept of package data\n",
      "                directory, all directories are treated like packages.\n",
      "          ********************************************************************************\n",
      "  \n",
      "  !!\n",
      "    check.warn(importable)\n",
      "  copying tflite_support\\metadata_schema.fbs -> build\\lib.win-amd64-cpython-312\\tflite_support\n",
      "  creating build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "  copying tflite_support\\flatbuffers\\__init__.py -> build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "  copying tflite_support\\flatbuffers\\builder.py -> build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "  copying tflite_support\\flatbuffers\\compat.py -> build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "  copying tflite_support\\flatbuffers\\encode.py -> build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "  copying tflite_support\\flatbuffers\\number_types.py -> build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "  copying tflite_support\\flatbuffers\\packer.py -> build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "  copying tflite_support\\flatbuffers\\table.py -> build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "  copying tflite_support\\flatbuffers\\util.py -> build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "  running build_ext\n",
      "  building '_pywrap_codegen' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for tflite_support\n",
      "ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (tflite_support)\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 594, in entrypoint\n",
      "    getattr(model, mode)(**overrides)  # default args from model\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 590, in export\n",
      "    return Exporter(overrides=args, _callbacks=self.callbacks)(model=self.model)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\exporter.py\", line 297, in __call__\n",
      "    f[5], keras_model = self.export_saved_model()\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\exporter.py\", line 138, in outer_func\n",
      "    raise e\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\exporter.py\", line 133, in outer_func\n",
      "    f, model = inner_func(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\exporter.py\", line 762, in export_saved_model\n",
      "    import onnx2tf\n",
      "ModuleNotFoundError: No module named 'onnx2tf'\n"
     ]
    }
   ],
   "source": [
    "!yolo export model=C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt format=tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9cf020cc-95c1-4fc4-bc69-ddf00ea161a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 300, 6) (5.5 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnx2tf>=1.15.4,<=1.17.5', 'tflite_support'] not found, attempting AutoUpdate...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m â�Œ Command 'pip install --no-cache \"onnx2tf>=1.15.4,<=1.17.5\" \"tflite_support\" --extra-index-url https://pypi.ngc.nvidia.com' returned non-zero exit status 1.\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.17.0...\n",
      "WARNING âš ï¸� tensorflow<=2.13.1 is required, but tensorflow==2.17.0 is currently installed https://github.com/ultralytics/ultralytics/issues/5161\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.1 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m simplifying with onnxslim 0.1.31...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 4.7s, saved as 'C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.onnx' (9.0 MB)\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.25.7...\n",
      "\u001b[31mERROR:\u001b[0m Generation of saved_model failed because the OP name does not match the following pattern. ^[A-Za-z0-9.][A-Za-z0-9_.\\\\/>-]*$\n",
      "\u001b[31mERROR:\u001b[0m /model.10/attn/pe/conv/Conv/kernel\n",
      "\u001b[31mERROR:\u001b[0m Please convert again with the `-osd` or `--output_signaturedefs` option.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [84 lines of output]\n",
      "  C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\setuptools\\__init__.py:88: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
      "  !!\n",
      "  \n",
      "          ********************************************************************************\n",
      "          Requirements should be satisfied by a PEP 517 installer.\n",
      "          If you are using pip, you can try `pip install --use-pep517`.\n",
      "          ********************************************************************************\n",
      "  \n",
      "  !!\n",
      "    dist.fetch_build_eggs(dist.setup_requires)\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-312\n",
      "  creating build\\lib.win-amd64-cpython-312\\tflite_support\n",
      "  copying tflite_support\\codegen.py -> build\\lib.win-amd64-cpython-312\\tflite_support\n",
      "  copying tflite_support\\metadata.py -> build\\lib.win-amd64-cpython-312\\tflite_support\n",
      "  copying tflite_support\\metadata_schema_py_generated.py -> build\\lib.win-amd64-cpython-312\\tflite_support\n",
      "  copying tflite_support\\schema_py_generated.py -> build\\lib.win-amd64-cpython-312\\tflite_support\n",
      "  copying tflite_support\\__init__.py -> build\\lib.win-amd64-cpython-312\\tflite_support\n",
      "  running egg_info\n",
      "  writing tflite_support.egg-info\\PKG-INFO\n",
      "  writing dependency_links to tflite_support.egg-info\\dependency_links.txt\n",
      "  writing entry points to tflite_support.egg-info\\entry_points.txt\n",
      "  writing requirements to tflite_support.egg-info\\requires.txt\n",
      "  writing top-level names to tflite_support.egg-info\\top_level.txt\n",
      "  reading manifest file 'tflite_support.egg-info\\SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  writing manifest file 'tflite_support.egg-info\\SOURCES.txt'\n",
      "  C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\setuptools\\command\\build_py.py:218: _Warning: Package 'tflite_support.flatbuffers' is absent from the `packages` configuration.\n",
      "  !!\n",
      "  \n",
      "          ********************************************************************************\n",
      "          ############################\n",
      "          # Package would be ignored #\n",
      "          ############################\n",
      "          Python recognizes 'tflite_support.flatbuffers' as an importable package[^1],\n",
      "          but it is absent from setuptools' `packages` configuration.\n",
      "  \n",
      "          This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "          package, please make sure that 'tflite_support.flatbuffers' is explicitly added\n",
      "          to the `packages` configuration field.\n",
      "  \n",
      "          Alternatively, you can also rely on setuptools' discovery methods\n",
      "          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "          instead of `find_packages(...)`/`find:`).\n",
      "  \n",
      "          You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \n",
      "          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \n",
      "          If you don't want 'tflite_support.flatbuffers' to be distributed and are\n",
      "          already explicitly excluding 'tflite_support.flatbuffers' via\n",
      "          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "          you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "          combination with a more fine grained `package-data` configuration.\n",
      "  \n",
      "          You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \n",
      "          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \n",
      "  \n",
      "          [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                even if it does not contain any `.py` files.\n",
      "                On the other hand, currently there is no concept of package data\n",
      "                directory, all directories are treated like packages.\n",
      "          ********************************************************************************\n",
      "  \n",
      "  !!\n",
      "    check.warn(importable)\n",
      "  copying tflite_support\\metadata_schema.fbs -> build\\lib.win-amd64-cpython-312\\tflite_support\n",
      "  creating build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "  copying tflite_support\\flatbuffers\\__init__.py -> build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "  copying tflite_support\\flatbuffers\\builder.py -> build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "  copying tflite_support\\flatbuffers\\compat.py -> build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "  copying tflite_support\\flatbuffers\\encode.py -> build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "  copying tflite_support\\flatbuffers\\number_types.py -> build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "  copying tflite_support\\flatbuffers\\packer.py -> build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "  copying tflite_support\\flatbuffers\\table.py -> build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "  copying tflite_support\\flatbuffers\\util.py -> build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "  running build_ext\n",
      "  building '_pywrap_codegen' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for tflite_support\n",
      "ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (tflite_support)\n",
      "WARNING:tensorflow:From C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-08-26 01:18:27.088333: E tensorflow/core/util/util.cc:131] oneDNN supports DT_INT64 only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n"
     ]
    }
   ],
   "source": [
    "!yolo export model=C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt format=tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9396fee8-8e31-4290-a57c-f3702350c683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 300, 6) (5.5 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnx2tf>=1.15.4,<=1.17.5', 'tflite_support'] not found, attempting AutoUpdate...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m â�Œ Command 'pip install --no-cache \"onnx2tf>=1.15.4,<=1.17.5\" \"tflite_support\" --extra-index-url https://pypi.ngc.nvidia.com' returned non-zero exit status 1.\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.17.0...\n",
      "WARNING âš ï¸� tensorflow<=2.13.1 is required, but tensorflow==2.17.0 is currently installed https://github.com/ultralytics/ultralytics/issues/5161\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.1 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m simplifying with onnxslim 0.1.31...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 3.6s, saved as 'C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.onnx' (9.0 MB)\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.25.7...\n",
      "\u001b[31mERROR:\u001b[0m Generation of saved_model failed because the OP name does not match the following pattern. ^[A-Za-z0-9.][A-Za-z0-9_.\\\\/>-]*$\n",
      "\u001b[31mERROR:\u001b[0m /model.10/attn/pe/conv/Conv/kernel\n",
      "\u001b[31mERROR:\u001b[0m Please convert again with the `-osd` or `--output_signaturedefs` option.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [84 lines of output]\n",
      "  C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\setuptools\\__init__.py:88: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
      "  !!\n",
      "  \n",
      "          ********************************************************************************\n",
      "          Requirements should be satisfied by a PEP 517 installer.\n",
      "          If you are using pip, you can try `pip install --use-pep517`.\n",
      "          ********************************************************************************\n",
      "  \n",
      "  !!\n",
      "    dist.fetch_build_eggs(dist.setup_requires)\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-312\n",
      "  creating build\\lib.win-amd64-cpython-312\\tflite_support\n",
      "  copying tflite_support\\codegen.py -> build\\lib.win-amd64-cpython-312\\tflite_support\n",
      "  copying tflite_support\\metadata.py -> build\\lib.win-amd64-cpython-312\\tflite_support\n",
      "  copying tflite_support\\metadata_schema_py_generated.py -> build\\lib.win-amd64-cpython-312\\tflite_support\n",
      "  copying tflite_support\\schema_py_generated.py -> build\\lib.win-amd64-cpython-312\\tflite_support\n",
      "  copying tflite_support\\__init__.py -> build\\lib.win-amd64-cpython-312\\tflite_support\n",
      "  running egg_info\n",
      "  writing tflite_support.egg-info\\PKG-INFO\n",
      "  writing dependency_links to tflite_support.egg-info\\dependency_links.txt\n",
      "  writing entry points to tflite_support.egg-info\\entry_points.txt\n",
      "  writing requirements to tflite_support.egg-info\\requires.txt\n",
      "  writing top-level names to tflite_support.egg-info\\top_level.txt\n",
      "  reading manifest file 'tflite_support.egg-info\\SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  writing manifest file 'tflite_support.egg-info\\SOURCES.txt'\n",
      "  C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\setuptools\\command\\build_py.py:218: _Warning: Package 'tflite_support.flatbuffers' is absent from the `packages` configuration.\n",
      "  !!\n",
      "  \n",
      "          ********************************************************************************\n",
      "          ############################\n",
      "          # Package would be ignored #\n",
      "          ############################\n",
      "          Python recognizes 'tflite_support.flatbuffers' as an importable package[^1],\n",
      "          but it is absent from setuptools' `packages` configuration.\n",
      "  \n",
      "          This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "          package, please make sure that 'tflite_support.flatbuffers' is explicitly added\n",
      "          to the `packages` configuration field.\n",
      "  \n",
      "          Alternatively, you can also rely on setuptools' discovery methods\n",
      "          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "          instead of `find_packages(...)`/`find:`).\n",
      "  \n",
      "          You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \n",
      "          - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \n",
      "          If you don't want 'tflite_support.flatbuffers' to be distributed and are\n",
      "          already explicitly excluding 'tflite_support.flatbuffers' via\n",
      "          `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "          you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "          combination with a more fine grained `package-data` configuration.\n",
      "  \n",
      "          You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \n",
      "          - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \n",
      "  \n",
      "          [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                even if it does not contain any `.py` files.\n",
      "                On the other hand, currently there is no concept of package data\n",
      "                directory, all directories are treated like packages.\n",
      "          ********************************************************************************\n",
      "  \n",
      "  !!\n",
      "    check.warn(importable)\n",
      "  copying tflite_support\\metadata_schema.fbs -> build\\lib.win-amd64-cpython-312\\tflite_support\n",
      "  creating build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "  copying tflite_support\\flatbuffers\\__init__.py -> build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "  copying tflite_support\\flatbuffers\\builder.py -> build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "  copying tflite_support\\flatbuffers\\compat.py -> build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "  copying tflite_support\\flatbuffers\\encode.py -> build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "  copying tflite_support\\flatbuffers\\number_types.py -> build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "  copying tflite_support\\flatbuffers\\packer.py -> build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "  copying tflite_support\\flatbuffers\\table.py -> build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "  copying tflite_support\\flatbuffers\\util.py -> build\\lib.win-amd64-cpython-312\\tflite_support\\flatbuffers\n",
      "  running build_ext\n",
      "  building '_pywrap_codegen' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for tflite_support\n",
      "ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (tflite_support)\n",
      "WARNING:tensorflow:From C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2024-08-26 02:03:35.300604: E tensorflow/core/util/util.cc:131] oneDNN supports DT_INT64 only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n"
     ]
    }
   ],
   "source": [
    "!yolo export model=C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt format=tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1291d8cf-6400-4a7a-9c0f-43499c2af72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\sshiv\\AppData\\Local\\Temp\\ipykernel_1804\\86653190.py:2: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  model=YOLO('runs\\detect\\train10\\weights\\best.pt')\n",
      "C:\\Users\\sshiv\\AppData\\Local\\Temp\\ipykernel_1804\\86653190.py:2: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  model=YOLO('runs\\detect\\train10\\weights\\best.pt')\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'runs\\\\detect\\train10\\\\weights\\x08est.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[1;32m----> 2\u001b[0m model\u001b[38;5;241m=\u001b[39m\u001b[43mYOLO\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mruns\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mdetect\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43mrain10\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mweights\u001b[39;49m\u001b[38;5;130;43;01m\\b\u001b[39;49;00m\u001b[38;5;124;43mest.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mexport(\u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtflite\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\models\\yolo\\model.py:28\u001b[0m, in \u001b[0;36mYOLO.__init__\u001b[1;34m(self, model, task, verbose)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m \u001b[38;5;241m=\u001b[39m new_instance\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# Continue with default YOLO initialization\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py:141\u001b[0m, in \u001b[0;36mModel.__init__\u001b[1;34m(self, model, task, verbose)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(model, task\u001b[38;5;241m=\u001b[39mtask, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 141\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py:230\u001b[0m, in \u001b[0;36mModel._load\u001b[1;34m(self, weights, task)\u001b[0m\n\u001b[0;32m    227\u001b[0m weights \u001b[38;5;241m=\u001b[39m checks\u001b[38;5;241m.\u001b[39mcheck_model_file_from_stem(weights)  \u001b[38;5;66;03m# add suffix, i.e. yolov8n -> yolov8n.pt\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Path(weights)\u001b[38;5;241m.\u001b[39msuffix \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 230\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;241m=\u001b[39m \u001b[43mattempt_load_one_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset_ckpt_args(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:807\u001b[0m, in \u001b[0;36mattempt_load_one_weight\u001b[1;34m(weight, device, inplace, fuse)\u001b[0m\n\u001b[0;32m    805\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mattempt_load_one_weight\u001b[39m(weight, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fuse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    806\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a single model weights.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 807\u001b[0m     ckpt, weight \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_safe_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# load ckpt\u001b[39;00m\n\u001b[0;32m    808\u001b[0m     args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mDEFAULT_CFG_DICT, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_args\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))}  \u001b[38;5;66;03m# combine model and default args, preferring model args\u001b[39;00m\n\u001b[0;32m    809\u001b[0m     model \u001b[38;5;241m=\u001b[39m (ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mema\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m ckpt[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# FP32 model\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733\u001b[0m, in \u001b[0;36mtorch_safe_load\u001b[1;34m(weight)\u001b[0m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    726\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m temporary_modules(\n\u001b[0;32m    727\u001b[0m         {\n\u001b[0;32m    728\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124multralytics.yolo.utils\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124multralytics.utils\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    731\u001b[0m         }\n\u001b[0;32m    732\u001b[0m     ):  \u001b[38;5;66;03m# for legacy 8.0 Classify and Pose models\u001b[39;00m\n\u001b[1;32m--> 733\u001b[0m         ckpt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# e.name is missing module name\u001b[39;00m\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:1065\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1063\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m-> 1065\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m   1066\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1067\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1068\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1069\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1070\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:468\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 468\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    470\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:449\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'runs\\\\detect\\train10\\\\weights\\x08est.pt'"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model=YOLO('runs\\detect\\train10\\weights\\best.pt')\n",
    "model.export(format='tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2c4151a5-5da2-4f6e-bb64-1afde69fee3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 🚀 Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 300, 6) (5.5 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnx2tf>=1.15.4,<=1.17.5', 'tflite_support'] not found, attempting AutoUpdate...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m ❌ Command 'pip install --no-cache \"onnx2tf>=1.15.4,<=1.17.5\" \"tflite_support\" --extra-index-url https://pypi.ngc.nvidia.com' returned non-zero exit status 1.\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.17.0...\n",
      "WARNING ⚠️ tensorflow<=2.13.1 is required, but tensorflow==2.17.0 is currently installed https://github.com/ultralytics/ultralytics/issues/5161\n",
      "WARNING:tensorflow:From C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/calibration_image_sample_data_20x128x128x3_float32.npy.zip to 'calibration_image_sample_data_20x128x128x3_float32.npy.zip'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 1.11M/1.11M [00:05<00:00, 195kB/s]\n",
      "Unzipping calibration_image_sample_data_20x128x128x3_float32.npy.zip t"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.1 opset 19...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mONNX:\u001b[0m simplifying with onnxslim 0.1.31...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 3.9s, saved as 'best.onnx' (9.0 MB)\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.25.7...\n",
      "\u001b[31mERROR:\u001b[0m Generation of saved_model failed because the OP name does not match the following pattern. ^[A-Za-z0-9.][A-Za-z0-9_.\\\\/>-]*$\n",
      "\u001b[31mERROR:\u001b[0m /model.10/attn/pe/conv/Conv/kernel\n",
      "\u001b[31mERROR:\u001b[0m Please convert again with the `-osd` or `--output_signaturedefs` option.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'tb_frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\onnx2tf\\onnx2tf.py:1330\u001b[0m, in \u001b[0;36mconvert\u001b[1;34m(input_onnx_file_path, onnx_graph, output_folder_path, output_signaturedefs, output_h5, output_keras_v3, output_tfv1_pb, output_weights, copy_onnx_input_output_names_to_tflite, output_dynamic_range_quantized_tflite, output_integer_quantized_tflite, quant_type, custom_input_op_name_np_data_path, input_output_quant_dtype, not_use_onnxsim, not_use_opname_auto_generate, batch_size, overwrite_input_shape, no_large_tensor, output_nms_with_dynamic_tensor, keep_ncw_or_nchw_or_ncdhw_input_names, keep_nwc_or_nhwc_or_ndhwc_input_names, keep_shape_absolutely_input_names, input_names_to_interrupt_model_conversion, output_names_to_interrupt_model_conversion, disable_group_convolution, enable_accumulation_type_float16, enable_batchmatmul_unfold, enable_rnn_unroll, disable_suppression_flextranspose, disable_strict_mode, number_of_dimensions_after_flextranspose_compression, disable_suppression_flexstridedslice, number_of_dimensions_after_flexstridedslice_compression, optimization_for_gpu_delegate, replace_argmax_to_reducemax_and_indices_is_int64, replace_argmax_to_reducemax_and_indices_is_float32, replace_argmax_to_fused_argmax_and_indices_is_int64, replace_argmax_to_fused_argmax_and_indices_is_float32, fused_argmax_scale_ratio, replace_to_pseudo_operators, param_replacement_file, check_gpu_delegate_compatibility, check_onnx_tf_outputs_elementwise_close, check_onnx_tf_outputs_elementwise_close_full, check_onnx_tf_outputs_sample_data_normalization, check_onnx_tf_outputs_elementwise_close_rtol, check_onnx_tf_outputs_elementwise_close_atol, mvn_epsilon, disable_model_save, non_verbose, verbosity)\u001b[0m\n\u001b[0;32m   1325\u001b[0m export_archive\u001b[38;5;241m.\u001b[39madd_endpoint(\n\u001b[0;32m   1326\u001b[0m     name\u001b[38;5;241m=\u001b[39mSIGNATURE_KEY,\n\u001b[0;32m   1327\u001b[0m     fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39minputs : model(inputs),\n\u001b[0;32m   1328\u001b[0m     input_signature\u001b[38;5;241m=\u001b[39m[tf\u001b[38;5;241m.\u001b[39mTensorSpec(tensor\u001b[38;5;241m.\u001b[39mshape, tensor\u001b[38;5;241m.\u001b[39mdtype, tensor\u001b[38;5;241m.\u001b[39mname) \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39minputs],\n\u001b[0;32m   1329\u001b[0m )\n\u001b[1;32m-> 1330\u001b[0m \u001b[43mexport_archive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_out\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_folder_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\export\\export_lib.py:351\u001b[0m, in \u001b[0;36mExportArchive.write_out\u001b[1;34m(self, filepath, options)\u001b[0m\n\u001b[0;32m    348\u001b[0m     signatures[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserving_default\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_concrete_fn(\n\u001b[0;32m    349\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_endpoint_names[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    350\u001b[0m     )\n\u001b[1;32m--> 351\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaved_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignatures\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;66;03m# Print out available endpoints\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\saved_model\\save.py:1432\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[0;32m   1431\u001b[0m metrics\u001b[38;5;241m.\u001b[39mIncrementWriteApi(_SAVE_V2_LABEL)\n\u001b[1;32m-> 1432\u001b[0m \u001b[43msave_and_return_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1434\u001b[0m metrics\u001b[38;5;241m.\u001b[39mIncrementWrite(write_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\saved_model\\save.py:1467\u001b[0m, in \u001b[0;36msave_and_return_nodes\u001b[1;34m(obj, export_dir, signatures, options, experimental_skip_checkpoint)\u001b[0m\n\u001b[0;32m   1464\u001b[0m meta_graph_def \u001b[38;5;241m=\u001b[39m saved_model\u001b[38;5;241m.\u001b[39mmeta_graphs\u001b[38;5;241m.\u001b[39madd()\n\u001b[0;32m   1466\u001b[0m _, exported_graph, object_saver, asset_info, saved_nodes, node_paths \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 1467\u001b[0m     \u001b[43m_build_meta_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_graph_def\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1468\u001b[0m saved_model\u001b[38;5;241m.\u001b[39msaved_model_schema_version \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1469\u001b[0m     constants\u001b[38;5;241m.\u001b[39mSAVED_MODEL_SCHEMA_VERSION)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\saved_model\\save.py:1682\u001b[0m, in \u001b[0;36m_build_meta_graph\u001b[1;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[0;32m   1681\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m save_context\u001b[38;5;241m.\u001b[39msave_context(options):\n\u001b[1;32m-> 1682\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_build_meta_graph_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_graph_def\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\saved_model\\save.py:1606\u001b[0m, in \u001b[0;36m_build_meta_graph_impl\u001b[1;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[0;32m   1605\u001b[0m object_saver \u001b[38;5;241m=\u001b[39m checkpoint\u001b[38;5;241m.\u001b[39mTrackableSaver(augmented_graph_view)\n\u001b[1;32m-> 1606\u001b[0m asset_info, exported_graph \u001b[38;5;241m=\u001b[39m \u001b[43m_fill_meta_graph_def\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmeta_graph_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeta_graph_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1608\u001b[0m \u001b[43m    \u001b[49m\u001b[43msaveable_view\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msaveable_view\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1609\u001b[0m \u001b[43m    \u001b[49m\u001b[43msignature_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnamespace_whitelist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnamespace_whitelist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1611\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_custom_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperimental_custom_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_saver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperimental_skip_saver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1613\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_debug_stripper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperimental_debug_stripper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefaults\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1615\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m options\u001b[38;5;241m.\u001b[39mfunction_aliases:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\saved_model\\save.py:969\u001b[0m, in \u001b[0;36m_fill_meta_graph_def\u001b[1;34m(meta_graph_def, saveable_view, signature_functions, namespace_whitelist, save_custom_gradients, create_saver, enable_debug_stripper, defaults)\u001b[0m\n\u001b[0;32m    968\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m exported_graph\u001b[38;5;241m.\u001b[39mas_default():\n\u001b[1;32m--> 969\u001b[0m   object_map, tensor_map, asset_info \u001b[38;5;241m=\u001b[39m \u001b[43msaveable_view\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_resources\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    970\u001b[0m   signatures \u001b[38;5;241m=\u001b[39m _generate_signatures(signature_functions, object_map, defaults)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\saved_model\\save.py:421\u001b[0m, in \u001b[0;36m_SaveableView.map_resources\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    420\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes[node_id]\n\u001b[1;32m--> 421\u001b[0m tensors \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_export_to_saved_model_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobject_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\n\u001b[0;32m    423\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, asset\u001b[38;5;241m.\u001b[39mAsset):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:770\u001b[0m, in \u001b[0;36mBaseResourceVariable._export_to_saved_model_graph\u001b[1;34m(self, object_map, tensor_map, options, **kwargs)\u001b[0m\n\u001b[0;32m    769\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 770\u001b[0m   new_variable \u001b[38;5;241m=\u001b[39m \u001b[43mcopy_to_graph_uninitialized\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    771\u001b[0m object_map[\u001b[38;5;28mself\u001b[39m] \u001b[38;5;241m=\u001b[39m new_variable\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:2558\u001b[0m, in \u001b[0;36mcopy_to_graph_uninitialized\u001b[1;34m(var)\u001b[0m\n\u001b[0;32m   2555\u001b[0m \u001b[38;5;66;03m# Like ResourceVariable.__deepcopy__, but does not set an initializer on the\u001b[39;00m\n\u001b[0;32m   2556\u001b[0m \u001b[38;5;66;03m# new variable.\u001b[39;00m\n\u001b[0;32m   2557\u001b[0m \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 2558\u001b[0m new_variable \u001b[38;5;241m=\u001b[39m \u001b[43mUninitializedVariable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2559\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2560\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_constraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2561\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2562\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_shared_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2564\u001b[0m \u001b[43m    \u001b[49m\u001b[43msynchronization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynchronization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2565\u001b[0m \u001b[43m    \u001b[49m\u001b[43maggregation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_handle_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2567\u001b[0m new_variable\u001b[38;5;241m.\u001b[39m_maybe_initialize_trackable()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: '/model.10/attn/pe/conv/Conv/kernel' is not a valid root scope name. A root scope name has to match the following pattern: ^[A-Za-z0-9.][A-Za-z0-9_.\\\\/>-]*$",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSystemExit\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn[75], line 3\u001b[0m\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m=\u001b[39mYOLO(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtflite\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py:590\u001b[0m, in \u001b[0;36mModel.export\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    589\u001b[0m args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcustom, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexport\u001b[39m\u001b[38;5;124m\"\u001b[39m}  \u001b[38;5;66;03m# highest priority args on the right\u001b[39;00m\n\u001b[1;32m--> 590\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mExporter\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_callbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\exporter.py:297\u001b[0m, in \u001b[0;36mExporter.__call__\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mint8 \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m edgetpu\n\u001b[1;32m--> 297\u001b[0m f[\u001b[38;5;241m5\u001b[39m], keras_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport_saved_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pb \u001b[38;5;129;01mor\u001b[39;00m tfjs:  \u001b[38;5;66;03m# pb prerequisite to tfjs\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\exporter.py:133\u001b[0m, in \u001b[0;36mtry_export.<locals>.outer_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Profile() \u001b[38;5;28;01mas\u001b[39;00m dt:\n\u001b[1;32m--> 133\u001b[0m     f, model \u001b[38;5;241m=\u001b[39m \u001b[43minner_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m export success ✅ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdt\u001b[38;5;241m.\u001b[39mt\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms, saved as \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_size(f)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m MB)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\exporter.py:803\u001b[0m, in \u001b[0;36mExporter.export_saved_model\u001b[1;34m(self, prefix)\u001b[0m\n\u001b[0;32m    802\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m starting TFLite export with onnx2tf \u001b[39m\u001b[38;5;132;01m{\u001b[39;00monnx2tf\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 803\u001b[0m \u001b[43monnx2tf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_onnx_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mf_onnx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_folder_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    806\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnot_use_onnxsim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    807\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    808\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_integer_quantized_tflite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint8\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    809\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquant_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mper-tensor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# \"per-tensor\" (faster) or \"per-channel\" (slower but more accurate)\u001b[39;49;00m\n\u001b[0;32m    810\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_input_op_name_np_data_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    811\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    812\u001b[0m yaml_save(f \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata)  \u001b[38;5;66;03m# add metadata.yaml\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\onnx2tf\\onnx2tf.py:1345\u001b[0m, in \u001b[0;36mconvert\u001b[1;34m(input_onnx_file_path, onnx_graph, output_folder_path, output_signaturedefs, output_h5, output_keras_v3, output_tfv1_pb, output_weights, copy_onnx_input_output_names_to_tflite, output_dynamic_range_quantized_tflite, output_integer_quantized_tflite, quant_type, custom_input_op_name_np_data_path, input_output_quant_dtype, not_use_onnxsim, not_use_opname_auto_generate, batch_size, overwrite_input_shape, no_large_tensor, output_nms_with_dynamic_tensor, keep_ncw_or_nchw_or_ncdhw_input_names, keep_nwc_or_nhwc_or_ndhwc_input_names, keep_shape_absolutely_input_names, input_names_to_interrupt_model_conversion, output_names_to_interrupt_model_conversion, disable_group_convolution, enable_accumulation_type_float16, enable_batchmatmul_unfold, enable_rnn_unroll, disable_suppression_flextranspose, disable_strict_mode, number_of_dimensions_after_flextranspose_compression, disable_suppression_flexstridedslice, number_of_dimensions_after_flexstridedslice_compression, optimization_for_gpu_delegate, replace_argmax_to_reducemax_and_indices_is_int64, replace_argmax_to_reducemax_and_indices_is_float32, replace_argmax_to_fused_argmax_and_indices_is_int64, replace_argmax_to_fused_argmax_and_indices_is_float32, fused_argmax_scale_ratio, replace_to_pseudo_operators, param_replacement_file, check_gpu_delegate_compatibility, check_onnx_tf_outputs_elementwise_close, check_onnx_tf_outputs_elementwise_close_full, check_onnx_tf_outputs_sample_data_normalization, check_onnx_tf_outputs_elementwise_close_rtol, check_onnx_tf_outputs_elementwise_close_atol, mvn_epsilon, disable_model_save, non_verbose, verbosity)\u001b[0m\n\u001b[0;32m   1342\u001b[0m             error(\n\u001b[0;32m   1343\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease convert again with the `-osd` or `--output_signaturedefs` option.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1344\u001b[0m             )\n\u001b[1;32m-> 1345\u001b[0m             \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mSystemExit\u001b[0m: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                        Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2145\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_only:\n\u001b[0;32m   2143\u001b[0m     stb \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn exception has occurred, use \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mtb to see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2144\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe full traceback.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m-> 2145\u001b[0m     stb\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInteractiveTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_exception_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2146\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   2147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2149\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcontains_exceptiongroup\u001b[39m(val):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\ultratb.py:710\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[1;34m(self, etype, value)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_exception_only\u001b[39m(\u001b[38;5;28mself\u001b[39m, etype, value):\n\u001b[0;32m    703\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \n\u001b[0;32m    705\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;124;03m    value : exception value\u001b[39;00m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 710\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mListTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\ultratb.py:568\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[0;32m    565\u001b[0m     chained_exc_ids\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(exception[\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m    566\u001b[0m     chained_exceptions_tb_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    567\u001b[0m     out_list \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 568\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m            \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchained_exc_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[0;32m    572\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchained_exceptions_tb_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m         \u001b[38;5;241m+\u001b[39m chained_exception_message\n\u001b[0;32m    576\u001b[0m         \u001b[38;5;241m+\u001b[39m out_list)\n\u001b[0;32m    578\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_list\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\ultratb.py:1454\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1452\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1453\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtb \u001b[38;5;241m=\u001b[39m etb\n\u001b[1;32m-> 1454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1455\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[0;32m   1456\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\ultratb.py:1345\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1342\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[0;32m   1343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose_modes:\n\u001b[0;32m   1344\u001b[0m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[1;32m-> 1345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1346\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[0;32m   1347\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1348\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinimal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m   1349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ListTB\u001b[38;5;241m.\u001b[39mget_exception_only(\u001b[38;5;28mself\u001b[39m, etype, value)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\ultratb.py:1192\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstructured_traceback\u001b[39m(\n\u001b[0;32m   1184\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1185\u001b[0m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1189\u001b[0m     number_of_lines_of_context: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m   1190\u001b[0m ):\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1192\u001b[0m     formatted_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1193\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1195\u001b[0m     colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mColors  \u001b[38;5;66;03m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m     colorsnormal \u001b[38;5;241m=\u001b[39m colors\u001b[38;5;241m.\u001b[39mNormal  \u001b[38;5;66;03m# used a lot\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\ultratb.py:1082\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1079\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tb_offset, \u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m   1080\u001b[0m head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_header(\u001b[38;5;28mstr\u001b[39m(etype), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlong_header)\n\u001b[0;32m   1081\u001b[0m records \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 1082\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m etb \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[0;32m   1083\u001b[0m )\n\u001b[0;32m   1085\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1086\u001b[0m skipped \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\ultratb.py:1150\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[1;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1148\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1149\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1150\u001b[0m         mod \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetmodule(\u001b[43mcf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtb_frame\u001b[49m)\n\u001b[0;32m   1151\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1152\u001b[0m             mod_name \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'tb_frame'"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model=YOLO('best.pt')\n",
    "model.export(format='tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "466cdcf6-8617-4412-b33a-8be9e5dc0cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 🚀 Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 300, 6) (5.5 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnx2tf>=1.15.4,<=1.17.5', 'tflite_support'] not found, attempting AutoUpdate...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m ❌ Command 'pip install --no-cache \"onnx2tf>=1.15.4,<=1.17.5\" \"tflite_support\" --extra-index-url https://pypi.ngc.nvidia.com' returned non-zero exit status 1.\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.17.0...\n",
      "WARNING ⚠️ tensorflow<=2.13.1 is required, but tensorflow==2.17.0 is currently installed https://github.com/ultralytics/ultralytics/issues/5161\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.1 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m simplifying with onnxslim 0.1.31...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 4.1s, saved as 'best.onnx' (9.0 MB)\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.25.7...\n",
      "\u001b[31mERROR:\u001b[0m Generation of saved_model failed because the OP name does not match the following pattern. ^[A-Za-z0-9.][A-Za-z0-9_.\\\\/>-]*$\n",
      "\u001b[31mERROR:\u001b[0m /model.10/attn/pe/conv/Conv/kernel\n",
      "\u001b[31mERROR:\u001b[0m Please convert again with the `-osd` or `--output_signaturedefs` option.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'tb_frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\onnx2tf\\onnx2tf.py:1330\u001b[0m, in \u001b[0;36mconvert\u001b[1;34m(input_onnx_file_path, onnx_graph, output_folder_path, output_signaturedefs, output_h5, output_keras_v3, output_tfv1_pb, output_weights, copy_onnx_input_output_names_to_tflite, output_dynamic_range_quantized_tflite, output_integer_quantized_tflite, quant_type, custom_input_op_name_np_data_path, input_output_quant_dtype, not_use_onnxsim, not_use_opname_auto_generate, batch_size, overwrite_input_shape, no_large_tensor, output_nms_with_dynamic_tensor, keep_ncw_or_nchw_or_ncdhw_input_names, keep_nwc_or_nhwc_or_ndhwc_input_names, keep_shape_absolutely_input_names, input_names_to_interrupt_model_conversion, output_names_to_interrupt_model_conversion, disable_group_convolution, enable_accumulation_type_float16, enable_batchmatmul_unfold, enable_rnn_unroll, disable_suppression_flextranspose, disable_strict_mode, number_of_dimensions_after_flextranspose_compression, disable_suppression_flexstridedslice, number_of_dimensions_after_flexstridedslice_compression, optimization_for_gpu_delegate, replace_argmax_to_reducemax_and_indices_is_int64, replace_argmax_to_reducemax_and_indices_is_float32, replace_argmax_to_fused_argmax_and_indices_is_int64, replace_argmax_to_fused_argmax_and_indices_is_float32, fused_argmax_scale_ratio, replace_to_pseudo_operators, param_replacement_file, check_gpu_delegate_compatibility, check_onnx_tf_outputs_elementwise_close, check_onnx_tf_outputs_elementwise_close_full, check_onnx_tf_outputs_sample_data_normalization, check_onnx_tf_outputs_elementwise_close_rtol, check_onnx_tf_outputs_elementwise_close_atol, mvn_epsilon, disable_model_save, non_verbose, verbosity)\u001b[0m\n\u001b[0;32m   1325\u001b[0m export_archive\u001b[38;5;241m.\u001b[39madd_endpoint(\n\u001b[0;32m   1326\u001b[0m     name\u001b[38;5;241m=\u001b[39mSIGNATURE_KEY,\n\u001b[0;32m   1327\u001b[0m     fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39minputs : model(inputs),\n\u001b[0;32m   1328\u001b[0m     input_signature\u001b[38;5;241m=\u001b[39m[tf\u001b[38;5;241m.\u001b[39mTensorSpec(tensor\u001b[38;5;241m.\u001b[39mshape, tensor\u001b[38;5;241m.\u001b[39mdtype, tensor\u001b[38;5;241m.\u001b[39mname) \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39minputs],\n\u001b[0;32m   1329\u001b[0m )\n\u001b[1;32m-> 1330\u001b[0m \u001b[43mexport_archive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_out\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_folder_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\export\\export_lib.py:351\u001b[0m, in \u001b[0;36mExportArchive.write_out\u001b[1;34m(self, filepath, options)\u001b[0m\n\u001b[0;32m    348\u001b[0m     signatures[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserving_default\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_concrete_fn(\n\u001b[0;32m    349\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_endpoint_names[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    350\u001b[0m     )\n\u001b[1;32m--> 351\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaved_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignatures\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;66;03m# Print out available endpoints\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\saved_model\\save.py:1432\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[0;32m   1431\u001b[0m metrics\u001b[38;5;241m.\u001b[39mIncrementWriteApi(_SAVE_V2_LABEL)\n\u001b[1;32m-> 1432\u001b[0m \u001b[43msave_and_return_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1434\u001b[0m metrics\u001b[38;5;241m.\u001b[39mIncrementWrite(write_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\saved_model\\save.py:1467\u001b[0m, in \u001b[0;36msave_and_return_nodes\u001b[1;34m(obj, export_dir, signatures, options, experimental_skip_checkpoint)\u001b[0m\n\u001b[0;32m   1464\u001b[0m meta_graph_def \u001b[38;5;241m=\u001b[39m saved_model\u001b[38;5;241m.\u001b[39mmeta_graphs\u001b[38;5;241m.\u001b[39madd()\n\u001b[0;32m   1466\u001b[0m _, exported_graph, object_saver, asset_info, saved_nodes, node_paths \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 1467\u001b[0m     \u001b[43m_build_meta_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_graph_def\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1468\u001b[0m saved_model\u001b[38;5;241m.\u001b[39msaved_model_schema_version \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1469\u001b[0m     constants\u001b[38;5;241m.\u001b[39mSAVED_MODEL_SCHEMA_VERSION)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\saved_model\\save.py:1682\u001b[0m, in \u001b[0;36m_build_meta_graph\u001b[1;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[0;32m   1681\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m save_context\u001b[38;5;241m.\u001b[39msave_context(options):\n\u001b[1;32m-> 1682\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_build_meta_graph_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_graph_def\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\saved_model\\save.py:1606\u001b[0m, in \u001b[0;36m_build_meta_graph_impl\u001b[1;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[0;32m   1605\u001b[0m object_saver \u001b[38;5;241m=\u001b[39m checkpoint\u001b[38;5;241m.\u001b[39mTrackableSaver(augmented_graph_view)\n\u001b[1;32m-> 1606\u001b[0m asset_info, exported_graph \u001b[38;5;241m=\u001b[39m \u001b[43m_fill_meta_graph_def\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmeta_graph_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeta_graph_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1608\u001b[0m \u001b[43m    \u001b[49m\u001b[43msaveable_view\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msaveable_view\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1609\u001b[0m \u001b[43m    \u001b[49m\u001b[43msignature_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnamespace_whitelist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnamespace_whitelist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1611\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_custom_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperimental_custom_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_saver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperimental_skip_saver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1613\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_debug_stripper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperimental_debug_stripper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefaults\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1615\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m options\u001b[38;5;241m.\u001b[39mfunction_aliases:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\saved_model\\save.py:969\u001b[0m, in \u001b[0;36m_fill_meta_graph_def\u001b[1;34m(meta_graph_def, saveable_view, signature_functions, namespace_whitelist, save_custom_gradients, create_saver, enable_debug_stripper, defaults)\u001b[0m\n\u001b[0;32m    968\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m exported_graph\u001b[38;5;241m.\u001b[39mas_default():\n\u001b[1;32m--> 969\u001b[0m   object_map, tensor_map, asset_info \u001b[38;5;241m=\u001b[39m \u001b[43msaveable_view\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_resources\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    970\u001b[0m   signatures \u001b[38;5;241m=\u001b[39m _generate_signatures(signature_functions, object_map, defaults)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\saved_model\\save.py:421\u001b[0m, in \u001b[0;36m_SaveableView.map_resources\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    420\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes[node_id]\n\u001b[1;32m--> 421\u001b[0m tensors \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_export_to_saved_model_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobject_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\n\u001b[0;32m    423\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, asset\u001b[38;5;241m.\u001b[39mAsset):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:770\u001b[0m, in \u001b[0;36mBaseResourceVariable._export_to_saved_model_graph\u001b[1;34m(self, object_map, tensor_map, options, **kwargs)\u001b[0m\n\u001b[0;32m    769\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 770\u001b[0m   new_variable \u001b[38;5;241m=\u001b[39m \u001b[43mcopy_to_graph_uninitialized\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    771\u001b[0m object_map[\u001b[38;5;28mself\u001b[39m] \u001b[38;5;241m=\u001b[39m new_variable\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:2558\u001b[0m, in \u001b[0;36mcopy_to_graph_uninitialized\u001b[1;34m(var)\u001b[0m\n\u001b[0;32m   2555\u001b[0m \u001b[38;5;66;03m# Like ResourceVariable.__deepcopy__, but does not set an initializer on the\u001b[39;00m\n\u001b[0;32m   2556\u001b[0m \u001b[38;5;66;03m# new variable.\u001b[39;00m\n\u001b[0;32m   2557\u001b[0m \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 2558\u001b[0m new_variable \u001b[38;5;241m=\u001b[39m \u001b[43mUninitializedVariable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2559\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2560\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_constraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2561\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2562\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_shared_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2564\u001b[0m \u001b[43m    \u001b[49m\u001b[43msynchronization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynchronization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2565\u001b[0m \u001b[43m    \u001b[49m\u001b[43maggregation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_handle_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2567\u001b[0m new_variable\u001b[38;5;241m.\u001b[39m_maybe_initialize_trackable()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: '/model.10/attn/pe/conv/Conv/kernel' is not a valid root scope name. A root scope name has to match the following pattern: ^[A-Za-z0-9.][A-Za-z0-9_.\\\\/>-]*$",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSystemExit\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn[77], line 7\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Export the model to TFLite format\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtflite\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# creates 'yolov8n_float32.tflite'\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Load the exported TFLite model\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py:590\u001b[0m, in \u001b[0;36mModel.export\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    589\u001b[0m args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcustom, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexport\u001b[39m\u001b[38;5;124m\"\u001b[39m}  \u001b[38;5;66;03m# highest priority args on the right\u001b[39;00m\n\u001b[1;32m--> 590\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mExporter\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_callbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\exporter.py:297\u001b[0m, in \u001b[0;36mExporter.__call__\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mint8 \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m edgetpu\n\u001b[1;32m--> 297\u001b[0m f[\u001b[38;5;241m5\u001b[39m], keras_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport_saved_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pb \u001b[38;5;129;01mor\u001b[39;00m tfjs:  \u001b[38;5;66;03m# pb prerequisite to tfjs\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\exporter.py:133\u001b[0m, in \u001b[0;36mtry_export.<locals>.outer_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Profile() \u001b[38;5;28;01mas\u001b[39;00m dt:\n\u001b[1;32m--> 133\u001b[0m     f, model \u001b[38;5;241m=\u001b[39m \u001b[43minner_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m export success ✅ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdt\u001b[38;5;241m.\u001b[39mt\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms, saved as \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_size(f)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m MB)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\exporter.py:803\u001b[0m, in \u001b[0;36mExporter.export_saved_model\u001b[1;34m(self, prefix)\u001b[0m\n\u001b[0;32m    802\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m starting TFLite export with onnx2tf \u001b[39m\u001b[38;5;132;01m{\u001b[39;00monnx2tf\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 803\u001b[0m \u001b[43monnx2tf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_onnx_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mf_onnx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_folder_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    806\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnot_use_onnxsim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    807\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    808\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_integer_quantized_tflite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint8\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    809\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquant_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mper-tensor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# \"per-tensor\" (faster) or \"per-channel\" (slower but more accurate)\u001b[39;49;00m\n\u001b[0;32m    810\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_input_op_name_np_data_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    811\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    812\u001b[0m yaml_save(f \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata)  \u001b[38;5;66;03m# add metadata.yaml\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\onnx2tf\\onnx2tf.py:1345\u001b[0m, in \u001b[0;36mconvert\u001b[1;34m(input_onnx_file_path, onnx_graph, output_folder_path, output_signaturedefs, output_h5, output_keras_v3, output_tfv1_pb, output_weights, copy_onnx_input_output_names_to_tflite, output_dynamic_range_quantized_tflite, output_integer_quantized_tflite, quant_type, custom_input_op_name_np_data_path, input_output_quant_dtype, not_use_onnxsim, not_use_opname_auto_generate, batch_size, overwrite_input_shape, no_large_tensor, output_nms_with_dynamic_tensor, keep_ncw_or_nchw_or_ncdhw_input_names, keep_nwc_or_nhwc_or_ndhwc_input_names, keep_shape_absolutely_input_names, input_names_to_interrupt_model_conversion, output_names_to_interrupt_model_conversion, disable_group_convolution, enable_accumulation_type_float16, enable_batchmatmul_unfold, enable_rnn_unroll, disable_suppression_flextranspose, disable_strict_mode, number_of_dimensions_after_flextranspose_compression, disable_suppression_flexstridedslice, number_of_dimensions_after_flexstridedslice_compression, optimization_for_gpu_delegate, replace_argmax_to_reducemax_and_indices_is_int64, replace_argmax_to_reducemax_and_indices_is_float32, replace_argmax_to_fused_argmax_and_indices_is_int64, replace_argmax_to_fused_argmax_and_indices_is_float32, fused_argmax_scale_ratio, replace_to_pseudo_operators, param_replacement_file, check_gpu_delegate_compatibility, check_onnx_tf_outputs_elementwise_close, check_onnx_tf_outputs_elementwise_close_full, check_onnx_tf_outputs_sample_data_normalization, check_onnx_tf_outputs_elementwise_close_rtol, check_onnx_tf_outputs_elementwise_close_atol, mvn_epsilon, disable_model_save, non_verbose, verbosity)\u001b[0m\n\u001b[0;32m   1342\u001b[0m             error(\n\u001b[0;32m   1343\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease convert again with the `-osd` or `--output_signaturedefs` option.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1344\u001b[0m             )\n\u001b[1;32m-> 1345\u001b[0m             \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mSystemExit\u001b[0m: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                        Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2145\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_only:\n\u001b[0;32m   2143\u001b[0m     stb \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn exception has occurred, use \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mtb to see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2144\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe full traceback.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m-> 2145\u001b[0m     stb\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInteractiveTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_exception_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2146\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   2147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2149\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcontains_exceptiongroup\u001b[39m(val):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\ultratb.py:710\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[1;34m(self, etype, value)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_exception_only\u001b[39m(\u001b[38;5;28mself\u001b[39m, etype, value):\n\u001b[0;32m    703\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \n\u001b[0;32m    705\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;124;03m    value : exception value\u001b[39;00m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 710\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mListTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\ultratb.py:568\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[0;32m    565\u001b[0m     chained_exc_ids\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(exception[\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m    566\u001b[0m     chained_exceptions_tb_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    567\u001b[0m     out_list \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 568\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m            \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchained_exc_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[0;32m    572\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchained_exceptions_tb_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m         \u001b[38;5;241m+\u001b[39m chained_exception_message\n\u001b[0;32m    576\u001b[0m         \u001b[38;5;241m+\u001b[39m out_list)\n\u001b[0;32m    578\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_list\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\ultratb.py:1454\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1452\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1453\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtb \u001b[38;5;241m=\u001b[39m etb\n\u001b[1;32m-> 1454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1455\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[0;32m   1456\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\ultratb.py:1345\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1342\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[0;32m   1343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose_modes:\n\u001b[0;32m   1344\u001b[0m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[1;32m-> 1345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1346\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[0;32m   1347\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1348\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinimal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m   1349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ListTB\u001b[38;5;241m.\u001b[39mget_exception_only(\u001b[38;5;28mself\u001b[39m, etype, value)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\ultratb.py:1192\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstructured_traceback\u001b[39m(\n\u001b[0;32m   1184\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1185\u001b[0m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1189\u001b[0m     number_of_lines_of_context: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m   1190\u001b[0m ):\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1192\u001b[0m     formatted_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1193\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1195\u001b[0m     colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mColors  \u001b[38;5;66;03m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m     colorsnormal \u001b[38;5;241m=\u001b[39m colors\u001b[38;5;241m.\u001b[39mNormal  \u001b[38;5;66;03m# used a lot\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\ultratb.py:1082\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1079\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tb_offset, \u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m   1080\u001b[0m head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_header(\u001b[38;5;28mstr\u001b[39m(etype), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlong_header)\n\u001b[0;32m   1081\u001b[0m records \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 1082\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m etb \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[0;32m   1083\u001b[0m )\n\u001b[0;32m   1085\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1086\u001b[0m skipped \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\ultratb.py:1150\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[1;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1148\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1149\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1150\u001b[0m         mod \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetmodule(\u001b[43mcf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtb_frame\u001b[49m)\n\u001b[0;32m   1151\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1152\u001b[0m             mod_name \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'tb_frame'"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO(\"best.pt\")\n",
    "\n",
    "# Export the model to TFLite format\n",
    "model.export(format=\"tflite\")  # creates 'yolov8n_float32.tflite'\n",
    "\n",
    "# Load the exported TFLite model\n",
    "tflite_model = YOLO(\"yolov8n_float32.tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9965b438-f460-4a57-938e-1bcc2ac9da78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 300, 6) (5.5 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnx2tf>=1.15.4,<=1.17.5', 'tflite_support'] not found, attempting AutoUpdate...\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com, https://pypi.ngc.nvidia.com\n",
      "\n",
      "Collecting onnx2tf<=1.17.5,>=1.15.4\n",
      "\n",
      "  Downloading onnx2tf-1.17.5-py3-none-any.whl.metadata (127 kB)\n",
      "\n",
      "Collecting tflite_support\n",
      "\n",
      "  Downloading tflite-support-0.1.0a1.tar.gz (390 kB)\n",
      "\n",
      "  Preparing metadata (setup.py): started\n",
      "\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "\n",
      "Requirement already satisfied: pybind11>=2.4 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tflite_support) (2.13.5)\n",
      "\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tflite_support) (2.1.0)\n",
      "\n",
      "Requirement already satisfied: numpy in c:\\users\\sshiv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tflite_support) (1.26.3)\n",
      "\n",
      "Downloading onnx2tf-1.17.5-py3-none-any.whl (400 kB)\n",
      "\n",
      "Building wheels for collected packages: tflite_support\n",
      "\n",
      "  Building wheel for tflite_support (setup.py): started\n",
      "\n",
      "  Building wheel for tflite_support (setup.py): finished with status 'done'\n",
      "\n",
      "  Created wheel for tflite_support: filename=tflite_support-0.1.0a1-cp312-cp312-win_amd64.whl size=358241 sha256=38b7a2b07f008efba58e8b8d70bd22c59f5bc8693b64b7c8e9c093d97165f1e2\n",
      "\n",
      "  Stored in directory: C:\\Users\\sshiv\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-elb37q8i\\wheels\\5d\\6f\\bc\\8b85ad0e51d3c8f82c590b321f2c5b35c41fbe84ad93271397\n",
      "\n",
      "Successfully built tflite_support\n",
      "\n",
      "Installing collected packages: tflite_support, onnx2tf\n",
      "\n",
      "  Attempting uninstall: onnx2tf\n",
      "\n",
      "    Found existing installation: onnx2tf 1.25.7\n",
      "\n",
      "    Uninstalling onnx2tf-1.25.7:\n",
      "\n",
      "      Successfully uninstalled onnx2tf-1.25.7\n",
      "\n",
      "Successfully installed onnx2tf-1.17.5 tflite_support-0.1.0a1\n",
      "\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 41.3s, installed 2 packages: ['onnx2tf>=1.15.4,<=1.17.5', 'tflite_support']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m âš ï¸� \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.17.0...\n",
      "WARNING âš ï¸� tensorflow<=2.13.1 is required, but tensorflow==2.17.0 is currently installed https://github.com/ultralytics/ultralytics/issues/5161\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.1 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m simplifying with onnxslim 0.1.31...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 2.3s, saved as 'C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.onnx' (9.0 MB)\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.17.5...\n",
      "\u001b[31mERROR:\u001b[0m The trace log is below.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\onnx2tf\\utils\\common_functions.py\", line 288, in print_wrapper_func\n",
      "    result = func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\onnx2tf\\utils\\common_functions.py\", line 361, in inverted_operation_enable_disable_wrapper_func\n",
      "    result = func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\onnx2tf\\ops\\Conv.py\", line 246, in make_node\n",
      "    input_tensor = get_padding_as_op(\n",
      "                   ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\onnx2tf\\utils\\common_functions.py\", line 2009, in get_padding_as_op\n",
      "    return tf.pad(x, padding)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\common\\keras_tensor.py\", line 138, in __tf_tensor__\n",
      "    raise ValueError(\n",
      "ValueError: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n",
      "\n",
      "```\n",
      "x = Input(...)\n",
      "...\n",
      "tf_fn(x)  # Invalid.\n",
      "```\n",
      "\n",
      "What you should do instead is wrap `tf_fn` in a layer:\n",
      "\n",
      "```\n",
      "class MyLayer(Layer):\n",
      "    def call(self, x):\n",
      "        return tf_fn(x)\n",
      "\n",
      "x = MyLayer()(x)\n",
      "```\n",
      "\n",
      "\n",
      "\u001b[31mERROR:\u001b[0m input_onnx_file_path: C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.onnx\n",
      "\u001b[31mERROR:\u001b[0m onnx_op_name: /model.0/conv/Conv\n",
      "\u001b[31mERROR:\u001b[0m Read this and deal with it. https://github.com/PINTO0309/onnx2tf#parameter-replacement\n",
      "\u001b[31mERROR:\u001b[0m Alternatively, if the input OP has a dynamic dimension, use the -b or -ois option to rewrite it to a static shape and try again.\n",
      "\u001b[31mERROR:\u001b[0m If the input OP of ONNX before conversion is NHWC or an irregular channel arrangement other than NCHW, use the -kt or -kat option.\n",
      "\u001b[31mERROR:\u001b[0m Also, for models that include NonMaxSuppression in the post-processing, try the -onwdt option.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "simple-onnx-processing-tools 1.1.32 requires onnx2tf>=1.20.1, but you have onnx2tf 1.17.5 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!yolo export model=C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.onnx format=tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2791cc1-d15b-4ae1-a491-ad81ab517ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is 20FD-A684\n",
      "\n",
      " Directory of C:\\Users\\sshiv\\Desktop\\sihProject\n",
      "\n",
      "27-08-2024  14:28    <DIR>          .\n",
      "25-08-2024  00:29    <DIR>          ..\n",
      "24-08-2024  08:42    <DIR>          .ipynb_checkpoints\n",
      "26-08-2024  00:53         3,932,288 calibration_image_sample_data_20x128x128x3_float32.npy\n",
      "25-08-2024  00:23    <DIR>          custom_dataset\n",
      "25-08-2024  13:32               308 data.yaml\n",
      "25-08-2024  16:16    <DIR>          test_images\n",
      "27-08-2024  14:28           770,308 Untitled.ipynb\n",
      "24-08-2024  20:04    <DIR>          yolov10\n",
      "               3 File(s)      4,702,904 bytes\n",
      "               6 Dir(s)  100,416,376,832 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d65ef943-79a9-40d2-9bd1-9eb01428b80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'best.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load the YOLOv8 model\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mYOLO\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbest.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Export the model to TFLite format\u001b[39;00m\n\u001b[0;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mexport(\u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtflite\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# creates 'yolov8n_float32.tflite'\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\models\\yolo\\model.py:28\u001b[0m, in \u001b[0;36mYOLO.__init__\u001b[1;34m(self, model, task, verbose)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m \u001b[38;5;241m=\u001b[39m new_instance\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# Continue with default YOLO initialization\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py:141\u001b[0m, in \u001b[0;36mModel.__init__\u001b[1;34m(self, model, task, verbose)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(model, task\u001b[38;5;241m=\u001b[39mtask, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 141\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py:230\u001b[0m, in \u001b[0;36mModel._load\u001b[1;34m(self, weights, task)\u001b[0m\n\u001b[0;32m    227\u001b[0m weights \u001b[38;5;241m=\u001b[39m checks\u001b[38;5;241m.\u001b[39mcheck_model_file_from_stem(weights)  \u001b[38;5;66;03m# add suffix, i.e. yolov8n -> yolov8n.pt\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Path(weights)\u001b[38;5;241m.\u001b[39msuffix \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 230\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;241m=\u001b[39m \u001b[43mattempt_load_one_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset_ckpt_args(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:807\u001b[0m, in \u001b[0;36mattempt_load_one_weight\u001b[1;34m(weight, device, inplace, fuse)\u001b[0m\n\u001b[0;32m    805\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mattempt_load_one_weight\u001b[39m(weight, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fuse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    806\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a single model weights.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 807\u001b[0m     ckpt, weight \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_safe_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# load ckpt\u001b[39;00m\n\u001b[0;32m    808\u001b[0m     args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mDEFAULT_CFG_DICT, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_args\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))}  \u001b[38;5;66;03m# combine model and default args, preferring model args\u001b[39;00m\n\u001b[0;32m    809\u001b[0m     model \u001b[38;5;241m=\u001b[39m (ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mema\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m ckpt[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# FP32 model\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733\u001b[0m, in \u001b[0;36mtorch_safe_load\u001b[1;34m(weight)\u001b[0m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    726\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m temporary_modules(\n\u001b[0;32m    727\u001b[0m         {\n\u001b[0;32m    728\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124multralytics.yolo.utils\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124multralytics.utils\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    731\u001b[0m         }\n\u001b[0;32m    732\u001b[0m     ):  \u001b[38;5;66;03m# for legacy 8.0 Classify and Pose models\u001b[39;00m\n\u001b[1;32m--> 733\u001b[0m         ckpt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# e.name is missing module name\u001b[39;00m\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:1065\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1063\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m-> 1065\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m   1066\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1067\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1068\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1069\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1070\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:468\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 468\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    470\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:449\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'best.pt'"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO(\"best.pt\")\n",
    "\n",
    "# Export the model to TFLite format\n",
    "model.export(format=\"tflite\")  # creates 'yolov8n_float32.tflite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12420067-7b9b-428d-917e-1f5db506e2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\runs\\detect\\train10\\weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\sshiv\\runs\\detect\\train10\\weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "434c97d7-e856-42b4-b77b-046fc811f3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is 20FD-A684\n",
      "\n",
      " Directory of C:\\Users\\sshiv\\runs\\detect\\train10\\weights\n",
      "\n",
      "27-08-2024  14:25    <DIR>          .\n",
      "25-08-2024  14:53    <DIR>          ..\n",
      "27-08-2024  14:25         9,428,266 best.onnx\n",
      "25-08-2024  14:53         5,736,676 best.pt\n",
      "27-08-2024  14:25    <DIR>          best_saved_model\n",
      "26-08-2024  02:19         3,932,288 calibration_image_sample_data_20x128x128x3_float32.npy\n",
      "25-08-2024  14:53         5,736,868 last.pt\n",
      "               4 File(s)     24,834,098 bytes\n",
      "               3 Dir(s)  100,403,355,648 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1170415-cbf5-45b0-b4bf-c0630221be4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b5da850-12c9-4b23-951c-d06a159fab66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 🚀 Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 300, 6) (5.5 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.17.0...\n",
      "WARNING ⚠️ tensorflow<=2.13.1 is required, but tensorflow==2.17.0 is currently installed https://github.com/ultralytics/ultralytics/issues/5161\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/calibration_image_sample_data_20x128x128x3_float32.npy.zip to 'calibration_image_sample_data_20x128x128x3_float32.npy.zip'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 1.11M/1.11M [00:00<00:00, 2.80MB/s]\n",
      "Unzipping calibration_image_sample_data_20x128x128x3_float32.npy.zip t"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.1 opset 19...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mONNX:\u001b[0m simplifying with onnxslim 0.1.31...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 2.5s, saved as 'best.onnx' (9.0 MB)\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.17.5...\n",
      "\u001b[31mERROR:\u001b[0m The trace log is below.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\onnx2tf\\utils\\common_functions.py\", line 288, in print_wrapper_func\n",
      "    result = func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\onnx2tf\\utils\\common_functions.py\", line 361, in inverted_operation_enable_disable_wrapper_func\n",
      "    result = func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\onnx2tf\\ops\\Conv.py\", line 246, in make_node\n",
      "    input_tensor = get_padding_as_op(\n",
      "                   ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\onnx2tf\\utils\\common_functions.py\", line 2009, in get_padding_as_op\n",
      "    return tf.pad(x, padding)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\common\\keras_tensor.py\", line 138, in __tf_tensor__\n",
      "    raise ValueError(\n",
      "ValueError: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n",
      "\n",
      "```\n",
      "x = Input(...)\n",
      "...\n",
      "tf_fn(x)  # Invalid.\n",
      "```\n",
      "\n",
      "What you should do instead is wrap `tf_fn` in a layer:\n",
      "\n",
      "```\n",
      "class MyLayer(Layer):\n",
      "    def call(self, x):\n",
      "        return tf_fn(x)\n",
      "\n",
      "x = MyLayer()(x)\n",
      "```\n",
      "\n",
      "\n",
      "\u001b[31mERROR:\u001b[0m input_onnx_file_path: best.onnx\n",
      "\u001b[31mERROR:\u001b[0m onnx_op_name: /model.0/conv/Conv\n",
      "\u001b[31mERROR:\u001b[0m Read this and deal with it. https://github.com/PINTO0309/onnx2tf#parameter-replacement\n",
      "\u001b[31mERROR:\u001b[0m Alternatively, if the input OP has a dynamic dimension, use the -b or -ois option to rewrite it to a static shape and try again.\n",
      "\u001b[31mERROR:\u001b[0m If the input OP of ONNX before conversion is NHWC or an irregular channel arrangement other than NCHW, use the -kt or -kat option.\n",
      "\u001b[31mERROR:\u001b[0m Also, for models that include NonMaxSuppression in the post-processing, try the -onwdt option.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'tb_frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\onnx2tf\\utils\\common_functions.py:288\u001b[0m, in \u001b[0;36mprint_node_info.<locals>.print_wrapper_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 288\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m get_log_level() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m LOG_LEVELS[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdebug\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\onnx2tf\\utils\\common_functions.py:361\u001b[0m, in \u001b[0;36minverted_operation_enable_disable.<locals>.inverted_operation_enable_disable_wrapper_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minverted_operation_enable_disable_wrapper_func\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 361\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;124;03m    The output_shape_trans stores the result of determining\u001b[39;00m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;124;03m    whether the final output shape of the connected OP differs between ONNX and TensorFlow.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;124;03m    False: No transposition\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\onnx2tf\\ops\\Conv.py:246\u001b[0m, in \u001b[0;36mmake_node\u001b[1;34m(graph_node, tf_layers_dict, **kwargs)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pads \u001b[38;5;241m!=\u001b[39m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m spatial_size:\n\u001b[1;32m--> 246\u001b[0m     input_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mget_padding_as_op\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    250\u001b[0m     pad_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVALID\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\onnx2tf\\utils\\common_functions.py:2009\u001b[0m, in \u001b[0;36mget_padding_as_op\u001b[1;34m(x, pads)\u001b[0m\n\u001b[0;32m   2006\u001b[0m padding \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconstant(\n\u001b[0;32m   2007\u001b[0m     np\u001b[38;5;241m.\u001b[39marray(tf_pads)\u001b[38;5;241m.\u001b[39mreshape([num_dim \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m])\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint32)\n\u001b[0;32m   2008\u001b[0m )  \u001b[38;5;66;03m# tf requires int32 paddings\u001b[39;00m\n\u001b[1;32m-> 2009\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\common\\keras_tensor.py:138\u001b[0m, in \u001b[0;36mKerasTensor.__tf_tensor__\u001b[1;34m(self, dtype, name)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__tf_tensor__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    139\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA KerasTensor cannot be used as input to a TensorFlow function. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    140\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA KerasTensor is a symbolic placeholder for a shape and dtype, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    141\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mused when constructing Keras Functional models \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor Keras Functions. You can only use it as input to a Keras layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor a Keras operation (from the namespaces `keras.layers` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    144\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand `keras.operations`). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are likely doing something like:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    146\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    147\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = Input(...)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_fn(x)  # Invalid.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    150\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    151\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat you should do instead is wrap `tf_fn` in a layer:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    152\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    153\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass MyLayer(Layer):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    154\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def call(self, x):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    155\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return tf_fn(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = MyLayer()(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    158\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSystemExit\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Export the model to TFLite format\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtflite\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# creates 'yolov8n_float32.tflite'\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py:590\u001b[0m, in \u001b[0;36mModel.export\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    589\u001b[0m args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcustom, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexport\u001b[39m\u001b[38;5;124m\"\u001b[39m}  \u001b[38;5;66;03m# highest priority args on the right\u001b[39;00m\n\u001b[1;32m--> 590\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mExporter\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_callbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\exporter.py:297\u001b[0m, in \u001b[0;36mExporter.__call__\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mint8 \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m edgetpu\n\u001b[1;32m--> 297\u001b[0m f[\u001b[38;5;241m5\u001b[39m], keras_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport_saved_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pb \u001b[38;5;129;01mor\u001b[39;00m tfjs:  \u001b[38;5;66;03m# pb prerequisite to tfjs\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\exporter.py:133\u001b[0m, in \u001b[0;36mtry_export.<locals>.outer_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Profile() \u001b[38;5;28;01mas\u001b[39;00m dt:\n\u001b[1;32m--> 133\u001b[0m     f, model \u001b[38;5;241m=\u001b[39m \u001b[43minner_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m export success ✅ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdt\u001b[38;5;241m.\u001b[39mt\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms, saved as \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_size(f)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m MB)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\exporter.py:803\u001b[0m, in \u001b[0;36mExporter.export_saved_model\u001b[1;34m(self, prefix)\u001b[0m\n\u001b[0;32m    802\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m starting TFLite export with onnx2tf \u001b[39m\u001b[38;5;132;01m{\u001b[39;00monnx2tf\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 803\u001b[0m \u001b[43monnx2tf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_onnx_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mf_onnx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_folder_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    806\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnot_use_onnxsim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    807\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    808\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_integer_quantized_tflite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint8\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    809\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquant_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mper-tensor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# \"per-tensor\" (faster) or \"per-channel\" (slower but more accurate)\u001b[39;49;00m\n\u001b[0;32m    810\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_input_op_name_np_data_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    811\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    812\u001b[0m yaml_save(f \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata)  \u001b[38;5;66;03m# add metadata.yaml\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\onnx2tf\\onnx2tf.py:998\u001b[0m, in \u001b[0;36mconvert\u001b[1;34m(input_onnx_file_path, onnx_graph, output_folder_path, output_signaturedefs, output_h5, output_keras_v3, output_tfv1_pb, output_weights, copy_onnx_input_output_names_to_tflite, output_integer_quantized_tflite, quant_type, custom_input_op_name_np_data_path, input_output_quant_dtype, not_use_onnxsim, not_use_opname_auto_generate, batch_size, overwrite_input_shape, no_large_tensor, output_nms_with_dynamic_tensor, keep_ncw_or_nchw_or_ncdhw_input_names, keep_nwc_or_nhwc_or_ndhwc_input_names, keep_shape_absolutely_input_names, output_names_to_interrupt_model_conversion, disable_group_convolution, enable_batchmatmul_unfold, enable_rnn_unroll, disable_suppression_flextranspose, disable_strict_mode, number_of_dimensions_after_flextranspose_compression, disable_suppression_flexstridedslice, number_of_dimensions_after_flexstridedslice_compression, optimization_for_gpu_delegate, replace_argmax_to_reducemax_and_indicies_is_int64, replace_argmax_to_reducemax_and_indicies_is_float32, replace_argmax_to_fused_argmax_and_indicies_is_int64, replace_argmax_to_fused_argmax_and_indicies_is_float32, fused_argmax_scale_ratio, replace_to_pseudo_operators, param_replacement_file, check_gpu_delegate_compatibility, check_onnx_tf_outputs_elementwise_close, check_onnx_tf_outputs_elementwise_close_full, check_onnx_tf_outputs_sample_data_normalization, check_onnx_tf_outputs_elementwise_close_rtol, check_onnx_tf_outputs_elementwise_close_atol, mvn_epsilon, disable_model_save, non_verbose, verbosity)\u001b[0m\n\u001b[0;32m    996\u001b[0m sanitizing(graph_node)\n\u001b[1;32m--> 998\u001b[0m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_node\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    999\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgraph_node\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_node\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1000\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtf_layers_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf_layers_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1001\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1002\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1003\u001b[0m op_counta \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\onnx2tf\\utils\\common_functions.py:354\u001b[0m, in \u001b[0;36mprint_node_info.<locals>.print_wrapper_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m error(\n\u001b[0;32m    351\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAlso, for models that include NonMaxSuppression in the post-processing, \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtry the -onwdt option.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    353\u001b[0m )\n\u001b[1;32m--> 354\u001b[0m \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mSystemExit\u001b[0m: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                        Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2145\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_only:\n\u001b[0;32m   2143\u001b[0m     stb \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn exception has occurred, use \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mtb to see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2144\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe full traceback.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m-> 2145\u001b[0m     stb\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInteractiveTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_exception_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2146\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   2147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2149\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcontains_exceptiongroup\u001b[39m(val):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\ultratb.py:710\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[1;34m(self, etype, value)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_exception_only\u001b[39m(\u001b[38;5;28mself\u001b[39m, etype, value):\n\u001b[0;32m    703\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \n\u001b[0;32m    705\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;124;03m    value : exception value\u001b[39;00m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 710\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mListTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\ultratb.py:568\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[0;32m    565\u001b[0m     chained_exc_ids\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(exception[\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m    566\u001b[0m     chained_exceptions_tb_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    567\u001b[0m     out_list \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 568\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m            \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchained_exc_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[0;32m    572\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchained_exceptions_tb_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m         \u001b[38;5;241m+\u001b[39m chained_exception_message\n\u001b[0;32m    576\u001b[0m         \u001b[38;5;241m+\u001b[39m out_list)\n\u001b[0;32m    578\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_list\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\ultratb.py:1454\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1452\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1453\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtb \u001b[38;5;241m=\u001b[39m etb\n\u001b[1;32m-> 1454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1455\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[0;32m   1456\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\ultratb.py:1345\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1342\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[0;32m   1343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose_modes:\n\u001b[0;32m   1344\u001b[0m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[1;32m-> 1345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1346\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[0;32m   1347\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1348\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinimal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m   1349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ListTB\u001b[38;5;241m.\u001b[39mget_exception_only(\u001b[38;5;28mself\u001b[39m, etype, value)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\ultratb.py:1192\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstructured_traceback\u001b[39m(\n\u001b[0;32m   1184\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1185\u001b[0m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1189\u001b[0m     number_of_lines_of_context: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m   1190\u001b[0m ):\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1192\u001b[0m     formatted_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1193\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1195\u001b[0m     colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mColors  \u001b[38;5;66;03m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m     colorsnormal \u001b[38;5;241m=\u001b[39m colors\u001b[38;5;241m.\u001b[39mNormal  \u001b[38;5;66;03m# used a lot\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\ultratb.py:1082\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1079\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tb_offset, \u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m   1080\u001b[0m head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_header(\u001b[38;5;28mstr\u001b[39m(etype), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlong_header)\n\u001b[0;32m   1081\u001b[0m records \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 1082\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m etb \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[0;32m   1083\u001b[0m )\n\u001b[0;32m   1085\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1086\u001b[0m skipped \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\ultratb.py:1150\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[1;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1148\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1149\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1150\u001b[0m         mod \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetmodule(\u001b[43mcf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtb_frame\u001b[49m)\n\u001b[0;32m   1151\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1152\u001b[0m             mod_name \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'tb_frame'"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO(\"best.pt\")\n",
    "\n",
    "# Export the model to TFLite format\n",
    "model.export(format=\"tflite\")  # creates 'yolov8n_float32.tflite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a0f7d1f-c8b6-463b-9354-90faf696be84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\Desktop\\sihProject\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\sshiv\\Desktop\\sihProject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77671be8-4b20-40ac-bfbd-92692d7d3c5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\yolo.exe\\__main__.py\", line 4, in <module>\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\__init__.py\", line 5, in <module>\n",
      "    from ultralytics.data.explorer.explorer import Explorer\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\data\\__init__.py\", line 3, in <module>\n",
      "    from .base import BaseDataset\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\data\\base.py\", line 17, in <module>\n",
      "    from ultralytics.utils import DEFAULT_CFG, LOCAL_RANK, LOGGER, NUM_THREADS, TQDM\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\utils\\__init__.py\", line 20, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "ModuleNotFoundError: No module named 'matplotlib'\n"
     ]
    }
   ],
   "source": [
    "!yolo export model=C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt format=tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37c44f6a-332e-4516-aa18-777990061b29",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (2852578047.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[13], line 4\u001b[1;36m\u001b[0m\n\u001b[1;33m    model = YOLO(\"C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt\")\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO(\"C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt\")\n",
    "\n",
    "# Export the model to TFLite format\n",
    "model.export(format=\"tflite\")  # creates 'yolov8n_float32.tflite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4fe736f-41d2-4697-ab17-0a34f4ff360b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (2512969907.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[14], line 5\u001b[1;36m\u001b[0m\n\u001b[1;33m    onnx_model = onnx.load(\"C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt\")  # load onnx model\u001b[0m\n\u001b[1;37m                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "from onnx_tf.backend import prepare\n",
    "\n",
    "onnx_model = onnx.load(\"C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt\")  # load onnx model\n",
    "tf_rep = prepare(onnx_model)  # prepare tf representation\n",
    "tf_rep.export_graph(\"C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best_saved_model\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33f544c8-ed1d-4eb5-85a9-6baee782b617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\runs\\detect\\train10\\weights\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\sshiv\\runs\\detect\\train10\\weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3c2e75f-e2b3-4679-bcfb-2f7fb8e3056a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_addons'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01monnx\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx_tf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m prepare\n\u001b[0;32m      5\u001b[0m onnx_model \u001b[38;5;241m=\u001b[39m onnx\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest.onnx\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# load onnx model\u001b[39;00m\n\u001b[0;32m      6\u001b[0m tf_rep \u001b[38;5;241m=\u001b[39m prepare(onnx_model)  \u001b[38;5;66;03m# prepare tf representation\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\onnx_tf\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\onnx_tf\\backend.py:29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx_tf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_unique_suffix\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx_tf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m supports_device \u001b[38;5;28;01mas\u001b[39;00m common_supports_device\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx_tf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhandler_helper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_all_backend_handlers\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx_tf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpb_wrapper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OnnxNode\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01monnx_tf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcommon\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\onnx_tf\\common\\handler_helper.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m defs\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx_tf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhandlers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx_tf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhandlers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_handler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BackendHandler\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01monnx_tf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcommon\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\onnx_tf\\handlers\\backend\\hardmax.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfa\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx_tf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhandlers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_handler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BackendHandler\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx_tf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhandlers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhandler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m onnx_op\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_addons'"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "from onnx_tf.backend import prepare\n",
    "\n",
    "onnx_model = onnx.load(\"best.onnx\")  # load onnx model\n",
    "tf_rep = prepare(onnx_model)  # prepare tf representation\n",
    "tf_rep.export_graph(\"best_saved_model\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb5f6694-8165-4352-aeb0-8742070519d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 300, 6) (5.5 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.17.0...\n",
      "WARNING âš ï¸� tensorflow<=2.13.1 is required, but tensorflow==2.17.0 is currently installed https://github.com/ultralytics/ultralytics/issues/5161\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.1 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m simplifying with onnxslim 0.1.31...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 3.9s, saved as 'C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.onnx' (9.0 MB)\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.17.5...\n",
      "\u001b[31mERROR:\u001b[0m The trace log is below.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\onnx2tf\\utils\\common_functions.py\", line 288, in print_wrapper_func\n",
      "    result = func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\onnx2tf\\utils\\common_functions.py\", line 361, in inverted_operation_enable_disable_wrapper_func\n",
      "    result = func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\onnx2tf\\ops\\Conv.py\", line 246, in make_node\n",
      "    input_tensor = get_padding_as_op(\n",
      "                   ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\onnx2tf\\utils\\common_functions.py\", line 2009, in get_padding_as_op\n",
      "    return tf.pad(x, padding)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\common\\keras_tensor.py\", line 138, in __tf_tensor__\n",
      "    raise ValueError(\n",
      "ValueError: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n",
      "\n",
      "```\n",
      "x = Input(...)\n",
      "...\n",
      "tf_fn(x)  # Invalid.\n",
      "```\n",
      "\n",
      "What you should do instead is wrap `tf_fn` in a layer:\n",
      "\n",
      "```\n",
      "class MyLayer(Layer):\n",
      "    def call(self, x):\n",
      "        return tf_fn(x)\n",
      "\n",
      "x = MyLayer()(x)\n",
      "```\n",
      "\n",
      "\n",
      "\u001b[31mERROR:\u001b[0m input_onnx_file_path: C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.onnx\n",
      "\u001b[31mERROR:\u001b[0m onnx_op_name: /model.0/conv/Conv\n",
      "\u001b[31mERROR:\u001b[0m Read this and deal with it. https://github.com/PINTO0309/onnx2tf#parameter-replacement\n",
      "\u001b[31mERROR:\u001b[0m Alternatively, if the input OP has a dynamic dimension, use the -b or -ois option to rewrite it to a static shape and try again.\n",
      "\u001b[31mERROR:\u001b[0m If the input OP of ONNX before conversion is NHWC or an irregular channel arrangement other than NCHW, use the -kt or -kat option.\n",
      "\u001b[31mERROR:\u001b[0m Also, for models that include NonMaxSuppression in the post-processing, try the -onwdt option.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "!yolo export model=C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt format=tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8686176-a146-461e-9b46-f0b8b39108df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "image 1/1 C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\12.jpg: 480x640 2 Shivanshus, 205.0ms\n",
      "Speed: 11.6ms preprocess, 205.0ms inference, 8.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\predict2\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.02 save=True model=C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt source=test_images/12.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4ade509-3640-4621-886b-2caa2ac31ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is 20FD-A684\n",
      "\n",
      " Directory of C:\\Users\\sshiv\\Desktop\\sihProject\n",
      "\n",
      "27-08-2024  20:41    <DIR>          .\n",
      "25-08-2024  00:29    <DIR>          ..\n",
      "24-08-2024  08:42    <DIR>          .ipynb_checkpoints\n",
      "26-08-2024  00:53         3,932,288 calibration_image_sample_data_20x128x128x3_float32.npy\n",
      "25-08-2024  00:23    <DIR>          custom_dataset\n",
      "25-08-2024  13:32               308 data.yaml\n",
      "25-08-2024  16:16    <DIR>          test_images\n",
      "27-08-2024  20:41           819,052 Untitled.ipynb\n",
      "24-08-2024  20:04    <DIR>          yolov10\n",
      "               3 File(s)      4,751,648 bytes\n",
      "               6 Dir(s)  98,268,270,592 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "263ecf41-45b5-43e9-8fd9-8f8bac1b746f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\runs\\detect\\train10\\weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\sshiv\\runs\\detect\\train10\\weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efcbdb86-a30d-4913-b5a6-d9b76cf2a9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is 20FD-A684\n",
      "\n",
      " Directory of C:\\Users\\sshiv\\runs\\detect\\train10\\weights\n",
      "\n",
      "27-08-2024  20:17    <DIR>          .\n",
      "25-08-2024  14:53    <DIR>          ..\n",
      "27-08-2024  20:17         9,428,266 best.onnx\n",
      "25-08-2024  14:53         5,736,676 best.pt\n",
      "27-08-2024  20:17    <DIR>          best_saved_model\n",
      "25-08-2024  14:53         5,736,868 last.pt\n",
      "               3 File(s)     20,901,810 bytes\n",
      "               3 Dir(s)  98,273,239,040 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d21abfb-3bc3-49ee-b324-6d031913dde8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m()\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(pt_model_path, map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39meval()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Model' is not defined"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "model.load_state_dict(torch.load(pt_model_path, map_location='cpu')).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "862071cc-b827-447a-ba1e-3336236d18c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'best.onnx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01monnx\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load the ONNX model\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbest.onnx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Check that the IR is well formed\u001b[39;00m\n\u001b[0;32m      7\u001b[0m onnx\u001b[38;5;241m.\u001b[39mchecker\u001b[38;5;241m.\u001b[39mcheck_model(model)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\onnx\\__init__.py:210\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(f, format, load_external_data)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(\n\u001b[0;32m    190\u001b[0m     f: IO[\u001b[38;5;28mbytes\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m os\u001b[38;5;241m.\u001b[39mPathLike,\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;28mformat\u001b[39m: _SupportedFormat \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# noqa: A002\u001b[39;00m\n\u001b[0;32m    192\u001b[0m     load_external_data: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    193\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ModelProto:\n\u001b[0;32m    194\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a serialized ModelProto into memory.\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \n\u001b[0;32m    196\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;124;03m        Loaded in-memory ModelProto.\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 210\u001b[0m     model \u001b[38;5;241m=\u001b[39m _get_serializer(\u001b[38;5;28mformat\u001b[39m, f)\u001b[38;5;241m.\u001b[39mdeserialize_proto(\u001b[43m_load_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m, ModelProto())\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m load_external_data:\n\u001b[0;32m    213\u001b[0m         model_filepath \u001b[38;5;241m=\u001b[39m _get_file_path(f)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\onnx\\__init__.py:147\u001b[0m, in \u001b[0;36m_load_bytes\u001b[1;34m(f)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     f \u001b[38;5;241m=\u001b[39m typing\u001b[38;5;241m.\u001b[39mcast(Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike], f)\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m readable:\n\u001b[0;32m    148\u001b[0m         content \u001b[38;5;241m=\u001b[39m readable\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m content\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'best.onnx'"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "# Load the ONNX model\n",
    "model = onnx.load(\"best.onnx\")\n",
    "\n",
    "# Check that the IR is well formed\n",
    "onnx.checker.check_model(model)\n",
    "\n",
    "# Print a Human readable representation of the graph\n",
    "onnx.helper.printable_graph(model.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af80300c-1d4f-4861-aa02-e772f06dd27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\runs\\detect\\train10\\weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\sshiv\\runs\\detect\\train10\\weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09829114-e63d-4db9-86fa-86a89df2bfa1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01monnxruntime\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mort\u001b[39;00m\n\u001b[0;32m      3\u001b[0m ort_session \u001b[38;5;241m=\u001b[39m ort\u001b[38;5;241m.\u001b[39mInferenceSession(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest.onnx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m outputs \u001b[38;5;241m=\u001b[39m ort_session\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m----> 7\u001b[0m     {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(batch_size, channels, height, width)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)}\n\u001b[0;32m      8\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "\n",
    "ort_session = ort.InferenceSession('best.onnx')\n",
    "\n",
    "outputs = ort_session.run(\n",
    "    None,\n",
    "    {'input': np.random.randn(batch_size, channels, height, width).astype(np.float32)}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b02c87d-495c-44e9-a9c7-3cccd0b80582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
      "\u001b[1m102967424/102967424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 0us/step\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\sshiv\\AppData\\Local\\Temp\\tmp1r23y_38\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\sshiv\\AppData\\Local\\Temp\\tmp1r23y_38\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\sshiv\\AppData\\Local\\Temp\\tmp1r23y_38'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='keras_tensor_177')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 1000), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2206832741264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206832741456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206832742032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206832740304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206832740880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206832741840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206832745104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206832746256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206832746640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206832744720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206832745488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206832746448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206832747408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206832748560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206832748944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206832747024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206832747792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206832748752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206832749712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206832750864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206832742800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206832743952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206832744336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206832742416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206832743184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206832744144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206832751248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206832749328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206832750096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206832751056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206832752016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206832753168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206832753552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206832751632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206832752400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206832753360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206832753936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206832752784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833230864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833230096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833231056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833230288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833231824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833232976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833233360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833231440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833232208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833233168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833234128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833235280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833235664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833233744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833234512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833235472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833236432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833237584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833237968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833236048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833236816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833237776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833238736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833239888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833240272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833238352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833239120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833240080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833243344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833244496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833244880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833242960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833243728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833244688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833230672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833245264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833606928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833607504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833606736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833607696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833608464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833609616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833241040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833242192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833242576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833240656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833241424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833242384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833610000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833608080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833608848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833609808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833610768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833611920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833612304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833610384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833611152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833612112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833613072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833614224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833614608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833612688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833613456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833614416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833615376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833616528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833616912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833614992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833615760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833616720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833617680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833618832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833619216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833617296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833618064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833619024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833619984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833621136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833621520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833619600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833620368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833621328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833620752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833622288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834032720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834033488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206833622672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834033296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834034256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834035408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834035792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834033872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834034640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834035600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834036560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834037712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834038096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834036176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834036944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834037904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834038864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834040016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834040400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834038480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834039248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834040208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834043472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834044624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834045008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834043088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834043856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834044816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834045776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834046928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834047312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834045392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834046160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834047120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834048080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834047696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834041168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834042320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834042704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834040784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834041552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834042512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834492432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834491664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834048464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834491472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834492816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834493968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834494352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834492240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834493200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834494160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834495120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834496272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834496656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834494736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834495504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834496464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834497424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834498576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834498960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834497040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834497808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834498768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834499728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834500880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834501264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834499344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834500112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834501072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834502032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834503184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834503568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834501648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834502416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834503376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834504336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834505488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834505872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834503952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834504720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834505680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834506640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834506256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834950800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834950224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834492048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834507024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834951376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834952528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834952912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834950992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834951760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834952720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834953680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834954832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834955216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834953296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834954064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834955024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834955984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834957136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834957520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834955600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834956368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834957328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834958288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834959440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834959824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834957904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834958672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834959632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834960592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834961744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834962128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834960208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834960976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834961936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834962896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834964048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834964432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834962512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834963280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834964240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834965200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834964816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835343824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835344400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834950608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206834966352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835344208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835345552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835345936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835344016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835344784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835345744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835349008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835350160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835350544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835348624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835349392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835350352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835351312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835352464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835352848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835350928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835351696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835352656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835353616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835354768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835346704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835347856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835348240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835346320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835347088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835348048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835355152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835353232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835354000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835354960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835355920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835357072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835357456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835355536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835356304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835357264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835358224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835359184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835359376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835868304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835343440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835359568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835868496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835869648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835870032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835867920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835868880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835869840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835870800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835871952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835872336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835870416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835871184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835872144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835873104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835874256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835874640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835872720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835873488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835874448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835875408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835876560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835876944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835875024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835875792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835876752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835877712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2206835878864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the pre-trained ResNet model in TensorFlow\n",
    "model = tf.keras.applications.ResNet50(\n",
    "    include_top=True,\n",
    "    weights='imagenet',\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "# Convert the TensorFlow model to TensorFlow Lite format\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TensorFlow Lite model to a file\n",
    "with open('resnet50.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58622b93-8066-456f-8143-5541a1f73811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is 20FD-A684\n",
      "\n",
      " Directory of C:\\Users\\sshiv\\runs\\detect\\train10\\weights\n",
      "\n",
      "28-08-2024  17:32    <DIR>          .\n",
      "25-08-2024  14:53    <DIR>          ..\n",
      "28-08-2024  14:18         9,428,266 best.onnx\n",
      "25-08-2024  14:53         5,736,676 best.pt\n",
      "28-08-2024  14:18    <DIR>          best_saved_model\n",
      "25-08-2024  14:53         5,736,868 last.pt\n",
      "28-08-2024  14:37       102,155,956 model.tflite\n",
      "               4 File(s)    123,057,766 bytes\n",
      "               3 Dir(s)  89,527,111,680 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "788487d4-92e1-4bd0-a142-2c850777b0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\ultralytics\\cfg\\__init__.py\", line 594, in entrypoint\n",
      "    getattr(model, mode)(**overrides)  # default args from model\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\ultralytics\\engine\\model.py\", line 441, in predict\n",
      "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\ultralytics\\engine\\predictor.py\", line 177, in predict_cli\n",
      "    for _ in gen:  # noqa, running CLI inference without accumulating any outputs (do not modify)\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_contextlib.py\", line 36, in generator_context\n",
      "    response = gen.send(None)\n",
      "               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\ultralytics\\engine\\predictor.py\", line 220, in stream_inference\n",
      "    self.setup_source(source if source is not None else self.args.source)\n",
      "  File \"C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\ultralytics\\engine\\predictor.py\", line 192, in setup_source\n",
      "    self.dataset = load_inference_source(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\ultralytics\\data\\build.py\", line 181, in load_inference_source\n",
      "    dataset = LoadImagesAndVideos(source, batch=batch, vid_stride=vid_stride)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\ultralytics\\data\\loaders.py\", line 292, in __init__\n",
      "    raise FileNotFoundError(f\"{p} does not exist\")\n",
      "FileNotFoundError: test_images/12.jpg does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.02 save=True model=C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt source=test_images/12.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd8d7579-a159-4fee-8508-2af806154582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\Desktop\\sihProject\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\sshiv\\Desktop\\sihProject\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9167603-c1fd-4ea9-8429-d01b6d9b741c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "Loading C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\model.tflite for TensorFlow Lite inference...\n",
      "WARNING âš ï¸� Metadata not found for 'model=C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\model.tflite'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\ultralytics\\cfg\\__init__.py\", line 594, in entrypoint\n",
      "    getattr(model, mode)(**overrides)  # default args from model\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\ultralytics\\engine\\model.py\", line 441, in predict\n",
      "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\ultralytics\\engine\\predictor.py\", line 177, in predict_cli\n",
      "    for _ in gen:  # noqa, running CLI inference without accumulating any outputs (do not modify)\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_contextlib.py\", line 36, in generator_context\n",
      "    response = gen.send(None)\n",
      "               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\ultralytics\\engine\\predictor.py\", line 248, in stream_inference\n",
      "    preds = self.inference(im, *args, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\ultralytics\\engine\\predictor.py\", line 142, in inference\n",
      "    return self.model(im, augment=self.args.augment, visualize=visualize, embed=self.args.embed, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\ultralytics\\nn\\autobackend.py\", line 537, in forward\n",
      "    self.interpreter.set_tensor(details[\"index\"], im)\n",
      "  File \"C:\\Users\\sshiv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py\", line 732, in set_tensor\n",
      "    self._interpreter.SetTensor(tensor_index, value)\n",
      "ValueError: Cannot set tensor: Dimension mismatch. Got 640 but expected 224 for dimension 1 of input 0.\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.02 save=True model=C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\model.tflite source=test_images/12.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18355cfa-9a05-46d6-b274-39d73481a43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.12.1 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i7-11800H 2.30GHz)\n",
      "YOLOv10n summary (fused): 285 layers, 2697926 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "image 1/1 C:\\Users\\sshiv\\Desktop\\sihProject\\test_images\\12.jpg: 480x640 2 Shivanshus, 97.8ms\n",
      "Speed: 3.1ms preprocess, 97.8ms inference, 12.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mC:\\Users\\sshiv\\runs\\detect\\predict5\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\Desktop\\sihProject\\yolov10\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict conf=0.02 save=True model=C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt source=test_images/12.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0804692e-d4ce-472d-a6cf-d1e0051c3c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is 20FD-A684\n",
      "\n",
      " Directory of C:\\Users\\sshiv\\Desktop\\sihProject\n",
      "\n",
      "28-08-2024  20:30    <DIR>          .\n",
      "27-08-2024  20:45    <DIR>          ..\n",
      "24-08-2024  08:42    <DIR>          .ipynb_checkpoints\n",
      "26-08-2024  00:53         3,932,288 calibration_image_sample_data_20x128x128x3_float32.npy\n",
      "25-08-2024  00:23    <DIR>          custom_dataset\n",
      "25-08-2024  13:32               308 data.yaml\n",
      "27-08-2024  19:57    <DIR>          saved_model\n",
      "25-08-2024  16:16    <DIR>          test_images\n",
      "28-08-2024  20:30           869,463 Untitled.ipynb\n",
      "27-08-2024  20:53    <DIR>          yolov10\n",
      "28-08-2024  14:18    <DIR>          yolov9\n",
      "               3 File(s)      4,802,059 bytes\n",
      "               8 Dir(s)  90,734,325,760 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f549aa0-96f5-4ee9-8c75-38e8d2864144",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (2475625787.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[21], line 6\u001b[1;36m\u001b[0m\n\u001b[1;33m    weights='C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt',\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the pre-trained ResNet model in TensorFlow\n",
    "model = tf.keras.applications.ResNet50(\n",
    "    include_top=True,\n",
    "    weights='C:\\Users\\sshiv\\runs\\detect\\train10\\weights\\best.pt',\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "# Convert the TensorFlow model to TensorFlow Lite format\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TensorFlow Lite model to a file\n",
    "with open('resnet50.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b077d95-db28-43f7-9a40-c3ee4e57ee73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sshiv\\runs\\detect\\train10\\weights\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\sshiv\\runs\\detect\\train10\\weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3dd2346-38f9-43ca-8cf8-8336eb5c210a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File format not supported: filepath=best.pt. Keras 3 only supports V3 `.keras` and `.weights.h5` files, or legacy V1/V2 `.h5` files.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load the pre-trained ResNet model in TensorFlow\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapplications\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mResNet50\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbest.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Convert the TensorFlow model to TensorFlow Lite format\u001b[39;00m\n\u001b[0;32m     11\u001b[0m converter \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mlite\u001b[38;5;241m.\u001b[39mTFLiteConverter\u001b[38;5;241m.\u001b[39mfrom_keras_model(model)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\applications\\resnet.py:409\u001b[0m, in \u001b[0;36mResNet50\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, name)\u001b[0m\n\u001b[0;32m    406\u001b[0m     x \u001b[38;5;241m=\u001b[39m stack_residual_blocks_v1(x, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m6\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    407\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stack_residual_blocks_v1(x, \u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m3\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 409\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mResNet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresnet50\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_top\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpooling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpooling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclassifier_activation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclassifier_activation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\applications\\resnet.py:214\u001b[0m, in \u001b[0;36mResNet\u001b[1;34m(stack_fn, preact, use_bias, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, name, weights_name)\u001b[0m\n\u001b[0;32m    212\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_weights(weights_path)\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 214\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:273\u001b[0m, in \u001b[0;36mload_weights\u001b[1;34m(model, filepath, skip_mismatch, **kwargs)\u001b[0m\n\u001b[0;32m    271\u001b[0m             legacy_h5_format\u001b[38;5;241m.\u001b[39mload_weights_from_hdf5_group(f, model)\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    274\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile format not supported: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeras 3 only supports V3 `.keras` and `.weights.h5` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    276\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiles, or legacy V1/V2 `.h5` files.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    277\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: File format not supported: filepath=best.pt. Keras 3 only supports V3 `.keras` and `.weights.h5` files, or legacy V1/V2 `.h5` files."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the pre-trained ResNet model in TensorFlow\n",
    "model = tf.keras.applications.ResNet50(\n",
    "    include_top=True,\n",
    "    weights='best.pt',\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "# Convert the TensorFlow model to TensorFlow Lite format\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TensorFlow Lite model to a file\n",
    "with open('resnet50.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da31fb0f-a7d4-4b04-bd61-0519d1ca6d78",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_addons'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01monnx\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx_tf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m prepare\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load the ONNX model\u001b[39;00m\n\u001b[0;32m      5\u001b[0m onnx_model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest.onnx\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\onnx_tf\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\onnx_tf\\backend.py:29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx_tf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_unique_suffix\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx_tf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m supports_device \u001b[38;5;28;01mas\u001b[39;00m common_supports_device\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx_tf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhandler_helper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_all_backend_handlers\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx_tf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpb_wrapper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OnnxNode\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01monnx_tf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcommon\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\onnx_tf\\common\\handler_helper.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m defs\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx_tf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhandlers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx_tf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhandlers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_handler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BackendHandler\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01monnx_tf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcommon\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\onnx_tf\\handlers\\backend\\hardmax.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfa\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx_tf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhandlers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_handler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BackendHandler\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01monnx_tf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhandlers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhandler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m onnx_op\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_addons'"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_model_path = 'best.onnx'\n",
    "onnx_model = onnx.load(onnx_model_path)\n",
    "\n",
    "# Convert ONNX model to TensorFlow model\n",
    "tf_rep = prepare(onnx_model)\n",
    "\n",
    "# Save the converted TensorFlow model\n",
    "tf_model_path = 'best_tf_model'\n",
    "tf_rep.export_graph(tf_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2f3971-046a-4054-8ced-b0a75152860a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
